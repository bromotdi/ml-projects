{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "005cabf6",
   "metadata": {},
   "source": [
    "## 1. install depencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a428fbf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/lts/1.8/cu111\n",
      "Collecting torch==1.8.2\n",
      "  Using cached https://download.pytorch.org/whl/lts/1.8/cu111/torch-1.8.2%2Bcu111-cp39-cp39-win_amd64.whl (3057.4 MB)\n",
      "Collecting torchvision==0.9.2\n",
      "  Using cached https://download.pytorch.org/whl/lts/1.8/cu111/torchvision-0.9.2%2Bcu111-cp39-cp39-win_amd64.whl (1.9 MB)\n",
      "Collecting torchaudio===0.8.2\n",
      "  Using cached https://download.pytorch.org/whl/lts/1.8/torchaudio-0.8.2-cp39-none-win_amd64.whl (109 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.22.4-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting pillow>=4.1.1\n",
      "  Downloading Pillow-9.1.1-cp39-cp39-win_amd64.whl (3.3 MB)\n",
      "Installing collected packages: typing-extensions, numpy, torch, pillow, torchvision, torchaudio\n",
      "Successfully installed numpy-1.22.4 pillow-9.1.1 torch-1.8.2+cu111 torchaudio-0.8.2 torchvision-0.9.2+cu111 typing-extensions-4.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.8.2 torchvision==0.9.2 torchaudio===0.8.2 --extra-index-url https://download.pytorch.org/whl/lts/1.8/cu111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c5466ad",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5db33309",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib>=3.2.2\n",
      "  Downloading matplotlib-3.5.2-cp39-cp39-win_amd64.whl (7.2 MB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from -r requirements.txt (line 6)) (1.22.4)\n",
      "Collecting opencv-python>=4.1.1\n",
      "  Downloading opencv_python-4.6.0.66-cp36-abi3-win_amd64.whl (35.6 MB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from -r requirements.txt (line 8)) (9.1.1)\n",
      "Collecting PyYAML>=5.3.1\n",
      "  Downloading PyYAML-6.0-cp39-cp39-win_amd64.whl (151 kB)\n",
      "Collecting requests>=2.23.0\n",
      "  Downloading requests-2.28.0-py3-none-any.whl (62 kB)\n",
      "Collecting scipy>=1.4.1\n",
      "  Downloading scipy-1.8.1-cp39-cp39-win_amd64.whl (36.9 MB)\n",
      "Requirement already satisfied: torch>=1.7.0 in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from -r requirements.txt (line 12)) (1.8.2+cu111)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from -r requirements.txt (line 13)) (0.9.2+cu111)\n",
      "Collecting tqdm>=4.41.0\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Collecting protobuf<=3.20.1\n",
      "  Downloading protobuf-3.20.1-cp39-cp39-win_amd64.whl (904 kB)\n",
      "Collecting tensorboard>=2.4.1\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "Collecting pandas>=1.1.4\n",
      "  Downloading pandas-1.4.2-cp39-cp39-win_amd64.whl (10.5 MB)\n",
      "Collecting seaborn>=0.11.0\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "Requirement already satisfied: ipython in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from -r requirements.txt (line 35)) (8.4.0)\n",
      "Requirement already satisfied: psutil in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from -r requirements.txt (line 36)) (5.9.1)\n",
      "Collecting thop\n",
      "  Downloading thop-0.1.0.post2206102148-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (2.8.2)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (21.3)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.3-cp39-cp39-win_amd64.whl (55 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2022.5.18.1)\n",
      "Requirement already satisfied: typing-extensions in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 12)) (4.2.0)\n",
      "Requirement already satisfied: colorama in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from tqdm>=4.41.0->-r requirements.txt (line 14)) (0.4.5)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (61.2.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.8.0-py2.py3-none-any.whl (164 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.46.3-cp39-cp39-win_amd64.whl (3.5 MB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting protobuf<=3.20.1\n",
      "  Using cached protobuf-3.19.4-cp39-cp39-win_amd64.whl (895 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.37.1)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "Requirement already satisfied: stack-data in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from ipython->-r requirements.txt (line 35)) (0.3.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from ipython->-r requirements.txt (line 35)) (2.12.0)\n",
      "Requirement already satisfied: traitlets>=5 in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from ipython->-r requirements.txt (line 35)) (5.3.0)\n",
      "Requirement already satisfied: jedi>=0.16 in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from ipython->-r requirements.txt (line 35)) (0.18.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from ipython->-r requirements.txt (line 35)) (3.0.29)\n",
      "Requirement already satisfied: matplotlib-inline in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from ipython->-r requirements.txt (line 35)) (0.1.3)\n",
      "Requirement already satisfied: pickleshare in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from ipython->-r requirements.txt (line 35)) (0.7.5)\n",
      "Requirement already satisfied: backcall in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from ipython->-r requirements.txt (line 35)) (0.2.0)\n",
      "Requirement already satisfied: decorator in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from ipython->-r requirements.txt (line 35)) (5.1.1)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.16.0)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from jedi>=0.16->ipython->-r requirements.txt (line 35)) (0.8.3)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.11.4-py3-none-any.whl (18 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.8.0-py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied: wcwidth in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 35)) (0.2.5)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pure-eval in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from stack-data->ipython->-r requirements.txt (line 35)) (0.2.2)\n",
      "Requirement already satisfied: executing in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from stack-data->ipython->-r requirements.txt (line 35)) (0.8.3)\n",
      "Requirement already satisfied: asttokens in e:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages (from stack-data->ipython->-r requirements.txt (line 35)) (2.0.5)\n",
      "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, zipp, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, pytz, kiwisolver, importlib-metadata, google-auth, fonttools, cycler, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, scipy, protobuf, pandas, matplotlib, markdown, grpcio, google-auth-oauthlib, absl-py, tqdm, thop, tensorboard, seaborn, PyYAML, opencv-python\n",
      "Successfully installed PyYAML-6.0 absl-py-1.1.0 cachetools-5.2.0 charset-normalizer-2.0.12 cycler-0.11.0 fonttools-4.33.3 google-auth-2.8.0 google-auth-oauthlib-0.4.6 grpcio-1.46.3 idna-3.3 importlib-metadata-4.11.4 kiwisolver-1.4.3 markdown-3.3.7 matplotlib-3.5.2 oauthlib-3.2.0 opencv-python-4.6.0.66 pandas-1.4.2 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 pytz-2022.1 requests-2.28.0 requests-oauthlib-1.3.1 rsa-4.8 scipy-1.8.1 seaborn-0.11.2 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 thop-0.1.0.post2206102148 tqdm-4.64.0 urllib3-1.26.9 werkzeug-2.1.2 zipp-3.8.0\n"
     ]
    }
   ],
   "source": [
    "!cd yolov5 & pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ae7c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda_env\\yolov5\\yolo\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c72376",
   "metadata": {},
   "source": [
    "## 2. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d5d19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\saski/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-6-18 Python-3.9.12 torch-1.8.2+cu111 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5x6 summary: 574 layers, 140730220 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5x6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f71665d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoShape(\n",
       "  (model): DetectMultiBackend(\n",
       "    (model): Model(\n",
       "      (model): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(3, 80, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): Conv(\n",
       "          (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (4): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (4): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (5): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (6): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (7): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): Conv(\n",
       "          (conv): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (6): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (4): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (5): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (6): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (7): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (8): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (9): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (10): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (11): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): Conv(\n",
       "          (conv): Conv2d(640, 960, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (8): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(960, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(960, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(960, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): Conv(\n",
       "          (conv): Conv2d(960, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (10): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): SPPF(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (12): Conv(\n",
       "          (conv): Conv2d(1280, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (13): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (14): Concat()\n",
       "        (15): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(1920, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(1920, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(960, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (16): Conv(\n",
       "          (conv): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (17): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (18): Concat()\n",
       "        (19): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (20): Conv(\n",
       "          (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (21): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (22): Concat()\n",
       "        (23): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (24): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (25): Concat()\n",
       "        (26): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (27): Conv(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (28): Concat()\n",
       "        (29): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(1280, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(1280, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(960, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (30): Conv(\n",
       "          (conv): Conv2d(960, 960, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (31): Concat()\n",
       "        (32): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (33): Detect(\n",
       "          (m): ModuleList(\n",
       "            (0): Conv2d(320, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): Conv2d(640, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): Conv2d(960, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (3): Conv2d(1280, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c24966",
   "metadata": {},
   "source": [
    "## 3. Make Detections with Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f0d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = \"https://images.unsplash.com/photo-1589828155685-83225f7d91f3?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=710&q=80\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "138b8ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1: 1007x710 6 persons, 26 cars, 1 motorcycle, 1 bus, 2 trucks\n",
      "Speed: 658.8ms pre-process, 1369.7ms inference, 3.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    }
   ],
   "source": [
    "results = model(img)\n",
    "results.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "104ce9af",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            car\n",
      "1            car\n",
      "2            car\n",
      "3            car\n",
      "4            car\n",
      "5            car\n",
      "6            bus\n",
      "7            car\n",
      "8            car\n",
      "9          truck\n",
      "10           car\n",
      "11        person\n",
      "12           car\n",
      "13           car\n",
      "14           car\n",
      "15           car\n",
      "16        person\n",
      "17           car\n",
      "18           car\n",
      "19           car\n",
      "20           car\n",
      "21           car\n",
      "22        person\n",
      "23           car\n",
      "24           car\n",
      "25    motorcycle\n",
      "26        person\n",
      "27           car\n",
      "28        person\n",
      "29           car\n",
      "30        person\n",
      "31           car\n",
      "32           car\n",
      "33           car\n",
      "34           car\n",
      "35         truck\n",
      "Name: name, dtype: object\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(results.pandas().xyxy[0][\"name\"])\n",
    "num_vehicles = results.pandas().xyxy[0][\"class\"]\n",
    "num = 0\n",
    "for vehicle in num_vehicles:\n",
    "    if vehicle == 2 or vehicle == 3 or vehicle == 5 or vehicle == 7:\n",
    "        num+= 1\n",
    "\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "252b57d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMcAAAD8CAYAAADDuLCoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOz9d7hl2VXeC//mnCvseHKokyrHrtA5q5OkVkJqhZYAgQJgsoUJNr4YLLBNuASLZGNASDIIlBAox845VXV1xe7K4eR8dt57pTm/P+ba51QLta+/6wfd4nl69lN9dlx77bXHmCO94x3CGMOr69X16vqnS/5/fQKvrlfX5bpeVY5X16vrFdaryvHqenW9wnpVOV5dr65XWK8qx6vr1fUK61XleHW9ul5hfc+VQwjxJiHESSHEGSHEr3yvP//V9er6313ie1nnEEIo4BRwNzAJ7Afea4x58Xt2Eq+uV9f/5vpeW44bgDPGmHPGmBD4LPD27/E5vLpeXf9by/kef94IMHHJ/UngxktfIIT4SeAnAbLZ7LVjI0PMzc2TGIMxIARordHGoLWht7NI1nfIZzM0I4NGIqRESgEGDIAxKCVxPR8Q9oOMRicJQgqklLSCAIEAKZFSIgAhJRiDlBKtNWEU4TkSmUQIAVKY1eMZBI0YMr6H0sHq40IIotgQBCGOIwmqVYQxtOKEapQQa43veRTzWZSUOF4Gx/NZWFikFbTQWpNog+d5DA0OoBONs7CAm8Sr18yk59j2AoT94NXb5pLXpTfs8+377dvpe+z7BAYDvg8dnRBHUC4jtE6/b/q6QgETxRDH0NMDUthPrVVZrNaoxAmuFGQch0ac0BQC13XtbyIEna5LNWyRCIXAEMYxOD4IgU4SjBAIIfAkuNKelRD291VSopQiCAIA+7sJQRLHhHGC73koJZFCgFD09HRTrZTw/CxR2KLZbOH7HpNT04vGmP7vFNbvtXL8Py5jzEeBjwLs2bPH/NFv/Reeefx+UPaLt4ImiYZWENJotugsFugp+Nx13Tbmow4aMofrZchlM2gDOjEYNN0dOYZHN4F0SLRGmJhGeZmM75HJ5nnsyWdphJooTsAY4iiku6eHTRtHGR4apNlsMTUzx2CHz1NPPMxwb55b94zRFqPYeOyfU+zdOka+fj5VHAVCMrfc5MVTFxka6OFLn/9H1nkeE9JnfLnMzOISV+/azvV7diKlZN3W3fQObeLrX/5HOjMtstEZPv3gBejYyK/90r+huVJizyf+ii1JAoUCzM9DGILnwcAALC1Bq2WfKxZhZcXeVgoWFkBr6OuzyrC4aIU/m4V8HubmrJC3l+/Dhz8MX/0q7N5tj/XFL649PzYGv//78PGPwyOPwPAwuC584AOYL32Jiy+8wExfP3JgAPfAAX6vGfNMosmNbiVSHlpAXjpsXtdH2Kgz0t9Ls7xETTk0owgpXbQx5HIeOc9lS3c3ulZlcnIc1/VQwqp+rVGjXqsTa0PG9/E9F+W4uFJhhMFgGNu4ndffdTv3fetrXHv9rdSXLnL+/AR7r97Hj/2rn7r43WTxe60cU8DYJfdH08e++zJw8cI5WpUZlFIIIUHHCG3w4wRPGKJqk0oo8eRWpBQIJEo5SKXQcYIBtI5JEgPC7iJGCIQR+L6P5yjAcPrUSSqNBiOjY3R0ddLRUWTrts24ykFKF2jhug7lSpXRbo+hHh8pJAaBMNqerEktibGWBAwIgxAC5Ticm5qhnOtlplohShpEccxgfz+j63pxHZdms0Hn9Axd9ZBd1RLHD5xCdma5d8MOZlca9J27QLNaJlfsgO9/j93pT52Cr30N3vQm2LULpqfh29+G970PpIQXXoBrrrGvfeghWF6Ge++15/qFL9j3XH89NJvw8MPw3HNWkbq6rCWYmoL9+60SvuUtVpGaTchk4P3vh+PH7bHiGMbHYf16CEPEsWNs9H02/sLPw8oK+sXj7FMrxK4hlLM0wxhDgu/n6I4aSMcgF2Z51223sXHzKEgXpIJsB0oqTGOZxtIsj3zrWXxTR7rdCD9PoaNIuFwl6emgJXyioEVUXmBuqcnFMIsxoJSgZ2CEY0cPsbC0gFIK388QRhGHXzjyiuL3vVaO/cA2IcQmrFL8IPBDr/hqIcjkfQaG8owNrcfoGGOsm2ESTaI1UaLp6cjS09XJzLJCRwajNWhQUiHQxEYRW2/AugqAVJKOYpEoaOE4itGxUTK5DD29g4yMrSdoNslms2hjMKlLZ4yhs7PIlvwmfFcCEgQIITGJACSJNgSxQght3yckldBQKBbpKmTIq5hWtgCtOhnXZdf2DRQKHQRhiIkitn3hi/RUamw2hnuNwSyXEKnbIz7x0VTfNHzkI9YKWD/TKshXv7p2/0/+xP4FK/SXJl4+8hGrAB/4AGzaZN/zF39hLQfAlVfa5xYX4emnrQX60R+1x/vwh+GP/xiuvRZ27IBKBd74Rjh7Fi5etLcfeACiCL7v+yAIIIoQwK/sAdMdYJi/5EcuAzPtnxtx8SRiHEDA9lvg1g8ABs49Akfv484+jRlQcOf3wehuxMBmzP/8aejbCNfcAyNXwCMf5/4HH+T/nuqE9LfrHxzmlptvAKPx/Qy5nh60VJxfrr+i+H1PlcMYEwshPgR8G1DAJ4wxx1/59ZrTF09SNDVu3reLVjOkXgvp7ckhlURj0MYgMehII4Wg1Whw5OhRpJQ4jmv9zyhk/YYNbNy8GYGk0WiwtDjLaH8frutSLpUZGR0lm8sRxRpHSUIA0VYw7OcIiasEOaloJIJvnQ3xlEuPlzDilmkG3cyu1HjmoWeJE02SaDCansFhtmwcI2+avOX2m3l4/wtMVSR9fT1sHOqlHiS0GjVkkmCKHYjX3I7o6oLHH7e78d69VmAPHICZGSuYAwNw8CDs22eF9qGH7EV7/eutwD7yCGzebP8Vi3DffdZq2Atr379+PfzWb8HrXgeveQ38wz/Y54eHoV6Hc+fg5En7/kIBPvtZa3W6u+Gpp+DMGXjta6FWs5ZlcBCGhuCTn1w7DsAVVyCuvRblvgTiPIzthW23QGkGXnoYNl0PvWNw/nmYOGIDGiGtsH/zv0LQgLf+ezj+AJgETAyP/CW89qegvgilaVgeh6ACb/sPcPpxdBzTbLaQUoJ0UI5PZ2cHh46/xMiG7ejqCvOLC8wE2VeU1+95ncMY8w1jzHZjzBZjzG//r14rhOTW629ksHeEiYlFHnziIEdOXeSx515iudxESYnvKBwlSYwmjiOmZ2eYW1hgcXmZuYV5FpYWKZXL1Ot12uFzrVZFCokQ4DiSjO/T3dWF7/vtT7aBcJwAZnXnTlaDUUMtgoXII3R8TiwHTM0s2PckMDG/wuT8EuOzS8wsLWOaJc5NzjDfgjDW3HbD1WztyxJoqIcuXfkOurp6cJSD2bQR7rrLukc/+7NWKX7hF6xA/uIvWt//gx+ECxesYO7aZd2f66+Hn/opu2Nv2QL33ANvfrN93nHgrW99+cXt7V2LTy5cgJGRtedmZuDZZ63Af+hD1j0rFOBd74L+fqhWbWxx4QKcOGFdO9eFbdusW9bVZY/zrW/BkSPWAs3MwO7Xw6br4O4Pwfw5uOWHoG8TvPmXIGxCeW7tHBwPMkVYmYHqAigX3MylkgTzZ6FzyB4TrBJNHofXfACNIJfL4fk+StnAHQFxnNiNUwlyQZPJE8deUf4uu4D80mWMYV1HBxT6+cYjj3Fm5gJFP0uiBcdPv8ib77iTbZsGEDbPRBxGTE1PE0cROkmIogjRzo60k1TA2bPn6O4qEHQW8H2fMIqpN1p0dBYBa94TnaC1xmjriBnWMkJC2IyMjg2tSCCTgJmFBXLFbRg0zWZIGLaIEkNXwWdseJBKucLMiqC3o4AfNrj1mqt4+LkXOHT6HDft20lOajKei9SxFbhHHoHbbrOWIYqsEL/wgvXtDxyw7s7cHLzhDVYZLl60SvLAAzA6Cm9/u939H3zQfvG77nr5xa1WrcBLaRVvedneBqsUx47Zz7r9drjzTqssf/3X8M53Ym66idL0NMGhQ0jPg0SjevtwXvMaG8RXKuhSCbWwSObw83iegqVJODQJe3fA/Hk4dh/sutNagqUJeP5LELXWzi+J7f1MHiIFOoEkAulApmAV5eh9kOuG4V1QW4TZ0/DoJ+Ce/4Ds6EEkw4ileXzfxpcYIEkw2oCG5UaDZq38ivJ3WSuHEPDgcwc5c+x+zk8uUY1DfGcFB0mjEXHg6En6+zroKmYwRlOtValUaggpiON4NXUZx7G9IFbKyWazGK2JkwidRJSWl1lZXqGrpxtop4wFjutgUsthdIIxBm0ELaPozWjeuD7m/PwUW0YUD5ytkgMkVoGCMEYIyGYyCKPo7e7GqTeoNCRdxU7yKuH2a6/igSef4szEHPt2bMYLQxwl4dZbbfYpSWy8cMUVa0FyHEOjYS/Qnj02y9RsWtfn5En46Z+Gjg6rJDt32mMI8fIsFMDsrP370z9t3atPfALe8x4ol+3nbNxo3aVmEw4ftsH3+98Pu3ZhPv95/vjA8zyaaLadOMPC0iL93V1sOfACUimSfJHaNdfR19XJ65sH2HvtCFzxY9C3Dh7+C+gZhbf8Mozusb9JUFuLj9pLx3D6KXjzv7VKceEgDG6Fm34Qnvu8tT4Tx2B0N9z/3+395UlrSU49SaW8wvjCIsOui5fxyGV8lBQoJRFSEOmEcjPAuN4ryt9lrRzGGHw/x0K9yWytSRhpejpdTOKynDRoxTHnz09w5RWbMdowv7CINhpXuWhtQGviOLZ+J9Z4CCEYHh4iDOq4rkeoBU6uwLrRHH42T2+fg6MkylEIBNpYjbLhg2am1OTA5AKv39nDhiL42kM0ytSbLRKdYNI4SKQ1A0fC/OwsuVwG33PJezBfrhFlPKLFBXZuHOPUxWlOjWe5JokoVBuEZ88g9+9nemmB5sZR9NOPU9y7Dy6M43V2kv3q1/n7gS04jx7gh8+dpyrg6eUl9i4uMr9zFy80m3QuLVJ56SW6HAedJGy8OE64dy86TlDKuqKlr3wFtm1FHTuGBMz4OFJrzPgEulbDuC7JiZPoRgPxhS+SDA4ivvIVktlZgq1bGRGSqVKJchwho5Ahx7F1BhzCTJZExgwH55j7+h8RDu8h01iE8gL6y3+EGNqJOvYUslQi/MZHEZGiQ3l8LdyEm83Sn/eYfuIYzrgB6RBcOEKYGMz8g0wfOU7z8V9H9W0g0/wGUhqqJz+FO7oLp3UWMXOCw41RIpVhobpCV2izlyCQQqRyIGm1WtjQ97uvy1o5hBAcPXmGciXGaInveAgDm8d66c8qovocM/OGfbs2IJAsLi23NQDlSKSSeAAGOjo6Vo/b0dFJEnlUaw32v7CfINYIxyMOmsRxzOjoCIMDfWQzOVtMxCDQNkgU0IwdNNAMNa2WYWlujkYQI4zGaE0YhgBIKfAUSBOBcRDSp7uQIwyWWKnHdPd04ZWW2TK2jrlqhepCnThMeHp5iZ2TE0Q7t7J81x3ki0UWjeBcrcl1m7Zgnt7Pn/asp78+xw++dBh/U5mNAz6dnQEEM+yVgtz6DM1Wi3wuR5Ik9Og6QVfTuqDCCkl/sY9k543owEceOgjBKTQG0SUQy8cRo1eg90r0+FlEvoLZshk2b8C4h6g0NXU9SiGbpberi6hWoVWvI5SyRdMo4vypC4ieiD+c3sj0ss9yPMb4XJYwaJLNzJHPZhkcuIFuEeBNhvzm5jmeyV3NUgtmTpxiYGgjHdManbRA7KChQ2ZPLTK5MszKmQWELrFh0xa6N2zl/hOL6DPTZDM+kd5GIa+4cmsGPSPIBjUcaZBCICVIYTc/BHhSfxfJs+uyVg5jDF0dHt2dDonMsLLSIpstMLEyTyHTxc7RMe66+QakEkRRRBQlOI6HTKvcIGxtBE1nZwHSamsul4FEIeKAoy88wzXX3YCb8+gc7qLZCtmxYxtxolcrxlJK8rkcQiqWlkuotGL+lcePcX6xQV/OEGlbUVeug+u6JFqT6IRiLkfOdylkHDw3weiA/u4iTiMi29WD091HPorZ0dlD78kzTP7d5/njyVl+uVVn5w3XogfWIYSh1WxSq1ago5OsSMiefJSebBaRgVy34YouFxp1OpKYMceDrAtBCGEJcj6YZdBV66IACAV3/hRMHoViP9z0OnjoL9ILD+S64J6fhGP3w8QDcNdP2KyQUDDaz8Jkg1N+N2EQ4NUUs5UStVo1FTqBBGqVCqJHMLJ1J6fnQp47cpQgDJFKkanX8V2Ps0srfN9tN/GGfRvQL36MZ556gpOzFTwleNvmrQgJeT8DxpDNZMgMbmK6D/padbaLKY4ePki1UiVTh8LoRjoKWQYGh9jS6SGWZjk4O0NxcAA/jpDAQF8PriMwUjE6toFiX8TD51/6rvJ3mSsHLJWazCw1qLca9PV30V3wSLTH6Zky1+0tslwuM9jVTaVaIU4ilJNZzTrpdjBtoJjLIJFp5gkEhiQx7Nm7jx3bttLSknUDfSytlABBHCfWRdAJvu9RyPXRaLZYWF4higIEORarIbHMEOgQ5Xi2qOj7ZHyXKGjieA69/T0Uiz5+rkC2kCdIIMYj60symQzZfJGBXI5sNkthucJyEnPw5Ckqfd0IKXGURAhJ3FrhzLGDDMzOcrPWODoi5+YQbsamL/v6oDwLj34c3vSL4Oftvy//FrzrP0NtCR76S5hKM+d+DvLdNhDOdcHbfsUW3XRi/97xr2Bl2sYCTgY2XAWd62zge/jrKDWE5zgoDGHgEEchtVoNpSRaGwr5LI7jAIZWpLnplju56obb0IlGAwiBIyW4PkUCzh97lBvCiPmZSeJAgHJZKa2wdeMorWaTjO8RIzlcKTK4fRMXJ2apNupUGw0qiyVClWfMlezqzbFSnmX/8WnOnzlJxnPYs2M7otlgfnyKbk+AjtHakMkWcDOvnLC9zJXDUG2ELJSa+J6kUmtQq1cxRuM5kudPvciGoUF6CwUWlirE2thqqhbo1P83BlxHkM/5qctljx3HCUjBtl17yGSyNOqtNBCXYMQqTscYWFpaYnZqhrn5OUZHBtg75OGi0doQxxGxTHA8n1w2SzaTYfOm9XQW8uRzOQrFHNJzMY6LyeXpzBfI5wo4rguk+C0MjlRIIXEcB6kkgtQNEGCShLC0xNbhbmpzs7hxzE9kM3TpBJnphPoy3Pd/w7rttn6wNA6P/U/4oY+Al7MC//e/agPf9pKpr220DX6lhbpAAltvgr1vsNmf7a+BqRdtlujRj8HgNrjlfcjHH8ZzHRKJ/ZvEtJoNlJIYA46S1OtVhBBsXD/CgZlZEIpsvouxdb00gxbX793G1OwCi7PjzC4v4voON1+/j6bIkPE98sUCaENnRyd+Pkd5foGupMnsUoUbxjKMPzNP2Gqi4wTZqnHhwCPMHrLCXk8M2VwRVyRs7O6ne2SEpYVl/DCmMDOBChsUPJ+V8DsSFZesy1o5pBR4rkcrhEqlieMoikVJEsfkMorx2TmeO3oIvWMnM0sl4iikVJnGU1DIZxFodGLAdenI2hy50YY0E4sUkp6ePuJmBSEgCAKSJEEqCTFgIEkSjp88geN65Lu66CwU6c4PgZC89a7XMLVcYmZujp7uLpQQZH2f3bu24ziKro5Osrk8nu9bgZdOCppbCwKlkGgdU6838ZIEgRUsA4iggVmepbw4S21umt5iHo1kceMgb241wUA8lEMVC+C40D1sc/3SAdeHOIQkhLkzEKSVYCHtv7AJrQp0j0LPiFUovwCdAzBzEr7wn2z9oKMflidgZcrWGpQLOkEpSSabwWhNq9VCCEkUhSRaYbQhSWKSRGMMLEzPUezeymy5Qr2yQnPpIkNjGzGtJrVyhYMvHGPMkbiOy7bNm5G5LrK+y2K5yrqBAZLZSa7u76c2atjw8KMk3/cBys8+iJcz5K/cTSMILGrAQJzExElCHCUYBNlMBh01qJ45y8YdG3FH1hONricXNdgyPcexlcYryt9lrRzaGGZmZ4CAbRsGuGL7HjqKDnGsKeQz9HXk8F2FLPbRMZDj2vwog/19FDxBEocoITFSEmkoFAooKSzWyQBGoxyJowWhMTjKIZPxiWKNEFCv1fEcF+VKrrvueqZnZgnCmCjRTK3UUUJQzBfZ09NDPpchTgxJHOE4ik2bNiGFRCoXkVogmRahRJoxaYM5pIBatcEnPvHX3BAEXC8l3YUiGQXFF79Brvpl1qUI3FUAyGD7hsExMTxyztYFzh+AVg3COrzj10E5VkG+/cf23blOePt/tMozexq+9nu21nDVW6G6CJkCoYZWo4U4dwQRaUShF1Mpw6OfQtzyAUyzAo9+nKYZItExjWqDZr1JsauDmfklXM/HkQKpHNb19mDMLE8+8Rgnw0MYL0NHxiefUZw5dY4DLxwmbrXQzTK9pgK+wXNdhOMQRhF9Pd2EcUA+alA5foCRN7+N0rc+z0CwgLjpaoLTE4xsWI9BE8XaorW1RkiL6JWkqBkpCYqdNGODFAlO1EI0GvieYrDrlSvkl7VySCEZGxogafXy3ne8ndfe9kZ85dFo1AjCAGMEfq6A57sMbYiwYaBGIojjCKkcmmFInCQI5WOEdZeSOMEkNrNkUMSxTsGFAoTAGGNjjYyPQZPNZFCp+wNghMVqJUgyfoaNGzdRqtRoaWVrI35mzUXDBvRS2OSAECkYXGuMTiBJEK0aV2wcovTk0wijUVGAdH2kl0GObsGdO2Njho5B6N8IlXlYnoKudTaYXjhvC2ZRywr+te+EJz8FhR645YfhS79lL2ix3xbNDnzBxh5hEzbfAF/5HdhzN+y6k5eOHOa54feS8TO2sFpPMOuGIAbxxFE0GpO7kwCF0Na97Sjk8DdtZGx0BCkUM7GHKx3GzCIqeZGfHV6gmizjugqlHPK5DKEGVdyAKWj00jhucwWFQz6poUNjs06iyfSeWVp768xVJjkQvkjyQ01mrzzA3OGDlF/Ti5YqRS/Y38yCPg1aazzXIWsKbPWuoZI9z33NY+QGY6KVbzPavYsr73ozu03MH/7Jn35X+buslcMYjY5b7Ny0gz1b9tIoVQgcB6TEGIFQCrTBGIkRLqBJEoEUtq8j0RAnEAQRKonJSWH7MFJhNQaWS2XiIMDP+3iui+vGqyhabQxGJzjKwfU8RGgzPTpJkEISJzFCClzp0WoukensxnUdYmOPL5XAaJuSloCIWkStFvVqhUatQqvZJIlCglaTjkKOnt1XMDj7BB8r5lmvFNzwdthehBveYyu/b/p5WLhgY4K//w/ww38EJx6DZz5j4w6wgbbrw+QRG29cc491hZLQ/o1DW1G+5h744n+GL/0X+77BrfDM59BOhpZToB5qojCkO1jgTdXHUcKk2MVLAIxpzcCCMnUKz5GsJCBiQYebkL3qjbxm7Ao49TicejJ9YwV23G6tlo7h6c/AwgI638mPXpGDQ19BlGPKec0/XnsDcUc339ZfxdBOu56ErZdKikgbB16elnVw+Sn1+4S0uJK9/L1+koNmv/0NhU+HeAEp/oXWOZRS3Hzza5gdP029ERDHBs/3yGYLZDIZEiNIkgSVWGi6ibWFrSuFowSJ1vi+Rxi2cN02bsqQSiyO61Io5FluVJFSUiqtsFKpMzAwuAo5EQgefuQRHM+nq7cXlVqemBhfZxA6QTo+zaCFm8REUWyboiQkYUzYbBK2mrQadZr1GkEQECcx2gi0AZshULh+jtr69Ry5+w7cKMJkWzAs4Wu/C4VeK0znn7dK8sN/aOOGxQvw9d9fS8/CWqVZKGtFdAJtoVk4D5/5t9Zi3P0hGNsHJx6FN/wcTByFC8/je2P0ZcaR+R5EMEtfMsdwsoAs9NpjVBdsirtjwGpFo2zv+1lQHlTmGGkngMauht13WuG/88etYq+kHQq7X2vvz56G8jw4HvKN/4bc2F449EXQLQKtcXC4Q/4wO8WN3K//lmUzwwZxBfvNt7lbvo8D+n7ern6GDnp5Vn+Tp8xXVi9FD0PkKPIXyS+zT9zODeKNnEyV47h5iuPmKa4Xb3xF+buslcMYw9VXXsOxJEQ4DigJUmGSmKAZI5TN+ATNBl42S5zEEFvBV1IRJQlSKlzl2LoFgLHQcm0EwvHJZlz6143gZ3MkUYTTjDBGW5gBECcJGzdvplytIYyxjW5GW6tgYkwSI4yhulJGJxY7tTJxkbBWJohsgK+NRGPVwHZ+iDQhYOsuQggUAlzF4o6tSAyjy8/A5r2w8DrYfCOcfAz2vB6uuMsG3gDNair8l6ywAZUFuO6dNkU7c9JmsUb3Wtds8/V2Bx/dAycfh+/7ZZvSPfkEdA2xSwl2vuXN0KxAuB7xpd+C3a+D695lj//MZ22QvusuyHbYOoifhx23WSv2yMesNQAY2wMnHoHz+621G9xilUNIa9U2XmPdulwXHP463PencO9/ednXkUheMs/yqP48Pyx/jW/oj7FNXsPzyQNcJe9izkywXVzHM/rr9IsRhJGrFiRPJw1qJCSUzDydsp9LeyM9MrxBfoDf5It8t3VZK4eUEs+RrB9bT8F3beyAoFZeZnFmgiBKUAoymRyun0HH8aq/KaW0qV3HxRhYl8kjxAAYOHt+nKmZWRuDIAnCgCgMKeYy9A0OgrE1kiRJ8DMZCvluKrUaUlprFActYq3Juj6NUpl6fQrVWmZpeQJdmcNojVACY4R1+Wi3r1rHQ6ymy+QqzEQgSBJNKwwQtSVy0/tJHlqB7bciXnoEc+F5EAqz4Wp46jOI0ixi/z8gMbaHIY5g8by1Bueft6nYiaOwdNEqRhxarJKft1mok09YS9KqQdcQbLkRpEI0Sogn/xYuPA/v/1PId8HV98DX/8C6bvk0jvmH/wjrr4KBzVa4n/w7OPyNl/+AQq1ZMqPt/fbtr/yO/ezuIVunOXaftWjfQfhhMKyYOWbNBcDg4uHik6VAjiLz5iLf1n/DKNvoEeuQSJJUOcos0EEvGXKMiu3MmXFyFDBAkyp7xC1McuoV5e+yVo4k0czOTGPCCJXP4ChFGLRoVEoIsGAyRwAxSVRfDcaEMRgtEBrCVgtjpE3vxRYGouOQRx/8Ftddfz3Ky7C0MMPI8AY2bRglTCvdbaE1WiOA8ZUWQih2dktOnzmBAaYzOXzfI5PJgfLJd2QJkvTHjUzau0zaxZNaCazliKOIMGySxBFh0MRIhyBOSLShJ17GRC0+P1dgZfEcK81uwvBOnNMu6uIFSksV1Mh1/ETrFJvSoJ+rvg9mT9k6x7H7rTU4v9/uxF/6TRg/bAP2g1+2wL83/SI8/Wl49u8tuO++P7VCC3Znv+WHLPy7ugSNEozsssIrpLVOw7tsckAq69aVZ//pDzj9ok0OzJ62AMHD37CB/9RxuO1H4fkvQu8Ga6V0YmOiS1bTN1RVjbvlj7FL3MBh8yinzEFexw/zc86fYjBkRZFbxNuICJgx518Wd6wwz1lziF9Qf4bE4a+TX+du+X40CV9L/oo94jYeij/3ivJ3WSuHEIKVUgPTWMK0qggSgmYdkphssWhTd3GEEdIWy4TEIEliTSuMIDEgBQmGBIkxse0EcxQjgz28/s7bWKmHLM0P0tU7iCsTwkYEFkmF1mAcW+so5nxqkabQ0Umhe4A4sSjdwEDYDGxjExKpUnfJ7uloY4hjTTNo0Wg20+AVWkGTbC6H6zg4JqHUrNEMIuIkIaRCZAwnmz6Pnp+mUmsRxQa3o4vExLhRhOvmed/YEMxMwNRL1mW6+m3WapzbDzf+gP2gi4fg7HO8LJBu1cDNWiKDjn5olqzQtyvk17/L9ll864+swjz053Dbj9j3PvbXmIVzcOv7rdIfvd/2XlTmMUhqbpHEQBRGcP4kcuAs3bd9EHPom5jyAlz5NszceTizH279EUSzCg9+FINCGBAnHkfphKbfxZN7Ip42TzDx0gKllsu4F+GGef6o+eu4xqcumzSSOv8t9wfksn0sxXOElX5cnSCVotE1xCcz++mZfpDtV6xnwNvMkzPPIzIG0ePy1U89TG288Iryd1krB0A2n2P95nWIxBCELaRy8DyfbCZDHAUszc+lFWWIjOClcxPMLlcJmnU29XfiKZ0yWNjKdytMWGm2uO21b8TzMqiWZmR4iGZkLKwd0qalxLbbYtGc9cCQy+codHQSxQlhGFhLICVKCNvsbxJ0DM04oVSpslIugTHk8kUKxQK5QpE4sSwmjhDUw4SkGaW97hrTFlAEOtIUOvO8521Xk/U8pFQ04wjPcfEch7l8He/Y/7T1jWzHWnDduz6NBb5tsVCHv8lqCrp9UZsVmDsN7/iwdZOe+BtreXrG7ON3fwiOPwi3fdBal75N1i1TLnhZJobW89nmfm7Jb2X7dW+hlDR4odjg+w5VeXz7B1luhJwbn6Izl6XnXI13Hfg9jg/cyszQvZx8YpK5+hXoaXCOPYVS4KqrcNjFlmKG7SWXK4XHo/1380LnRbzl43R/8XbGp5qM3Px9rPcDpl86zolmlkW3g1rQRCYamc2TI8LUyrhJCFKw2DlM38Ag0cRhfta7k02DHTw6vkjnaIu/7XwfZx6cQ58Qryh7l7VyCAGDfT2sLC/hCEOcxIRhhOO4ZHwfbTT1hoWKZzI5Tl+c4ujZ8wShJg4brO/NkwhSUKBCKUmjUaevv5e8l8XJ+KhaQDGXIajW0+q57QK8lKpGSsn8hTPs27cTaQQ518WXa01PBkGsNaVqlVKlilQOyvEYHtuIQbBSKrFcrmNkEykVynFw3SxtRIttoLIxUhzHFIFMI8Nb33YPo7uvRUpxCZuObQ9+4OSnGH1sES0E5QTU1AlLQjF3DrwsjB/BuDn00iSt7AB+UiUxGQ537iU0EvPCcXTfJgiOI5Y9RDNBrcwiVTfiwW/SmfGolwy7nC5a5RpPnlrhyNGj6KU61d05jlUKHOiJuK5P0lSCzsY6kKdR2U6CoI7fMUDfUB9DRR9Rvo96pp9TtQyfee55Lq7UUFKRz3rkPB+pNblCgY1dPu/o3cce6SA6B3HyK7iuS39vH10XjsHB+6gOjLJUqrJQj+hb38vgviuZFx6tWhmvWSJo9LJUWsF3fYoOhPUyM+uu4P7ZkMHJ00zWHQb8AD0Er7vrDpxtLs8fO/hd5e+yVg6EoNVoUikt0dXZiasU5dqyraImIVonuK6Di6LVanH24jj7rtjOyRNnGBxbj+t5xGEIaUus1pqXTp1mbHQMt+isQsurtRqWLMH2b7Qz9ms7rsY1TVrL85yrLRGnWagkiYm1YG55CY0kWyjQO2ihJdVak/mlEmEcW8iIkDjSRTkOQgrCKLKcSlJitCFOQpLEgh21sC26Dzz4CI0nj9FoBszPz5HLF6g3moyuX48/do5ESwLhM3/rv6b7xjeipJMWK1cvIK1mjUcff4ze6S8zvNTiWWcv2tg4SiwLHNWDKvYjlINMs2bOYkJj/DQ9WzeyQRWZqsKnX7zAfc+cI3EUvTMX6Mt5rHQPEGzNcM22EepH6sgcEDUI6yVU0mR5aZGC6sVow+mJcfbPZ+hfN8SeXV3kMh4DPR30dubRScy5qWVKK0t8+7GneMtQBAZk2q5cLtXQscapLTC3vMCGbXvZvHOIIzXFwZ715DOK8mSO5cwgmUyJZv9WKokG38PP5tHS4+lOw+RClfcM1NnUV+JZKRjpzpOr/AsFHtreA0Mmk0Eoheu6dHZ2EoUBUlpUaxDFNFoBkwtLVFoN9uy6gumJaXZu3cLKwhyR1piUuM2iXBVhGOF5Hq7jYUyDxcUlij39KZ0Oq5B3Y1IGEa0Z2ridghMydeIQEcKyjEQR03NLDIyM0t3bR6lSYX65RBCEGGMhFL7n47qurZuQZpKx8ZRVMKsQUgqkdMjlcnRLQbgS8vef/SwzoUOms8i1V12JTlokScI/fP7T3PC2HsIwQiJwC70sVmKCsMXMUpXIGNb1FMn6LlpIBobGSOYctE5I4gjluniuY9ECSUKSaJSw8KzOXI7lpTnmSnNE05IwaRFWmoyWBTLfSZwkZKolrlc+D55r8Fgp4eDFZX6aJWJfIzNFxrYMEkYxCIFHgpCSHj9HfPEc6/KdyO4hRkeGGezpoksotmU8RlbK3H92CTdjr0XGVSgJ4xNTPPCxvybj57nr5uvJOwm18RdxhUO44WbUo19FlxdYHzeQcYiqLDAzPUNzZRFR7GZ493V09PaR5DooOhmWOuB8IUsyDMVCjmwheSXxu8yVQ0ASxWR8j2ajifYTMtkcGFDSdnLF2oBUnBufYvPGTWR8j1w2Q85zWDFt2LrtBQ+DkN7ubnSSELRCXGl7D/xMxiJwLQvVKkYHsOBDLfjS0QXesacP5UjCKCFONEEYMTA8zOC6dQRRTCsICaIE18/Q092D7/s0G00ymQzGWNbCUrlEFMcUi0WEEIRhG+qtVhWo3mrhSNicbeFrQ84kdC5fRCmHKI7YbBbZ0HSQKdjudz/2SU5mHiWKIl48cwHleezbsQUhFUEU8R9+8C30ZDNIWSWT8dOuOEmSaLS2m4ESmo5shp6spG9dN3s23EYhV6T3xZNMLkfsHunkttoKDePgSMVcPs+2gqSjI2JXV4n3j3Tilw2D0QKhztBo1Gy9KQoQSYipzrNhKEuwfBG/ktC3XEFVXc4vlziXaG6/5Tr2Lp4iarVwCj2ooIquLKCzksDxIU7o7+0kDgO6Ozo5PjfB4c7XkH3mq9yULBMODLNn13ZO1Mr4uoyfj+ktRoTTB5GzEoQD9SbHlc/zve9lcC9MVqfZvW/TK8rf5a0cgE4ihNZ0FAtorYmiEKUshiqJQzK5AguLJerNJq/dcwUYQz6fxXMV2YztFU+wAL8oCunu6qLeDGz7a5paTZIEY7RlJEk7w6wbZvE69XqNcqBpJgky5hKPS9HV3ctiqcL4xBRCKfxMxhYgo4i0cYRmq4VOEhqNJhoIgpCVlRKO4yAEeJ6HUirlxzLURYaa18Mf3FRddfAQF9toe8woyNYMBQdmVQ/Pji/xYnUJqSRSKVyhOXb0GAbIFDspV+r0pelpx1G2XpICLqSUSAQmjujp6CNsNMjmiySOQ0NmCBKYml8gKU/ylb0R37lselqgFgCj2XvwL9pnufaaddu59w0/xjsB8eJDsP8foXrAZshu/SHElhsRwzu4cfqbMLYXdcVd3NqssJI8xZMCejMQBbYFQSpFZ3c3mdoKyUqZxtwcp2vj6OUqUbXG3PwUUdDCKxSZXllBa/A8l1YrQNXrRMLjwlSD3sTw1HPPkYv+hRIs2IDY1pSbtTIZ37dISwk6NugkphXGnL04SXd3B71dHTiOi+e6SMdnbrnMwsoyBsHuKCQvIJfPUKq3yOayxHFCohOiOCKvJIm2MYdFzqq00i5wHUViJMXuPmrjDlEYEWtNMwxxHJcwrFFvNunp7rHcVq5rFU8qHGlBkHFKdBBF8SooUUpJNuOlwb9CtxU0k+VL3rsIm7UUwq5wHIWUavWcxcgMP3j4CR7f9aPcmZnnNTpBGkOQxBgEuWyWjkwG6fmEzWUmp6fpFl7K86XTCr1NVEgEQhqEUETSIe9lkMol1NaWVsOQMuD1DsOeN1jYysnHbY3iijttLeTkYxDUEVe/zRIdnH127Xe87p2opz+Fmj4B7/ktOPKNFEKfwNOfsihiDHLuFFz3dliZQky/hMhfYOCKPq64+7VcODfF4tIKxgj6+wPKjYikw7qJZ8sNVHWCielJm9yQMDm3sGb9SdPrUhKpPK4GYcAVUMj8C0XlGmMoFAr4MiSJExyZUoJKgUk0M0HAsy8cYWapxC0334AQEs916O3Ic+bUCZr1CoN9PbZLz/Psru64uE6dODY0ajUbA9itGbDuWruiTZsowViCL0cqZCaHEoLIBCgfgjim2QpWs1BSKhzHppsBtNFoA1FsAY3r52a5cmFhNc7wPBed6NV9VqSoYJP2kqzWEaUtIraVV5+rUlzK8SZ5nnd3dgIORifoxKKHlRK2d+nKPSyHVcIn8hQWK7zW3Z82cgEdHYihIcTp05hMhs7+fpLI4D78GKXOLs7s3Weh+IlGKw/u+TV48WHYdqvtG7nzx+HQ1+GGd9u08eJFCwu5lH9KSOgctDxV9WVbiMx1rvWXGG1rNEJYmMr0S5YxpdADN78XUf4cSigynoeOY7RQ7H/+BaqF9QjlgOulNda1eFHItd+uzUBj0t9TKw9czzJnJgGt6r/QVC7A4lKZgm/ZP+I4QmtDGEdgDCfPnKMeRhgM+UKBVhCSz2bYODLM/ulpctksjWaTxAQYgxVcJenqyOP7LnHoEsexZb1qu1lStq8kQCqQOi0jJmid0KjWOXfhArnOLpxMjvnFZWIjqFQbKOVQb7SsAGPdpDiOLdOFgX0Li1w9NWlJ0OLYCgJYKh6t7WNSWioeYxlU8DxLq2mJXy1JWxAADpn5Z+yxouif0tvccw+UyvQvL8PtPwh/9mfs0+ftc1LCv/7X0Nlpydd+/MehFVou3NH1LN7/IN9cqtOr54jDAJnrhjiwbbXKsfSblXl44Su2Uh5HtpL+7N/b17WXMdCqQq4D6ku2VhI2bT3H8W0l/8Sj9rVbboLn/t4qWaYIN78VrTWu5zI01M/i/AI4imqjTj0nMG4O0dmLmJKrv5VVCL2GW0Os0itJKSHbgchafrKBrk2UJteIN75zXdbKYYyhFcfkPAfpOEjpUKvW0NKOHOgfHmNjoUCz2WB2ZpavPfJVXnf9DXTho7G8UwXPQzgerutQqddR0sH1s0SJIFfoRAiD6zjE2pLAtSncRPq37fNrN0uj3iQOQqIoQGPo6+3mxLkLLJUbFieVvlY5DiIdkQCQpPUZI2AlaMHP/7xlDiyV4GMfg61brSCHoeWPesc7YN06yxa4ebPlpjp71nLh/uiPWhK2xx+3JM4/9VNW0M+ds+9tK4iUli3x4x+3hG0f/jDkcpaLCiw31uioZT30fdiwAX7nd6xy/NzP0XX/l9lXO0Rnr8sPb3XQZsniq0wCRlkc1/3/3e4hT/6dtQSOD1Hw8h8RYwGJr/0ZqMxZlytTtHiqRz8Ob/l3lpNqbB889Wnbu94oW+K25Djlao3Fl87gK49mrYrjtFheqbKci9COjxrcSHb8MEoKJIJmqwVGkc9nqdXr9newjqPd7vo2YrIFlFKsX7eefLnrFeXvMlcOODe9wEuNCtVmQK3eYKC3m927tjO3tMwz+w+wafMmMp7LYmmZ548/zw27thMHHkI5tiFJa5Swrs/+J1+gFUdoA0pAq1EnTmJG1g2yY9dOcrksst23kO48ruuiw4igVufAgf1s8ANaUYTvWkBjqVInwZYCJS/vPYe1QqEQApRAuhIGO+CjfwrXXQ/3vB5uvNEqymgfvOZa2DIEf/d39rG7boL9z0GjBq+/BWbOwWcegX/zc9BYAtmCP/szawV6c5YnFyxhlpeAqYMKQdehoGxFtL8P3vcuOHQItm6DvVtBNEEFgAE3Yqwz4qd/5IehWbY7/fNfhNoMeK4NVnQC9Tk7uyOoWOsltEVNhw7VUOKLhPOmm1NHZtDzjxJ7OZILLxAFLtEXvoGeriCn/wo1vAPx+GdRy5M4Jz+PXH8lQ911LlSfxlnvEDo+C5UWLpbRPogNywFoYXA2X4d78QVU0EJmMzTKJRtr5DNgHHtbJ5AECOlh1l+BllbsHdclm/sXGnNorRmfWaRUK5HJ5MjmO9i8fRu7d+1i//79eNk8M7ML7NqxhUJi0ZYzkwsMdQ6QINGrgabAcxxOnTjKnn276V83wvqRIaIwoBXEJFETV7XRsib1ZhI73AY7DMUnwJEGx/HAgOdnaAQRsTa2JzzlgrKDb6y/b1gbKKMcByOBrgaUfw3eXAL3JbtTz33OukrzBkZKsPh5uLmUtmE8DNsegdIcYCCM4J4WlH8VrmtB5TF4ewVqH4bvL1/SzwE0fwPurdjHWv8J7i2B1w9DO2D+38Iw0ATubkH9eXjfihX8+q/DT94EWzfDzLMw/UXYXUqPHYCbgw0fhOlvgqnB8Aeg52pYeAamvgDHFJ+a2M713hxn4k4+21hPMF8mDOeJ4wJKFFBLEb67k8yKj9+oIEQ3yG5MQ6OPL9HTETL0/n347gxVHbMUCwrKQ6HJdxRJpEIJh2jb7VTGrkA0qiSyndzQrEShBUTqGCeJyFTGqahOzOg+YAUhBL7rWpf6FdZlrRxtWMXQ0BBxAo7nodwMQrnU6i2MMTRaAc1WiOd6iMQQhxFCpiA2YQkVpBA4SrB7zw62b9tCR88gQ4P9tFotllfKVFYiokTjpp+HTDFWqWC70vD9e7upzNfIZFwL03A8StUGhjTr04ahC2Gjd227DuMkIQxDDAbXdekjAjeG4RFQOWjOQLYPGhMQrUChC3JDdhcXAoZvgeqzoEqQHQG3A6qnQVShuxe8HnAakMnZNtj6WXA7IVgApwndroWK54fACSHTASO74fg/Qm4UnAIwCyaCrvTC+w7sfCuc+B1Y/16IroT5ByEEFrBBd1cnLCagXXAjOP77MHAXLPvQWmFDMkOXbrBFGd6aH7ebRr4HOsdg6SK6vmJTwI5Ka0wgutahy3Y8gRjYyXJco1Ml3FRc4BPLeSK3QJAERFHCltIp5NkneOHqe2j6Axi3N3X5AKPTiM8mJ4RwqA/twwgXIQ291RNIoxFC2VblV1iXtXJIKXGFYbCrA+n6hHGC50qL9HAUrqtItMPiwiI7dmzhLTfcwbq+IYTjWlpLrdHCVp5RLr1DG9iydQeLy2USnVi4hFJIIVJUrcBogzY6lXO7r4RhyHBeYhz7ujA2eL7PzNyybdkVl2aSDBIJwljFiEJaYYDrumSEZF+rCdt+Djq2QFSD7BBUXgSVhyf+Iwy8E5xhcC7C8nNwYQoaW6E8Dd3vBelD8ig0p6Hn/RCVoQH03APdYzB9H+giLH4Oeq6FuAp918G6G2DhCIx/FeJT4F4PPe+CZg3yz0Lt/rULn18PtbNQOw0Lj0HXPqscLeCUALMMRz+y9vqjn0xv/M3qQ2/uWExvNbjOLFj0770/Y8cO6M3wjf/68vikcwDe+kHbtqtj2HMjX8tfZFbF/Ej3JEcWRpiLWuQ9F92TZ7Q+S4d7niA8bzcxoy3SWGITAnFoNxc3m1oQzbQ3QNP4vG3qQaaTACN4GRPMd67LWjmMMTSDACMES4sLKCXpLu5AGcOm9aNs3jDKs88doLOQpZAt0N01ytmJBYRasV86nQXY2VlECsnIunX4fgYpa8g2AjatOZg0Z2pTt+1GJWsVjI5I4pgg1iRxzGKlRjaXpRGEqVle69eQaSrYaAs9iaJobRafdbTsTn7yj0BlYPBuOPkHcOUfwUUFz33y0isAz/za2t3n2wKZViGf/U3SLwC3XAP+CPS9BZ78WzgVAU/YfvK3vxtWyiBH4cgK3JCDkR+ERMEDfwaDLvSKtUajRgC1qlWGRgBuFSIXotgGyjf8oIWpP/Vpm7m65X0p8fOT9nQ2Xm2v7eN/YwVTYBusLr4AD//VGm3QpR5NdRE+/2sQNe39h/7CkljvDSgIyX/fPG6ty9VvhSvfjAiacP+f8u/PfsG+vn8TvOM3LN3Quf22Nfc177efW1uGb/xXfrHrx/hk15tZ8XLW5W5f41dYl7VyACRRyHXXXsnicoXpmVniJMbzHJIooKOjE4xhbGQdWzaM8PzBAzQaVZAOURwTpTxQYRwh0pqC6yibF5drMUZb1myF3KZPVy+Z1tSrNabmFnjoqQPUm03q1RWu2ruPINa2T1tYZbIvNyhpWQoNtq9AGYNQikRbHidMAknLQhqSZtpkZPtBuOIu21J64jE4+wzsfaPN5CyNw5Fvwb43QdewTanOnbbn6GZs7eHzv2pZxm99XyqoxsLNM0X4zL+zzIVhE577Bwg/abNLSQTlKOVTbgO/joM8A4kA7zjc9RrY9odw8TAc/xTs/4J9abZo4e1dQ5b5fOakJWoY2W1pfy7tbe8chNKsvdBRC4Z3wtBOWywsz9qBNn0bYHHc8mwN74TREnDANrYpbRXz2rdYYoiN11gCim//SXr8HghX4MRDcOZp6OiC9bvgc78EN/4AZtfNeNMxImkRzk6mgbpBX3qO37Eua+XQxlAtl+nt6GBsaIRt68e4MD7O8wcPk/cVSgqKmSwz0/OUlssM9vTS350OgcH6/lKAn8sjhfVAhQAlRYqhsi6U1gYU1lqkr0k7lRBS0mzU6C3meM1Vu1kulViqVDh1cYK5SgPH9a0ytCfPirbbq4ljWxdJ0limw3WJr2+QzN6HbsyDXEHoR1A6YeHoN8h1b6Vw/b3w+F/D1lus0O+6y8It3vQLtu311vfZzr42UQGAl7cK1qraoluu0yptEll3Jd9jd/Kh7fbvxUPWeo3use9fvGD/dgyCl7ENU6YBCFi/G7wO+Pxv2+lKA5ttoQ6sxZg9bZVFuba3ZPfrbU9Ju8jXXsuTtntQSKsUb/p5OP003PWTtrB40/fD+BF7zK/9LvzA78HMv3/5MfI99rjlOZg8Zq+NSC1e1LKEDU4G3v5hu3ksTdjay8Rh2P4a5JQBLTg1sI8R+ShBq4mov7z78NJ1WSsHxjY4JXGEEpDNZTl3YYKTJ1/k7W+5m1oz5MsPPUErTFDKZqQ8z7UTYj2PXNYjn80wMrzOFhG1sfUGY/G3WuvVIlG7SmHSCU5CgOPaYLHVbHD61EkazYBavYanFFs3bUBOzaejmdVqxTvrWxr+OGUhcaSl+FRSIaIQZ2icrz18hPtP9JDtKBKGC/zqXYJnDl9ky5bd7Fk4b4VzecqSFky9aOsA1UUrBFMvwpln1lpawbatCmmVpNhnm5lgre6weAGuf7e1QFFg22S7hqBjHRS6Ye6stWZbboJnP5cKXHrsddusO1Sdt5/dnyqHELZ3PVOEjdfaHvAksu7QwJbv/Bkx5w7Yhqp3/zaitog49ZRtssp1wc3vtU1ZLz4M66+0xz77LEw+CXsvOVDUskoole2FD+pr5zl/Dib/2L5mcKutsPs5+1y2w14Tp58o2835a97BoPxzFhYW6W/+M8znEEKMAZ/E8u8Z4KPGmD8RQvQAnwM2AheA7zfGrAjrw/wJ8BZsCPkjxpjv3mWSLmMMrVaLVtBKQYKGDev66cjsZnhwkPLyCru2jFGu1fE8jyCMWFwps1QqEYYhYdDEcx3uWTdA0KhTqgVsGBsiSavSruuuuldSqXZvE2CpSHt7u3GFoVmr4bkOtVaTQrGIdBzqoWFk3QCxMURBaOeDO4qtmzehpGBqaspOnh0dptFsMtA/wOLkDAJBI86xZ8/NDG7ax5986ouEehZhBO7EYbjhNtv3LRU89gl40y/ZH7tj0Pr1jfI/JSEIm9bPfudv2EanZz8HO++w/vZDf2H5brffivjq71mYR64T3vPblj93aAdsutZamsf+p527d+kKGvaYYK1K2KbPFFahvvkRWyl/52/YHvFLlRZIpMd0oPjriXXE/+PvELlOfnKswvBbfsIqQd8GqxQ3fj90j9iMmzGp5fmOeKC+bPl+7/xxa8GOPwh774ZCn702I7utS9a1Dh77OGy92bb3brkRHvpzTOu1iGoZ5S1hdML52UVK5X+emCMG/q0x5qAQogg8L4S4H/gR4EFjzO8KIX4F+BXg/wLeDGxL/90I/Hn69xWXMdBsNmk1G+nODFnfozg6YplJPI9dmzaku7dN2yU6wSQJSWJoBk3i2DIIPnz/t7n6lrvwPQu+09pOoxXY9lmZkiDItpkGcn4GRUKr1UK6Lv0DA3iOhzaCpXMTlEsVjLKNTJbz1nBxfBKAJI4R0mFyepZWGDK7uEy+DZTy8lTlOvKhSyQz4LgMihoj9WnGP/9fUYOb6TE1lPQxT30G0zEIRx9EOhk4/jAM76bVbLK8UqLT1CmZDA8/cpjccJ2o2cSUm8hMnk0Tj7Bpucqjn/4U73nPe3Cuv9cKV3XRuhw3vNsqXVCz8I9Liabba+KIrWK3apZp/YWvwut+Bo5+G84fhH1vtj3oSxPWrXI8LhXqFe3SFC5nMpswymNDUqZz5jDVb/4ZDO3EPfY3OJV5S5jXvxHzjT/BLE7D/q+gt/gkhMRITrjrObfUpPXJj1Lt3YGp7secP4DpHLJKuzQJmyctHOVLH4bSNOal/4LYfD3c/2cweYwXqyVU+ARqLCS5vcmRk2dw5uf/6XdO1/9r5TDGzJDOyDXGVIUQLwEjwNuBO9OX/Q3wCFY53g580tjUzTNCiC4hxFB6nFf6DJKwxfj4ON09AxSyPvm8T1dnF0kUIZQgCEOSdNJr2wpYHKEgk8mt3lZK4mX8tXpEG05wSaZJG5MOq1krDWljaEUJrTAiqTfI+j5+3vaCC5n2kCuF0y7+pe+TUqIAbQSuspdZSfvs5PQMf33kITKFXoKl80StFi6aEIe/aO4hF26l5ua4ODNLNQoJoxipu8kUhxEGCvl97Fq/jlJwhjvrz9JvqjwRjjDc6KBShUBvgJZDEF5k2M3Tk+tDP/JxarvfiFAu8viDqBcfRVz5Zmidh4uHLMtKZT4t8QjCjnWcbTjUJqpEX/sHrt2+HvnN/8bc9DzHklOMmi78Bz5P597bUZk8PPp5iF2kUYjHPkfSMhQNSGLySrGZRRLtstWpEKD43EWFnJvn1p5dKDMEcxncpSVi1UEjfztLjZjTSZkz/cf4r/fWOWGWGS8FeKrE0oI9X3MNwEqb8Aj4ur3429pBY5WXsSOaEruEwOtSCCcmqDe4ZvuVnD76z9gmK4TYCFwNPAsMXiLws6zRHo8AE5e8bTJ97BWVIwwjoqhFrdHi0aeeZd8VOxgZHiYIAoQ29GSL7Ny8nvGpacJYE4YRYRxbGk/A9Tzc9rirdJhNO9qW8lJRZrV3vI2t0ilfrjRmlZnQVW3rpIniyPZjqLQ6rtQqfKQ9VNNRisSI1fttddyqJG+IG3STpe4p8gJK9iTwfDtl9q8+8zl0Kyb2M6AEReXSkBongZZQHN6ymfdcvQMv9qFVxWCo16pIaahVK0zOLjGYncMMQjEq862Sw5898wS33nI7o1t+GsfLQMsC9tTgdjAxm/Xj7HTOExhJvW8bXy2t4+j8OMtPL/KXE4/RoRJmdCePH3qRa7dvZnfQou/E19euowRMCOefXIXEZwjoFgG/mj9grzOghOHHr+5HXH+vHZP94F/C+DP2GLlueNN/BCfDlWov/Ud+g9C0GBgswu6b4cQjzGSGeHbFobOri4xrLfb4xBRSKnJZ31p6pWgFAa7r0Wo1CYKQRGtcx2G9O0Tzy5JrRoY5P35JYuM71v+xcgghCsA/Ar9gjKmISxx3Y4wRQryyU/fdj/eTwE8CdHV2s26gExOHXHvN1Tzy9LO86c5bkWh8V5LL+AStJkoIO8cvmyWTwr3bs/kazSZBGJLJZEHY4ZlRFNFqWSJqmVoSK9RrkHGJha/rKEIKC1fHaOphTEde2cRru502RX+277f7CISUKANJ+nwClFyXuwqKnUSY5Wn8nKRbSo5kMuyIPG666Sa+feAYY11ZRKuFm/WJsVB85TrkfZ84jvFElf7+brblNrH00iIZaTBJgKMUeddlw2A3vaZKGM5SaiQUBjazb9MdrDgxzx0apxmF1OsNtIF8oYAnNO/I1iiaGpVQ4zo1RkeHOHFxmmJnBy/JIV7jTLPHbTA4GtJYeIrRHLg9IzYob9WgNGUzVV7WQk2WJ+188doyrpuxowwAlId77T3w1d+GfA/ypvfA5CHrznb2wcXn4cAX6f+hj/CBY9db8rnmAty5Bcp5LixWmT+fp9KCzo4ijhI0JycJw5ihgV5iHZPNZJmeW2Cgvx/XUcwvLFGqVBkbHWZraZiXTpwhO6AQoeGVAt//I+UQQrhYxfiUMSatxjDXdpeEEENA26mbAsYuefto+tjLljHmo8BHAcbGNhgMTE9N8ta3vIXdO7biKUWSGJR0iCPD7GKJRhDYcsUqucCaa5XP5ijkcziOh5ACx3HI+B5KSaIoSb+HtAwfq4QKBs91WJieojQ3Tb1eR6NtQU8poji28WgaQ6hLbJC5JFhuFwJJU8ahMVSQRJsU31oJqVcrbN80Qm8WqlLRagUsHnmcX4oO8O+u0ThSImVklSz9bkYA2jKxyFPncKsL9BLzy+6TICRi75sxI9chTj9J/swUxThi0IkIBjMM7FuP5ylKD3wCU5mD278f0TWEOHo/tfNHOLaUJcw1qNcCRFeDnp5+OvJ5lJfjS7KXojaUmhG/eyrL9OIyn3jTIHe84xfhwJdgy/WWTO6W99nA/LYP2pTzVW+FB/7Hy2lLvay14OVZS2ma714juZ49ZdPDjofY/w/2dhTYTNiLD4OU9Ndq/EShg7mwjKkaMGByGpM1oBYw225AtqqI1nlonrb9MYUs3Pg6hJdFLF3kSucI0i+SffsdfPWrX/2u8v1/kq0SwMeBl4wxf3jJU18BPgj8bvr3y5c8/iEhxGexgXj5fxVvgE21GqMpLS+QBE12b91ErVpBKoHvOlw8e45qrYpyvFWWQiHEGk8V2HhEG1trAFqtEOVmiIwApcjmc4jSCnb4rMZxJY6jyOdyTJ47zeEDz666aZ7nQzrvL0UWIoxYi3VW+wkuUZD0dhRFtOKEZyd6eNP2Wd5+g0Hg4zornC91MlXJ47oO+7ZvZGT/N5D5LnuA6qIVpOKAzQQ1K2uwCOECDRBQECFsuBp2X2P5bO/8V7DwPJSqZBWwaTvrGsfh3BnQF+Da22CkE05+C97xr0j+5ue4qlHjhDNCX0GzJBVBENHVkaexZNsEjFCEUZMLU9MEKkPSt9GmUI9+yxYsr3itraEcvc8WK62g2Kr1pSsJAWFTzZm8Tb+uXlPb+UkSWsrSdm+IkNaCJBEFo7lSSMinCtVOAEgF7/wZyxXcuwdORHDoa/a50T1w2/Xw4kPQmIb8HHzfB18++/w71v+J5bgVeD9wVAhxKH3sV7FK8fdCiH8FXAS+P33uG9g07hlsKvdH/58+IEmStNYRUanWcD2fRFsAX8bPMDM7i5/JQDoyDNrC2BZYy4QoHZeeoVEQLuOz8yyXqqwsLVFaWaSjUKSnpxs/m0XHCcKzNYvuzi5a/f3Umy2iKCYxCR6Cnv4BwkiDEDhCotJEgB1r0M6arSmFMbZPO5vL4WjN/vkizy9uBGPwHcVVe3Zx5PhJxlQDHEkjSCxl5jX32Ivw9GdsIa9N3Hz0Plsp3nGbbRJ65OOXEDfvhZcehnPPpcTNW23qFuzOu+VGS0qd7bAV9JOP27pFq0YkHJ7cdi/j2fXcPfVFJparlMtVBno6mV2sWMI7BYlOiOOIKIxRk0dh24BNpW67xdY/1l9pLcHFQxa2cf7AP/1hwxa89IhVJjdjaxz5bkuQPXPSppp33GbTus9/2SrY3jfa+slLD8PMCZtBA9tTMnfG3s512ULhl3/Lwklufb/tVMTY+k/X8Fpxde6MrbJPHntF+fs/yVY9wcvRMZeu132X1xvgX///9RlAMwiZnV/hxZOn2bZlI76fI+O61GoNlpbLIBRJoolNarZTfJM00o7CEoJKtc7Eyimefv4I3Z0dLC8vU8i77Ni2g53bt1Kt1hDCuj6mbQ2EwXccivkCjVZAK2hSrVYYXj/G0sIKOjFoYSwk3rR7lC/BZ10CTVlLkKXhvnDsc8rFyxaJE4NwbVPUzPwC+nVvRX7996FessWsW99niZs3XG277vLdFj91+Fu8rBbQpvMEuwNfymH1wtdsJbt7GN76K7ae0TUMr/1JeOgvkRj6rn0dOvTILX0LqDG3uMiW0T4On7yIjiKMNLSCgCiKGfM1u/WUPQ+E7QiEtHoubI0GUuVsZ48u+WWzBRi63grqkW/a0QbVBXv/Tb9k6ysd/dYKju6xt7feCIe+aguAhT74u59fm0sCFrOlY5tSDur2de3U/MVD8MkP2Wv6zl+3Fs8vWEvyCuuyrpALIcjmO1B+hm/d/wCjI+8jny/S0dnBi0ePE0aWlE0bs/oPQKYs6yK9MJVymWMvHudDv/TvuWbfHiamZujv76ZRD0iMQSkXISTaJLTzB+1JtFGcEOsEYQyFYgdSSpqtlq27YGdsCOzgTOm6gGUkNMK2yLYRvu2GJ4tol7YxCGw8Yyx0JYpimq0WslWxEIuoZQU8bNpiXd96C/uIozWc0qVr6kVrcebO2Or1oa9bOMeF560VaVatcrUqNlB++4dtwbC6QKIN4xPTiJ7RVYFaWF7myh0b0UlItRnSiOuoOKDPiRnLagpeFq55q7Uap5+22K/r3mnZ18sz8PRnbXGvY8B+TnuXdjO2QPn3v2p3+7s/ZN9rtA3ou0es8p54xJ7zycetRVh/pY1BCj0wf9b2nl+6GmV77M51MHyFhdjkuuxjg1tt41Z10W4gcWifnz/7ivJ32SvHusFeXnvbrTSaTbq7epBKopTD7MyMnaFhDLoNNY9jDBAbCzP3PA/Pcclmfa7eu4uezg58z0MpByEckqSJUHLV/hnTHk1msFlbbaluXA+RRJY5JIWbtNvOTUp4kJ7x6v/bsUeSToFqIzIMpFBfias8ctksQlnISRLHyKnj8MBB9G0fBGMQj/81LFyE17zPHvnofeBa4mZ70mvXKz5/iPLQNci7fp74hUegVIUrr6U4c5a4FVG58cdROiLz5D8SbLwDV/uoq96N2flGkic/zdimzZRiB5NESOUSRAkxkr6uApGuUXa7eMvICncM+DjC4I/uhN13w/3/zSrIzjtsofDxv4G3/5rdlfe+waJtZ0+vnaibsd+lXW3382vzCwu99l+jbEcdrExbgOWF5y3s5db3w/5/sH3m37mCOubgV4ju+TA6juwsxC23WoU7+bi1kkLZTeT8YUT+K5i3fRh+4y3fVf4ub+UAgnqVp595mnff+07Lcuh7zM3Osbi0TGI5zZBC4rsOGc+32RzDav+2AfyOTvZecx1+NvsyZpFVF6j9wnY6VggsL1ZMFEc0mk0IA6Tj0tnVjTczj5IxOtG0qT5FehCTGCvUxmaroijCc13bqZm6fkYnaANJElGvVylVylxoLeCu0+wLznD6Apw4/JsIIRgb6GS0PyT/9MeQponQVdsrrYrUCsOYlQUCleeC7mabWeRvDy5RvPgS4xMRyDtRj13k3lgwvjTOU0tP8MQzx9mx90qmDy/zmotP01XMUl4uc/LiIAONxzhz5gx/tgPrLmpJvRWxYWSYpeoFHhI7OazHMCamX1f5UC6HW523LorR1v1ZnoSFc2swl7kz1mK8DAuWIpHbMUKzYgPuTNEqzORRG0gP7bBgxc5Bi7Q9+xxccw+llmH61HnEyOtREjwFExOTJK0a1x+6nz/fv8JMSyGiXuITU2gzhaNc1OnP2elTYRNXXYv/fIP44JdeUf4ua+XQWlPM51hcWqKruwdNgu+6HD112FZFLym4JdrCvnVKjAZrnu66vn6GB9cRxQlKqXS8gGU1lI6ywTvGNr+k6dkH7rufuakp6s2mLWb5PpnOoh17pm0WbNUWaBvbaL2mGPbzxeo5CCFQRlDwPbK+x3KliZSgEaANF8stzvXl2VVsEMSa7VJRyDgkMmZuNkCIGkpJfC9ri6OxnfHdkfV5MhqmYTJslotMLldR9YQoAaUkrSCiRkyl1uKx589Qb4U8+chDVCtlXnrSklZgNEI5bNm5C4Fgfn4R43SDgLnFFTatG+TwiQsERjFLJ4kCgcJMHrRu1Xv/wPr4D/+ltR7f/3vW9YlD68Z8p/sXBxYX9c7fsHHSk39rQY87b4dv/aEN2N/7B/b9F57HvPEXiK95O2f6e0he+CrPuV18YdHB6eiip7ubvq4iomMb8xfPIXKKE/Uc85EPKZ2rY8A4FskglUJTJOf77Nq2hYzU8N++u/xd1sphMMwvLNHd001XsYAColaL6ekpi6Rd5bS1TH7tDGq7G6ONsPV9H9/zCeMGKqW8aQfNay0vli1dKYXnKMqlFUqlElJJdBIT6ITefI5yrUqr1VqtYbQdKqVUSgqtV5kL2+6VENZ1E45LpAUibfn1PA8pJT3d9kf+K2J+XD/PTCT5QmM9e3tafOmU4cRcjYyXpbu7k3zGodloEdRr1GLNdeuz3LppkO7SIiDJ5POMDI9w4vQZojhiqVJjwW3yxt46O/2jKUy0Lax2FgkpEYThOaQwbI4E47IXkCwsLrF7ywieq4jiBCFcHCHxhUQ3a5z50l/QLAwiWlV6c12E3/4bdLbLxgqBRDz5dUxhO9L16GvO0KpXabkdDDz/FU4dP0YUa0xtCS0UweHj5IMWO778OxxR6wmW5+jKZzn3336TbzlbqPzC7bzpjnfxyT2P066aLGE4I6oWXX3LBv6TWE/SJiQGXKH4yd47+Pjy47T0y3s3xsUSN+VfjiC+dF3WyhGGEdoYhkeHiY0mk/GZn1+gUm+gHAfPdxGqTWJggwCtLS9uW0DTwGB1xl87c6SUhZhb2VhjCclls2Q7C+zdu4/pqWnCKEZhe9ONhuXlFcvRm5iUQGytMq6UJJ0dRZIkxHG8Os6gXcgTUpAIi/r1XJ+uji4LPZEOCBchPK4cEXjDGzh77gIX56YwsaIVVxF9HSwvLyKjhM5chqF8Fk3M5kHN1j6BOmdoNZucPX8R6fv40mGsUOCI6aCVzIJvG8CkuHQeISAsjagwtrB5WipeNCMIoai3ArRQFAs5WuV6Wmy180gCHD4RXcnZSi8DxTw/9va3ghJkXQ9hDEEUppbakCQG57E/5fyLR3m0vp6f9g7w0blBSomHMetJtG1K26Tn+Tf+ef7dSzED/bu5NtfDpBej1/Wwp7CJ6wpbebR5hqzwGPV6qCZNKkmLI60JNnp9VJImAsGdhZ0sxjX2N8/T73XiKod9+TEONycIjE19SyT3dF3N77+C/F3WytFmRt+wfgPzc0tsGBrihYsTFutkDGEUYqI2EZtJh1OaS4TdZrISY1IBtBARkxac2rGCkHYKU6KNzSYJget6xLGm0WzhCoMiIZPNs1xdwvMzxKSFLCFWmdPbOiqkwCQGx3Xw8HGVQ2LaFXW52lQVJwnVagWEA2ldRiBYKddIchd53ZUem8fWE7RaGC3IFwWe02tdQiPwPI/ujix9BcHK/mVA4Hk+V+zeybGXztqJV8qhJns4aHpAJ5adUYAk/a6WExTluDZrJxVCWCI6FUckSUKt3qKnq5Olcn21mIr9qiwsrzCvHK4a7eWBR5/guZPncIpFsoUCyhg8z8ETgrzj8I5qCYwhSjcW1/UxwgMpcITCwdAlExxnnOHBdQx1FNg6fZRbbn03x3MFxkXAStJgJW7w/v5bmIxWeCSY471dN3EimOGW3DbOhQu8trCLF5oX2eIPsJLUUULyzs5rcITihcb4qnz5wsHhX2gPeRTFGK3p6+3nxOmzXL13NwtLyynBm7RBHGmhLSVLIEnSardJKR8TEJJGo4FSchWqrlPrYuVVWTKGdG5F2x1LjEZjyPg+uYyL5/uWLGF1JrmtxhshyOcyKCkJwohWGKIche86FLIZhIBSvWlrUdksyrEI4Fw2S1dXF0oYIK3wGwgYYGz9Ftb1TbN1o8JxsmAsW7w2ys5BFA5IRagzLFV9hkc2UJtaIkoML544TWJE2q4rUuiJwEiJ69rZ6ipNJctUmdubhFRrcZwWEiES5hZWGF7Xx/nJOZLkkvjBaDrqU2yUdbblNvLgY/cxPzGF6epmZMcOTBSB47A8cRG/3uKukWU2jA5hLqZFSyHsdF6hECptGCP9KwRT2udL/g6GFuqokQyLusZyXGc5qdHSEV8rH2Ypqa0isT2pyEmPvPR4qPYSEqt0/U6RYbeL/7H4IBFrMBZ7+5Whf5e1ciilEK5LrlDk6PETzM8tIAxkXY8EOx8jSl0X1Qb9Gb1qNYQUSCOp1+t4vk+j0Vx9rp2Jclw7tMUYbYNyo9EJ6CRBCTBJYtG4bTdNCNaPjjI5M02t1iCM7VSpPVfsIgpCZucXmJmfRwjBlXv3cvbsGbZu3cqzLxwiTDRXXbkHTwkcz+OFQ0e5OD4OmNV+EhBEScT0hQkeONbBQL/L67adoTdfw4gi1WQ7xUIV5XfTjDIcvLCOqYsXeENmyrYAC8nO7Ts5deYs8ervnl6PtFtRmzWYi9Z6rYclNQmXNn0JYHGlxNYNO3CkoJW2/moFvtD8yuA4jjeHd/YCbxhKYAighmASXHswsYFUeGF+6/Vc052gzr3I+uEBlsaXL4Gcr+HjqtUSyy3JvuuuBymITUwlSehxctyQ20zLxEQkRCYh0BEf7LmVG3Jb+MvWw0xEy/xE7x10qSxfLh9iNirxtytP897uG5mKSszGZQAik/Bs49wryt9lrRxJktDX00XQCpiYnODMmTN2/IAER1i3AsGqFTCrMUfq8yfW8nieh6McoihcZQNJdEISr+0cbcFpxyauIykWC9bFCJr4bg4wRKFmem6eWqNFbKzVCaOIYy+eQAhJK7S8vInRHDx6lGq1SrlWJwgitFA8e/AImYxPEkcMD/QxMtjH9MIK7Z4SYaAZJNSWDnPNUJ6TC4M8XqmjXEGHU8ZxjiG9bqqZ7XT4JUzjSW7ZUqV7aYkZLE3DyVOnSbTBSIkxa5ag/T3bimG/s0oLmam7+bLJUKANlKplHOXiOgLdjInCkLpqUvEEH8u9iR1btnHi0EuMbN/OurFhevp7cdTaptSVzyMEhPUGAVk2cRJ5QeL6fhoSJrZRWazVnFrNBguzJV4or1BQhvj6EXS8nj86+mUcBCf0OZKiQ1E5fG76cTa6vTy3cJxyfZKvZKbY5o9Q0S0mW/N8pvEEC60VPrZwHyarkA70n01oTCzzuP/IK8rfZa0cQhjWDa1jeblEtVJmcm4enU5xteafl+2AL/vhsXxVjiPwfdtEn8QaO5tCoqTCcxyUkKtbpRKCer3J+OmTLCzMEYQhuYyP9BSdHR00Wy3COKZSraWkCVa4hDE0mq12IdyeO4KgFeBIRZAmFoQwhFFgFTNJWFleodWoW9dC2Yo7QqBxeO5Ui1OTJXo6Zphvunz2aD/vvUow4FwAOcvXjh5h40iOQibA8zK8ZySiC4EShu7uTprNJrUgSsnt2k1cIJWwJQchkGBjL9sMSRvlggCpJBib2YviiCAKGR3spdKaBaFxlIOQiqrKc7KimVE5enIdrIgs8xXNxPw8XbqF52foLEbkizlKk7OsTEzgz5xk1As5d3Ga3s4CyxU7jxHR5iiGeq3G4uwSs5MTjIyO0mF68GYbzP3ZAVQYooo9vPs972bjum6csI7RMZlWwO7nvsGZmz5EvdBlScfDbutWt3p4/tAxAqWpfl+OK6vdLJ1Ypvnduh/TdVkrR7FQ4HV33c3s3ApRaN0n13HT4FWs7oYvsxrtFth0pJhu0+Fg8/61aoUkiS2KV7a7B60w+55LrVrhmWeeBmNdNa2t9XE8nyiK/+lJGmNJpFPXpF01bwMObYZMknJ7ssrojmFw3YCt46ycQCQpz6wxRLFhainhzIxgsaSp1FdIdIXP3G+F1lVVfN/BJCGd2Zirtlv4vcGxn5LWaizbSsrhK0RaMBVoYUdBr3pT4juQxWkMkqwiAGIWV2psGB7i1MQ8Wkkc5SKlpLK0jBrdw61vv5ldA3k6PdBCUBos4hk76Seby9LT3YPZsR6MJjr/AurLB+jPws59W3nsmedJkgiER0ElKG0omCa9soV2IV4cJ1gpohq9mLMnETqhd9e1dOuYYiIYG9tM7OZxqnN0PGMY6l9Pq3sMR7kYLAWPMbB72x4++nf/k1ZT8tRzJ3Ev1G3Q9QrrslYOhCDf0Uk8s7CaiVKOWiuqKbVWzFuteVhCNSkEruOidYLv2xkOSkoK+Wzq165NjW0H9H1d3URBjVw2i07idCKTHVfmZTOsVJsk6SyNtiDJtIdcpAJJkhYBDWngn6CctjWzj5s03byyUqJaLltFjhPCKKZiavSYmM1JTHcxoXNQ4TtFklhjhIWNA5YeFWNjr4slTs0I+kY7kWhKy8uodABmmy2ediaNtQavdmzRbhE2Zo1V3iYE2++VTM3Oc/2+bfiOJE5imxEEmq06rclxwoV5dvjHGKq8gBAw9h2Y1LViKIgkRpgmPx0/BAcf5g7XwMgmuOuncJQk80SFT0fHSLS1+GL3a3n45tt4QEzwX97g4TTKuN0X8AZbqAd/BT12JfVbfhTZWEAYQzZfQOSLKOVYDjKTFm0Dh6uu2stBThPFMUqD6/wLzVYV8lnymQyLC/NondBsNfE8d5UKp60gbZfBKoax+YjVbjxhsVTYoqLjOLZgZGxbbTbj2xSqNOSyGZxCBtfPsLK8RL1WJ+MqPD+L62VotkqpwOvV/hHAggzB1gku+U8nCYlJycO0QTkvz40UCwU68lnmlsrItIXzNOu527vIz+zpWOsoTH2d1TqNfRQ7d8lfLTQeMUMYBN09XRRyOS5MziCFs/qZIrUSiJSErp32TjsitU4QicSSTqy+i0QblpeXcT2fYs6nGcarx6wtL3PopW/hej43bitz9bCB0d0W+7QyZXFSwzttpXzhgmUGKfZDaZqOlRROLwTc/kNw7KsWFHn7j9I3/cs24MkU4a4fpnjuKzgbBukr+LhGwZ3vg23Xwzer6JMP44wfRBhDku8l8gokiUaKFPcmSKdXSfr7B3HUeVs01glJ8i/UcizML/HVb36d0yfPYoydzZfP55FpZ107w7GacQGgPaU1XsteSbVK3tauJRhjCMOQOIpIdGInOukYI22nX6PZpN5sYhIH17M7WBTFq8jftSLj2o4IAi2s/26Mzbw4QkJKwmBBjbbrUAiIU95d1/WsyyMlJ+QeTurtNOMGSRLZLFqaclYpgBEMUjqrrpCSNhWaKBdjBAvLZWrVxqqVWhP09AoJgdYWSXBpzaL9V9AemWBxYEJAEMWEYcLoun6WKq1ViMxKaZnS/DJRFLO0Lgfv+m0LU7/xB+Chv4Q3fMhir3beYQGI7/5NCx9/7vMWVAh2jG2x3/JjRS3bKejlLEldsQ/WbQdxAyTjNn2/6y7b87F4AYSkueF6lu78RYwB7fjEMoeMIqIgbYSSayMh+gcG8ULPfnNBmpT57uuyVo5EJ+zZcwWTF2bQibZDD6UijmOS1JVylcLz/XQ3tMUrtBVMrTWxTtaKf7CKqAXSjFaCTjTSdVIf3FqGOIlxPZfevh58zyeKIprNVrqbryklWHIFkxYm7UpTw6mrpVcft0F5uyof64QgZWBv1xiEVAiVxROOjXcSvcoEfmnA7DguUq0piDbY760TfF9xxY7tHDx0lCSxPjxqzRWE1IKkAmNSbJgRWEKJSyZEtT8vSQznLk6yrr+PA8fPslIvk3Rrqs3mWjKiZ9T2UnzjI7ahanSPtR7f/IjFWoGFmX/9D15OA2SMhZErx/L3Ytb6UqSC+TPw7Ofh7nfZDsPtt1klWbcNXv+zyPEXUX3rMcbOXRFxZHnEfIubI7WYQRDgeT4uLs1EY6KYl28bL1+XtXIAZPycZTI3luRg65atnD5zFkNoXaPIKs3qmOS2IBp7/VzHXe2/lphLAvRL/WwLL2nPHs/4PsV8gVYQ0Gw00InGz+YIwihlY+cSISOFo6dYqtUglrSdltVipVUagTC2Kt3d1UnOc5mYmVuDswur2AoHEtDt0Thp45bFQNk0LUquWiMLfkwwBurNiOcPHVsVCkO74PkdrbymfaHarb1mlfCuPYDHVn/s50/PzrFr0z6kDllYmCMuRnRozaBn5x3mm4uQ77ICvPEay23Vt9F28Q1utdchqL+cQxfs/dmTcNN7rdKsTFsk7u7XW3h6HMH6fRbNO/0S7P+iZTN813+GJz6JGdqbbn4GdAoqtWYTYdrtzKTXz1rxxKQx1/9COy5r5RDCYni0Tux1DZrs3LmdVhAxNzdtvzxWoFNnB60NcWxhEghJR08fHZ1dSOnQUewgjjWu69hMFMY2JqXAO6ks7EMnMVEUgLGBstfRAQiU49pmEbOmICLtJTcpRH51121njNqQEZFYwRfpDBCjKK2UaLnp7nbJd0ZY/1hqBRILpEuPT1o9bicVEGpVoWxMYnCEYMuGDVycnCBOW7PtlipAr7GmoA1KqBTEqdAifa1QiNVeGY3SCqEVzSgikyswPDhAhRbSXeSTt4TEiWVE7HaXib72B3DF6+DFRxAXDiEf+HPM1psxT30OliYQT33WZo+EA9jMWJIkqCc/DXvfQCh9ztz3D2iZh/kWppaBL32c8ZtvpDp1lideOE7W9ckXc4xdeBG/bxvBup0YYVbrNW0OZKFU6j4ZpIGgFTKzMo/uNizXG3RpQT7zL5UrF4uLMsZCOBqNGq6r2Lx5ExcuXgCT2J0Ynfr0a7v52MZNbNi8lb7BQRzXpd5sIIVguVQl47kEQQuBXO09T7Tm7EsvElQrEIc4StGRz1HM22akcq1KnKScWNp2+skU0yWwadN0E6adCTLGCqxOlamd5m2vgf4BijmP6YXS6owPIGVCkSDbO36aLm4X81I8lBBqVZlWU8VpsG0n0Uo7VVas8aPYNK1EapnWFYB0wGRbyax7Z8/doR20a4s1C2LGRoZ4vtzgD+PX4IsELWIKhPy0PMgnL2aZO38YKQyj69/F2+54E7VGg6T7CuTm19tazrXvJ9YQJZrezgLf/PrXKBQ6GTp9gtHFQ/yP8DZC4cJyBWOuR08bqifmKO/J8ufRdfiZPoZ6t/JD299MzzXvte3NcWLjtvRCt5MzwjYFAAbf9+jp60dqQRwnTCyukPf+GbhyvxfLpOYxSWxQWa2UqZRX6O7qobOjk2azbqEMWqRgvBQTpQ0zL57gyInTdsxyJoMEkqjFYF8vhe4+brruGsAOLxFIdKI58PxByouLGCmItSbj+UjlkctnacQa5ShkpDGX4I/arpBJIShrNQ4blWtjMGKNDbGN/hVopmbn8FwntVxydUdvK4BQViiFFqs+lxGrH2hfI21VWaaVcJRBJ5qJiUlb7U5nkLRDLdO2UlJA0nYLZZrOli97bXqBUqtie2am5lYYHR7k8MmLLJuCFT1l6CAgEYpZp5dEw1Y9zXrZSeX4kywsr7BUrtoRDBqMVOQyLgM9PcR93Wz3apx76SiJKFNwI+7oj0nynTB3FhO1wBiCRo5Wso/8nlE8L0dBzDHw4pfIDa4nyXVjZk8Tu1ma2+5aTc0brW3SMsXMCSlR6SY01NvFXLZMvf7Pwz7yz7+EQGEr2EEUEgQRYatJ4DQsV67rIHBshqgNIdGaONGcOnmSSrXMO995L1dceS1d3V0sLi6yY/NGjp+5QC6fhUUrXK6jcJQiaIVUGzWMELRaLXqKRXTQoqOrg2q1Zj2bS/zUNuOIkCoNXIVVBOuxrLmzJo1I2gNzpMBoQXdXBzpOUitwaUoxLUy2fWRpSHTaE7IWUmFHXK0RyVmXzVqBXbt2UimXmZ5fpE1T1K6Ct2MXnVZBxMsc7zSybxcHLzkPIzQz84vs2HgFGd8hiDVGSIwUCGOD26VSiY3xHB9YNwVzJ2HOsKl93S69eGD5MIF1wI3tDXzTtfzAXfdaVvdgI3z99+046lIRmlfBvgHYcCWceBzOfBu2/gKUx8FUCA98kWjbHUQmZGG+TCsIWTc6Stb3VlP5MrZutO+5bBhaR7lS5pW6yC9r5TBGr/7wcWIIooSjL52mu6efqfll1vXmMVqgpK01aK0xAhwEW7duQ+uEWq2KAXzPx/cyNrOU6HTXt70YxXwOgSGfz9HM5YiNsQGu1kRBgpKKZrNFHCWrAX/bjbP9HGsxQZppXd15pVI25kjz7KtKIKCns9OSZF8iMKs9Ft/l9ne+pk0GcamrZp+XnD9/kSSJU0Voh/vtQNy8TPjt7XbBL51KJaA98HOts1JQrlZBKjryWarNkMS0W4XtZzvSIpQZ24e48T12lsbjf2NrH1ffY9tgn/msJVhYt8220B744toF2/N6y/Z+8SD80EdsG211waZ1H/pLy9f1/b9jieOuv9cG77On4PwBjFFE2qbuK7UKQnlEQYjriJTsGya//UWC65pII3CkpKuj+IryJ1/xmctgCaFQroNB0jcwQL6jk+eeP8yp8RmeP/4S9VaY+s0CkgSRJEhtMElM3/AoN950O81anTgIIEkwcYzUGqE1ChBGY+KYnOvQ21Fk+9atCG2QscYVgozrkM/4BI0GwliKUMfYdKdIjyO0SY9nUNjdRmqN1AkKUMYgjYYktu+DVYjLidOnuTAx0c5zrX5vs/q/NDss2ly/9olLjcylGSiZtoGCsBOwXCe1Wva/l681sObq8cxa/cZcehKwCrNpNhrU6wH9vV20e8Uka81TAwNDXLHvWrj7X1smxJVpqxh3/Dg8/WlLh9POYE0cs+2ya5+ypgxxZOl5sh0vP+1tN9v6RnnGspR4WcuWeNdPoJHUag0azZjOzk4KHQXCoMXS4jKlUplGw3LmOo5jPVMpLqmP/dN1WVuORMdooxkeGmR5UbN16yb6ewcIHI+FUo0nDx5n37YN9LgObzpyjGwYpIKl8bJ5PNfjitIKXSfP4Gd8usKQfDbL3lqdbDZDrtnCdWzmynUdrqtW2LK0tJri9c9fTKvwDjc3min9D3DFFXD99XDqFOK552ygDKAU5rbbYGwMnngCpibgnrdhenoxrRb6i1/i7/vXMeNnwBhGR4YRAk6dvYjdl1MFMKt+CGmIshqwr8YsglUBbrtN9nHrfvX09LJp/TD7Dx1ZTWHa411yHJEqwyWK2Q5erYUR6fHb77exXbMVMbpugBfPTBBrY5Mi6SF0klBrhdaFnD1lB2Tmuy2D4dwZWyBsMzeefnJt0E76uZTnLG1QedaOVWuWLbl0o2SLhVe+xbKdGAONFTvo58JB2Hk75WbI48/uZ+OWrQz1dhGncWGj0kBFEsfpoKQKJDKwFXOjsTQz331d1srhSIWnXLKeojPn8cLBg7zh9a9nZm6BRMfMLi6xY9MYuaxieHmJAsIOiy+XwSyC59GTz8MZSwuT9TzIZumuVKBYJBPHUKtZCezspCcI6Gk27TF8H6LEHuvS1dcH974LvvIVeOMbYXICXkrHgN14I+zdA08/bf8eOwpPPQW33grr1xOvLJHr6kOk47Izvp8Wu9rC2S5YrcE3bDFzLd1s2jOkU5ewbXQMYHOxNmifW1xiaWXRdgOuZoHF6t+13nlepmg2M5UW4lbjBItGSNJEwsTcAnu3DON5DkES20AoDebjOEKWl+z0qff8jo2x7vsTS83zA79nd/vzz0Nt0RYMv3Md/jq86Rcx174TM37UsoXc++vwD79max/LU7A4YU/80DcQd38IrnsXnHwc14QM9XawrqeLbDaLch3iOCGbydrsYmIYGBsGcSHNUsq1Dem7yd//rqD+f7FsY45maaXEzPg4QRijPI+ZuWkEgkgbTp6/yIbdO+CGG+Hee60wHzoEDz8MP/uzkM3CmTNw5Aj82I/B+fOwtARb06ENn/407NgBV19t44y/+it4xztg/Xp7/2//Fo4eXTupDRvg9Gl48kl77N2715TjyithYMAqw7e/bQPJ8+fh/e+HILBKx5oPf3F8AsdJh2saK9QmTdOadnHukiLdmgqJ1ayWkCp9RICwQizSzJknFa1Yk2ZtX7asUbDTuvUlx7YhSZohU2a1eNZ+u9aG+YVF/N2byXgOtVa7ny5NESQhG1aOsfzCAn5pGTdpknhdqHMHEYvTmKiJkC7i9HMwund1TqPRCdHyNEyfZeWzv41wff6x1E+iN8L/j7r/Drcsu8p74d+cc62188mpcurqruoc1N1SS60IQighgkA2TlwwYDD2Y3wfG3N98XXg2vj6M2C4l+QAGCFZCAlJIKHYUrdandXVqbpyDqdOPjvvFeb8/hhzrb2r1C3uh8z3lFY/1SftsPZac8wxxjve8Y4//ATd2dvp7ilT/vjDXDwzRX1sjPu238GdS5u4qIoq7yF7063snb8Jm6bUy2WiUuRpQ5YsczRbmzxy+DiDXZpA49G5b1P6iDbG90EY+oOYaqXK1q1bCV44I0ANmitrm1xZXYOpKdmlP/Up+Of/HMplOHAATp2SRXvpEhw7Br/2a/C93ysLd3ERggDuuw/+9b+Wnf87vgMmJuC//leYn5fFP2ocUQSp3/GSxC94fzQacg5PPQV/7+/B4cPQ6cC//bfwoz8Kt90Oay1Adu89u3ehnGV187jwo/x/hc7uVYkHQ/jYJ9UOoabktZocC1KIGst9997DE88cIrGCSF1dJRcUUBVKHcNOx8JhQAEd5xR/ZzWttowumGzUWdvs+v4Q/xpZgrIxXwhu4/TyXrZtmcOWRKMqispYMiwKm6ZUymWiKKBWjohsQunlz7Nz9U+4svV+xo9/kZeyW4gx0NVs1qbZnIuoNpt8+YUVtu6ocM6d5M+fPEWnWsXogMBoovARgtAQRZHMZwlDwjAiVJoxO2B1eYksm6UcyGiIsFR+1fV3fRuH37GMkV7jel3YsTvnpzl17jypgyyznL28jJuelkU9Nydb0dqaLM5PfxoOHpSd+9IlWdgrK/CZz8Cb3wz798ubzc/Lv1YL4hg2NuT1rk3Yzp+Hd74Ttm6Fu+8WD3LLLfKaZ89KOBb5uOk1rxHv8vWvw9gYdDs+DJJ23DSVVlwROVDFghwtZqKk4KiUdC8apws6jXO26Ll2eKqKR83SLOOpZ54liRMwoUDduDz68W8kniDQGoMitVlxfsId8V7LWl/FF8MaxH1Onr/MxJh0+Cmb4bJYqvmZ+JHDh57hN5/8U2695Wbe9b7v5+LZ40xNz+BwBNqw0VxjfnqeMAzQRrO+tsrrAkOaZpw4fY67raXXbnOp2aGbZKi5GWxvksULF8FmXDh3lkvnz2L8ZqGVwRhT0GxEwCH01CADmaUKqLlJ5v76d7J72zynj5+gUZ9+1fV3XRuHqIp43pLWzMzOsrS0QqMaMd2ocXmjiQbslSXMDbtxd9whHuTDH8YdP0G6dy+D97+f6LHHMb0e2fo64cwMiQkw3/8e0k4Xffgwg4sXcH/nb8PyMupDH8JlGTaOUevrhOUySalUxP0sLYln+ImfhNOnUIdfljDs2FHcQ19G/dAP4d7/g6iPfAR34SLqr30A98AD8PzzpMeOk+7e7xErOHH6FIHR+fY8UiS8GroVAephQ1eRawBFnnBVDUH+mGZZkXjniX3uGaQm4qko+JqNs2ROqPZ6pG8+R9hARklnXpVlYqxBlsogoJbtkNZTTp45S7bDcmV5mUHcZ+funVy8fIlP//lnwUPDKpDW3FpUplEvUymXCaIy226qs89lrKyuYOsZNhsQ97ucu7RMfb+hkTboJynVep211VUxCiPGi1UF7C/TJQxBEMj1MiFaK9bSlB0L0yiluOmGfSw+dpbl5b+CmYD//ziMCQgD2YWVVszNL3D+3HmiUHNg7w5WDh0mtY4DWUY5SXjsq1/l07/xm7xZwWsffCMnt+3kkUce4q57X8fWrVtZWVlm/4/8CC+fOMPOySmObfaY/ZEf4auf/yztP/9TjNFk+/cSrCyS7NtBWCqzd/d2Dif3sdHq0IkTGbJ59CQcP02gFMG+G+Gll1HO4bbtQH3tcQkFM4ednsM89DApijROUPsOEJdK5Ivs4E03kiUxLx09Jck0+Dx4JEFnaDhFM1ceVo0QJ3N2ritqL4aDBw+wvLLCleXVkZximHxorX0TmcVmLg/qxCt5+SI1Ki6BeGprHd1Ol3037KAUhAx0gnIy9u2nt62xo+r4u3ti3r1QYqH0HKb1Am+74YqfDy8jr6X2FFKJIoxWJGnK1mZAqzfg9OISU6+ZZFdtgVZsKZlloQrhSHBQCiHw9H2lCnKhA5QzhXdMyFBGgXYoo8gyR5yJZwmjMncc2M0zL36bCixobQjDUOZ4G8OWrdt4+unn2bFjnp1b5xg7cZa1loQqp55/ns8GAX/YarJvapwHohDXaLDv7rvR0zPYsTGSfp+00SCtN7D1GlmtihtrkNbqZDbFGUWaWgZZQrObMtdo0CmVaAaGdmjoZJZUa59EikhbGIXkLbJSpfYLWGXYDKIwEpWUwBAEodRXECZUaEJcIjddFEAYxvp+hguAclKwHC0WFovc5W7BP5ahcR05elR4WrkHcEMlev8i8oxRJ+XxG2nocgWhUuqGAhagLWsbTSrVGuNjNQZpRpoFfIzbmW80OajP0K2MUd2+h01TYml1jU7kx8E5S7VeJen1IINa2CAMI8phyHOpZX3r/ezUp7F2nUq1wnijwd23HKQ5Xaa1vcHcv3gAay0LaToCeV9bw7nmUHkuZwlLJWxZ8+KzJ/nOgwd4/siZV33adW0cKIUOZDBNGEZMTEywvr7K1FSd+bk5FmYmWW21AUWr2WKQZPzNv/W32H/8KE4ppmamSF3CIM2Gu6y1BSXCaA1aOENxEkPq+UlpTJalRFHAZqvFWK1MvVallzguLa2QpSloxdatWxhv1HHWsrSyyma7jcIxPTnGeKNBv99Dm5DT5y5gjOGOW25C4xirNzhy8jQnTp32yvBqWM+AgmullJYxB7JcixzMIX3hAM7XIpyVF3AjhmJzpW0LRXOf/+w5dV9CNUfiLDlpMi8CyvvkwIBAu0qLsW60WiSZZXKiznKzg1Kar+tdBFjuUlf4ut3Kic0tvH79POs77kfduZ+sHBGnGS0HyqakSUK7Vmfblq2M1SvM9juUDz1FEm/SbF/g4uY6UalMpVZjckPR/soAG0TCn8sCrM089Cx5KW6oV4Y/78w56dnxH17rAaWvr3DlQobadRv7di286vK77o2jFEUcuPEG5mbGmJ+fYzDo02q1QRm2zk7z8pkLKKDRGOOOu+5BG818nKDiAVEUUavVSFr9Im6WOFuQmnIUYbQmyTJi3/qZZhkhKeVSibGxBt0kY3JigqmZGU6fv4JbWsai0NYRBYZGtUwUlVjf2JAwBNi2ZZ40SdjcXOemG3dx9sIlEmup18o0alWmJ6c4feECWxfmiXs9mmfPX/2xwdcO8n/eELTyJYWhoAPKhz9quMvnL7Jr1w7qlRLPvXgEm4lHUKNFr5HQLCfq5SGZ6HfZkUp9vuh8wp9m9JOMqYkJggvLhXie1gplodlu0y13OXPhRaobLRYGbV7YaHJkbi/zYUqlUiHNLOFGm8HXH+fOG3bQPXuIhYuHOT81jwo0B/ffxOraKpfWWrhEUT8R48CTS70In7UoZ321XtjIOdkl73fBF2+tFxvXvlD60qkL3HPnba+6/K5r41Bao4MSYXWMMaBSrYGSOHn79h30Bhm1cgniPtVqhWa7x5WlRfasrbO9UWV5bZNWqwVKPqZS+cWTJHNyYgxjHLV6nbXlK1i/yxgjszLCqMSg02QQ93j55Dl0WJJwA4sFLi4u0R8MsJml3e0IXo/i2Knz2DQhSQY8+9yLsnMBjz19iEa9jtGaVrvHDbt3EWq8y8+XnRuJdPxvvIHkPKjR8IvicR6iZRhkLC4uUjKKLEsJjIecrSvGNEBeIbfD5zoxSO3be0cPjfdU/kSuLK9RKZekUSyzQ30VpYiTlDO9Hp27/xqTKuWFboe9dz/AnXPbOVC3mFDjMkeG5vTXO/zh8XP09DTR9jewo3MaUJTLFXbv3M7ltSPiFUYYxQoZOYe1Asv7RS9eMZOzNYHXG4g86wHpDbKWFMvR46d5/V3f/arr77o2jigwTE3UeeMb7mfpyiXa7T4uS+l0WuzdvZ3+IGVhZgrb3MBllsXFRS4uLXHy7Dluu+0gzeYGWZZiAnNVrK0QGnxoNOPjNXbs2sn5Myc98JMRmhAIUFrT7Q7YaLXp9Aak7S6pb2bSWhOnCSvrmz4HUWgnvRv9fl/aW1H0BrG8t4I0tTRbHTkJ57iyuorK8hBK5YF9UTeQGoQUqhTK93PoojgohT0fMxXJiis+Y6vdpZkMcCYA5bAuk97zvJDhRbCx1r/KMCEfKkd6XbDMQ8Vu2DW4vLLKHQf3Uo6OM4gzP/4NcNDrtLm0scSuW+/krlsP0m5uMD01iTExiTVkiSMwhnJguOm+13Fp8RILO/dQSjqsfOa3IHM88/yLlCODzSzO64OhFVp6OsnFEzD+MuSETAw5v1JknOS5Ls8JEVGJdrfNSydffWbr/4w55AZ4GrjonHu3UmoP8GFgGngG+JvOuVgpVQJ+H7gHWAV+yDl35pu9dr/XY2Vlja986Yusrl4hKtUZDLr0OoZ2c5O9e3cxXqtilCK0CasXThM2poid759wikqpLAgF5KhnAYumWSrXVimclcap0BimJmWAptGaNJPW01wa6FoGLAx7MZw80C8uqUs48OHI1buwAlZWVoiCcDgJF3yF++qCXoFCOYoFO0y7cyhY41w2wrcSesq23ds5efpsgexopbgxu8iUbfvHO5zL0JZCPYXck2UUnKrcGJ0OYG4nLo0ZX3uGnZeu8Hp3kpYa4Ca2YiZmqa2Nc//EGqWt0zSSi5gLA+YHG5x+uc0ZJolshmu2KM/MYmo1gjCkFEacPnuBxfOneS1dqAibWAcRpWxA7PLzchS6wrL+PLtgqMuVt0VbX6txXn0nh8AzHGQW51KeOTRS4L3m+J/hOf4h8DKQ0yd/Cfhl59yHlVK/Cfwo8Bv+67pz7gal1Af8437om71wqVRC64BLi1eolg07du7i2acfZ9Drs7R0hQO3bOHgvj1w9Bi9Xh9dqrB1zz6CYyfIt2ClzMiUJ+d5REPlkBw6FY2jjFD5QpK1PsGzxL4D0I5WkGGEkDdEj5yT1tskExG6XLBAm+EoaJD1fOuBmwiU4onnXhp+6JHy9FU0da6Oplzxd1cU7tQo2uXkPRbmFzh/abFYPOB4YPASB9JzI6967bu82s/Ag39HptYGJXj2U/D135fh8gs3wHt/RsiG87/AD/zJv+IHbr9TpHW2HYQzz/IHH/offH55gUArSkqTra6iTEAY6AKKTrpdBhN9qIBCc/vtd1APLV985Bms55o4paS9VzBnvwH5+6p8DccJPeTa/nnp4XdoDDZzNJsbr7r+viXjUEptB94F/CLws0ru1luBv+4f8nvA/4EYx/f47wE+Cvy6Ukq5b9yKi8MYjQU63QHVakWoxg6SNKbbaRMPelhniYzBZhmPPPEUqw89wk+6FPZvpxQFTE9Pcf7ycmEgWmuSOJHOQe8NMi8xGpiAyCjW19ep1RNmtmzzo7GHCz8PgYZ9DkM4USuNMwaXZSijMVoRmIDU2UIg2V838VgmYDAYDPOLgnAoWdGoUsroOtVaUeiD+AUyWmHPoa/+IOaxx5/EKoWJSkPqidaoO9/lB11+DV78ggza3HWnUMyf/CPplRifF9WPi954wzLsuw8+8r+JkMJ3/BS8+Hl5fxNKjrJ6XijqSR++9JsQRPD+X4RnP8Xq8hUOv7Ti6e3yksJ7Ev5TGBoWpmfZVBomZVM5/PJRts7UyVyKcgGiFzRiskoVE76sTWXh+zmPBTpZkJ1znougfzLc9NWPb9Vz/ArwT4C8Y2Qa2HDO5XTLC8A2//024LycpEuVUpv+8SujL6iU+nHgxwHm5uawztLp9qgPApxz9JIBWhsOHztJUGlgjDQrta5ssrK+zvJmEzszIWFFpYQJvvEjxoMYnAi8uSwFrziijYGkR5JZKtUqaWYLgzSe4CfdgMOd3fkCZaFwomTHjkyuzOg9S1GmzpNgePnYCZHd8fQPqWdYAWrzx2KHBqN8SOjzAnztokjS5aQKr6KMROfOi8ppnxS4hRvh9u+GL/zfftDlG2Hva+Cr/x3e889kuOSd75LxzqPTVqMKoCDuyBuW6sNBl1pDUIaZXaCMsHFBVEhaq7B6ljRJ6bQ65IhDnjPkCoxxnHCqf4mViQa4irCA1lfYWF3GeUlVZUxx7XNCpkSVUiVXUHDNCgPxEYRTV4F/I8DHKx9/aeNQSr0bWHLOPaOUevNf9nWuPZxzvw38NsBNN93oFJrp2RnKZaEclKtjTE1Nsdnp44B6KWBmYozsyiJhuUI1y3wZS1GtVgpcv3h9HInXisqSPnFXiHJKiXQPWpMkKUEY0en26A9iGZLj3bPRmoxRNy2rcnRoTtEHjqcnoUaKDHn/OVQrJeLBwHfe5Ul1HhdxVUQjCfswqFKFwNvI09zwsQ5Ron/NnXdx6vRp1ppdLw5hpb9ic1FCoKQvHmPlrNDKuxviCRaPwbnnuWrQ5aArn6MyLq/Ra8obl+oy0++pj8JTfwxv/wew43aZeHv3e+Hh3wXneGBe88/vigRRKoCDa8JTHHfMxFgqPjTUzMxNo9MBVzbaIu+pEC/rDUQh8HF+6ZS/fjmTwCJiE6q4UIp8anBm/2pYua8H3quUeidQRnKOXwUmlFKB9x7bgYv+8ReBHcAFpVQAjCOJ+asesgNaKlHIoNulUa8xNz1No1Zi785t1MtlNh3U6zXBvzMolcrFjlCv14hTSw4v5uFRnCQkccLDD30JBk2yOKVWraCATntAnGbUanWavV5RGRbxBJmoVNwENezQy9fmqCBaLn+TJ9UKNxRoU5ob9+2ltbnBevOEX9gCUaqixCffudwI/c4nodEwJc+Pq3IaZAG2u90i7NBKY3BE5w/B7XfDB/69GMdDvw3v+Fn4wX8L9RnRkWqv8Q35RjqAlx+SQZcmwH3tg0PP8+yf4t76k7DrLlEpfPrjML0Luk24Ikjgrpkx3jZZL4xanF8e1g7fRpuAL2fbSLVci/mFrbzmlh186GOfI3GekDrqOVwBXfjXs4XR4a+5s4EMRy1yRN/e+016Yf/SxuGc+2fAP/M35c3A/+qc+2Gl1B8BP4AgVn8b+IR/yif9z4/5v3/pm+UbIAuuFAbUygEuqmIzi016HD1yktnZabZv2yXqJDZDO8dEELJ1x27uqUbESUyapCgdMTc3i1LC0gQl5DqXsbK0RL8rnWgmCDAosiRjZmaaUimkt7aB1ooc7EJprBu2hWqfEmilUDZnz8qZD/WrcgTI/1iEZOIa4hHl9pFlTU5Dyf8iN9X5Xu1cNd0jNwyNUyslMnBKgda8cPiIj8HlcZNZky39M5z6xG+Qjm+FzUWMcyw88XHCiXnfeTcDxx6DPff713WsrW/QbnfIvv41OH6CuXSNK+0BT5Zv5XVzA442p7nyoT8mq0yQtVagt0DqwH7iEdzgdgCWVINlGh7ulYp/kmUM4lSKdP7zR6UKUVQWMiRw8uQpWutX/LReRLLI53ga4X9ZRCUlSxMpCLo8xzReZT3DulERbeMdz6svwb+KOsc/BT6slPo3wLPAf/G//y/Af1dKnQDWgA/8ha+kpJlndnaWS5fO0+12WFxcRCnF7l27GPT7hCagoxX3uoxPjYXUsw7VtQ2uLEyzsryONgHWWZIkIwg8ic4v1mopRKdSHDNBgM0y4l6CCUOiKBJaRZKMOGM/Jo2R3uMR952HcNYO2bPF3BCuCe+c4tmXjpD0B+TQa56WiFEMq9FaK085HxqA5Dra5yGvgGIpL+2JV6P305yMsyTK8CFzLxudOtbcxO133sNb3nAf041a4eGGIYrQa449f5gXXnqJ06dO4TqO96VPYpzhuWSG+XArq/MZz710grg1wKoxUBNYZ0mTFKem5BorRWD8YFGvbxwYi9NWKDLeGwRBKEOKJFOjP+hz4VIHp4xA2gwXf567aGM8LiGbhnj0IVLlcrTRDjWWiwv+Ksf/FONwzn0Z+LL//hRw3ys8pg+8/y/x2mgjtYBypYzShiAw1MenOHn2Aq2NTUqVKp+rNKgbGTMQjk/Q1SXav/cHxP0ejfEx7r7nXhbmZlHbJfbUWhNFIaSRKIwD/TSV2oQT5KjT6xUzObQ2RR/FaB/2aN4BFKhYEd7Yq71G/nijFTu3bmHx8mUZ3XZNfqGuuWnFos/pHqPxgE/w8/bX/KWsgm1bF9i6MMuzL7zsB40CKJySKa+9xLJzz06ePnKMpdV1BoOEdrdPlqaUyyXGKmVKUURUrVKenCZOjxfghPOfN3OOhblpgqOnSROpTjstAtc5NO2c9I0EXqhB+8Ra5zkBItMpijDG7+gWnAYNjeo4Y/Uyl5bXKMiWzpIrPrriumucTXwOh2/QkpEPWIef4ECuHDNs9vrG47qukEt+rFE6IAgi8InwWGOMTquDTRN2bN9Ob9DjCzjGDSw1O9y+Yxc//b/8HcarEZvNNu04YXZmls31DWCYAJogkDkWWhNqTWbF9ZrAYIKQWq1GZ5D4Yp7y98THrEUsM/QYRZ/3KK7u9/tc8lP+Lmt01/ZttFtNVlt+VuEQnyRXJFEqB3bzv1B4mSJcK5JNhosRyVjiOBF19vyc/OtYIE0yZue28Lt/8kkefv4InU6PsalJ2p02ZJbZ+Vnaly6BtazrkLe89vXsr1a9t/Ov4zLWN1rcuGuG0Bj6sc+pvOhcEGgfDvkZKkZaVJVS0jeDMCEyh/C+lGxAwiZW3isETExN8/Y33sOHPvYpugMLfgps3kYsYagtNMHy1t/RpZ+LhBfj1a4SF/vG47o2DgmbNTos0Wh4vVpjmJqaZHVtjU67yc7tO3BYJsfHefNr7+KJl88TlsuUo4B6rYJTmu7KBnnlWSuN8aFWq9tj0O4QBAYTGPr9WIiHYUC73ZGwKvUK5NYJQ8FHxtppX9yTm2QL8H0UsRqqu+dHrtShlfKi1B5byycreUQrBxVGESkRuBvxTDlsq7VPUoc7IlZed2VtnfW1db+AhmeiHZioxPjMJM985SGuLK6htKI36JGlKc5Bv9tlSzWiMjbGwtw8/UGT8Zv2sXHmJGQePXOaK0tr3H3zHhq1Ku1B4mU489kYqpifkt9UlSOIxogCvHLYNPPnPqIm6eNFjeLylUUeeuQxkgwPdoO3i2Eyn6NeSryFbEqSI8qcFBHmFqcr2dS1oMbo8U1y9evjsFa608YnJgmCkGq1wvbt27iytEy70+XgwYNUK3WqtTqlsTnGpua9l5HFVnCC8Ju8VoSR/B00mYNBmtEdJPQGMc5ljNXrqMKT5Dq3rvg67PGmGLWW/02DSHg6USDMw51hwVCmPWXW8uTXD3F5aUWQtkJIbSROzi/CECBjqCk14mny1ZHDxlfvlz7etgX9JQxD3vKWt3Dg4M1stjZZaXaIymVKpRKh1gSlEkG1go5KzG7bypadO9i9fRuD1iabMdx93/3s3btX3kU7mu0mKE2jUS4MWml1lbccQtujk7GGota5UeSbizxvuDyzLOXU2UtkaUbgE/ocsr2qdgHFiOl87Bw4kQH1OUeeI+Yo4qsd17XnAL9YlOLmm2/l9KkzWGuZm5vj1BPP4VTM2FiF/TfewKGjJ9l3w40cPbeMi/t+eI2InI1+/CAImJwYJwwCpifGqWkxgMw5rvQ6lKOISrXOIEnJnO98y5EPv2DdSJKde4/caPJZ5qMhzMgnGSb1fgFpo1FWZuflxcFiZ/XPyL0EOD++wGNTeV6Tv+8IrIyHO8cbDW47sJ/Hv/4sqSfnpUnKqfOXSKJJxqs1XnvbHYRRQK0xTrVaJyyXZJwbwnDV1tGLB5QXtjE/PUmpFNLv9XJHSa/fJ0mkj+X0hVU/Fs2fh847CeW9tXPcn51g0vb9AhUbz5DHKJsbhP/8zkkh0zmsytClBmrH7djuBlw5gvLS6k6HuO034WrTcPkYtNdQe1+DMqL4YheP8fUrCWfdlDcqV1zfVzuue+NQSqHD0IdWNfbs2cv27TvpPvQYadZlZekK83PbGG+MeQq6JiiXJanTgSSFvujmcKxvbDI3PcnERIOtO3dz8oUVQq95W4pKpMmAKDS04pgszWQGYO4tRmZz5OmGZphjAB7qzRctvj7iF4obegOF5v677+TkyZMcP3cZZUZKVM7hsqs9ljxHFbmGrwUPkSo1fKwAvJD53KNebxBqCSXx59Ttdtl/8G5ef+fN/OTf8CEsPqH3kv0u35qdKkwbZzl15iTNRzeKs0qSlJWNTabGxvwODU7ZwrCdUpI74whwvN6eYAfrUkUvinBKDGm0KKcNhXSOAkID7/x5KWhN3g1PrsKRr8gHvuH18Po3wfkX4A1/DT72L2CuB6GFA2/CPb1Ic/k4Z7NxgXS1wTnNN0s6rmvjcE5i0SRJefnYUbbNzLJ3303Mb9uGNpp+u0e/26Hb7WCdIgwNRmtu2LmbfizDbfLdNd8tWq0mgQkIjCEIg6K/AyU7VKVWJYpKpJ2mTDj1YZW9KgdwEsMWEeuwGJX3dBs0SZIM6x0ji1zoUJY0TQrYVpEjO1cfReztn5i//vDv2p+Hp7L7jr7cTFrtNg8/8gipzQuhcj5JltGoVllevMDczCw6ZwfjpH8q3wCk2ohGpl112x1mp2Zo1ut0m81ixNvaepOFyYYoxWQGq67ek4vXswhH68GfgK0HRQ705a/Am38UpnfC2gV48qPwph+R0Wdf+H9E/hNE+XBsDv7wH8OWA/Ca94lxgAjERVUIS2JUnXV49L9DdUKq9Ye/hGKnGG4mWYvW+tvbc5hAs21mjD07tmGCkCTeKRydTodet8PK6iphuUYUaaIgYNv8LHt37SAMQ0phwHomwsLSVJeNVGQtNk5wSUqmDOmgTxb3CHUFCyyvrNDpdNnGJgfDZT8/b4hI5fQNjSr6tIvd20nca5Uim92JrU7A5SOYdAAoXBhidt/NvlKfqfmIXa0WqlRDjU8CCh13aV06xXPhvoIxkr8+jgJxEVhSmpXcNUMuR6HmVqdHEJUkrvdmY7OYlaXL6E4JnQ64cGWZp184yvjUDG96w+sJjKYaGp54+uu8fPYS7/3ONzJRjURQO1NMTIyzePmSN17L5aVl9m0/SKkU0Es8E6DIleSbfLah2/8AjC/IeLR998Fd7xar+eJvwHt/Xhb8lgNiBBuLw8VQqgmPK0uF5lIZxzNDRVM36UPsRwqEFZkidet3wqkn5fHsKNRJtLY4p78ZWHX9G4e1cP7cRTbX15mamOKZpx7DBBGrG6uMjY3z6BPP8+AbatTrVcIw5Lab91Mti5ZT5ikffiwceaOQMaMwqUWjfeNPQKVSpVypok0ISrNPr/MD0TGGEp1D+PSqn4cp8/Dk990PD75XmK5qP3zy/wSbQlSH7XdC7yQcvBfMZdkxZydgbBZmbuPiH3yaF8M9ZCMgbmYzn3wOKRBu5PviHH2MLwal2LplC5utFoMkLYqXi5cXSSYvM3XHLehyndmFEts2+5xZXKHdH0iVuRKx0u5zww03MNYYoxRKsW1lo0uz2RyiZSha7S4mCKiUI5rdhMx+47Ir4OpSXWYDtpZFP3fvvdBc9gLSA/kMFw/LPMHRo7suBlIZh7l9osNbqoIO5TUe+0M49qhIjs7shLQPN70BPv6vi3ASD0woJw1T3+y4zo1D4MgdW7eA0Wy0Opy5cInvesc7ef6lwywszLJ3zy4sisWlZS4vXuHipctsmZ1gamqWOBb2rSB3Um0PdCDG4hxoRVQue2W8lHa7XUjbGCNjuQDYcw/c94NyA7/yO7DzDrjrPZAMxHXf8FqY3y9TUp/66PD0b34LPPxf5fd/3Q+NbC7J3LtHflfCgC03wqE/FQFlgLf+BJx6CpL+VeGTB3DJk9ThH1zxZQi8DEMvjeWeu27lhZeOcHlpBTIxnJWlKxxd+yp/8oe/z7YtC9SqZWrVBrWb7uPoi89TiiKwjprOOP71R3n5qYfp9Pqsra4zs/8g793cFCNUwvhttdtkFmqVCpq2nI+TE1M5Vdk5QjKiY1+GG39Krsnlo/DMx4XbddOD4hXi7vB6jB69Fhx5GN7/b+TnP/9l3G3fhR1bwB3+svSa3PN9otB+5TQsHITTz3qemCLzCIIADRal8m7HVz6uc+MAFJRKIWGpRDpIGKtXmGg02D4/xfrqFS5fqlCfnGK92WF2ZponDr3E1HgNrTWD/kAMBA+zaoUJAjQZ1qbEScpqs0tgBmiXEvd7pPU6mXWkzpJmGVlQhrf8BHzu1yQm3nIQXv+3ZKjKG/4WTO2QMcJP/jEc+fLVJ16dlBtjUxn2WG6IceTHjW+AxRPDhdCYhW03w6MfxLkKfoT51cdVdiH7di6M4OwQPJD+BovOHEePHqO52WTQ63N+5TKD8ZhjJ06x6/63kcxtY63T49CLx1lZXWZh7xGen6yQpRlhEJJmKS8dOUJ5fIobbryJHdu2cPsNu+ic7Ipaoz+lNEnoDRKmJsY4d2mlGCctZMAhgrZDbTDWucyhj/8OtjyO6m6gCCl9+g9Yavbobq5hXIY6+Sl0NodzVkZnpylzszMEzzzNxMXLVEzGpcUeB5Y/zSfNXVzMaqhLn8GFVWxnHRvfCac17uQZVPY6cI5FW5FhmV43ogAzXuW4ro2jgDyVuPO56SnG6nWstZw8dZZep8kdd93JzPQ0d95xjyiSZ5aFhQUcjvHxCbqDDPoyIjlNErRLyXotUp3i+h20cpgowGSWWq1GuVwmTa2Mc84yERBTGtbOCUW7Mias1bULMng+l9M//ZTEuMXhxO3P7hGDqDQk7m3MyvPCCG7/LvjzXxk+5Y7vluR00AZTGdpBHiK5a5JcRiK7kTudo2QK+RyHj51EKwlR014PN+bo93u8/Owz7N69gy0LOzl4416cVXT7Qs83vkdFG8Otd91NrVKmUgpJel2+8Gef5t1Jj4lqCa0UKRnWWlY3NqlXqx5pFurHaM3GOSFVtinxEXcnyaCEU5agXKUyvoXVYECnNgBtCG1KSWucCbAmAGuZm55GDZrEa1eIAkfLTfJPsi9wwVU4qWahr2CgybIJMlcX5MtalMuKmozLpCvTea/Gt7Xn8C4wMIo0SZid24oDoiBgYAxzc1tYW1nhja97AK00b37da5ienCKzGWEU+eqx9IAP4gEry8s8+rlPEQYaZx2lUogJAoJAE0Ylqo0xBvGAwBicUzQGa5Igvv//lIv52V+RaUQf+PeCnJx8Qnb+a8cHg7SRvvMfwz3vg9NPS7fc9/4C7o/+OXZ8AZbOiKQ+ShCc2b3y+iisktZR7fJwQIIlPA0ehdeoGqk454mv1jIUUstINq21TMhNLbV6jbJ2/Mj2Llc2DsGpZ9GnfdHMw3HDSj3gRNbGWUcqaADbtGHPTQ1W7DxZwaW1rG+22L0wThgY4jSRXm1y5ferYWnrpHFsZaPF5EKd5w4dYqnV5sJGiyyFB+cb3N6IWFUhhxJDL06oVOtECvaNlSilXWoqJ2e6AigpqDta4awW5RYUBmkkM1r7y+dp8jnZ6hWO69s4ipjVc4eM4Z77X8f66gqVSpk4GRBFZU6cOs09992HDjO2b5nGOpF+lHsrjUFplhEPYsJSyGanT871UVqjBymT9TJKa0rlkuyYShMqyx3mCicf/hRrTz8jaEi/hbn8MSYW5hmPHCXXJ3zxk5ipcfT0GJaQLEvpdPt0Ox1WP/hLDHQN1VlHK8XCB/81g4Hjk+0ZtrPEin4Qi8boEP2FQ2j1ANQ1A1MmY7jzChVFRJqH1ApXVImBIn5WWvmOOYcNHQsLO5ibHOP5w8cw1Z0cUm3u290mTcfJ0swXLpWvKnuPoVVxC3IOTO6gtNL0jeEQO4tcyFpHs9Vh7MZdlKKQ3iCWpPwV4KDUWo6dOUtQHWNu+y5W1jZ56fRZVlVIuVam12pzSEUciQOMgo1mk2acUo8TwjSlGswz5xL6OiULcwDCyYDRYsOQGYb5Gip6oZQqWM2Zr5i/2nF9GwdSD8j7J4KoTOwQtYpSxPj4OP1+wvLiebqtTcqVKo2xBmurTWyWkSSJPF8LjSRJE0ylTMmrKGptZFa1tURBSFCuEIQlVtfWWVpaYtDvYaqWP+3v4snmnA9VHG+9fYzvum+csTFf5SYGl6BwGB2h0TScxvVCLjy/xh89ukHKNrQ2vCc7w40644SZ5Z7738mRrzzCymYHo0JM3pCjAz8SOa8f5zWWvEyYV9l9ETCfS5j/zkrBTisNRlMuldi1YztHT4mowp/a+8iyhIGNSYlJrDCPA6UItKEaitgdSnl1Qa/AYh3KaEIT+PZjTeAszo946/T6BGGJWqVMs90lN+Q85lNKkYvBVyplzi0uMTk7R6fXo++gOt6gVitTCWUGY39gMFpIkuONBkGg6a732Oj0qZctc+N1XM8boLKet+ZFhvKYU4GzOfsgr8jnYIUqWNSvdFzfxqEApYvlkWSWc5cuMjdWQ2vYuXM7KyurrK6s0e50mdIi9CWV7Uyao6zFKE1sHWnm0BrK2mIUkmuYgEEqxb5+v0fDTYA2VGo10lSweosj9QzRiXLMzVtXqQQrtNsDrE1JMumX0AZ0EIEuEUYlTClgy0yXLfUe59uRVwDxi0UqgcJ5QlAl66QPOjB5ApH3izsfMamiD0LMJK9a55CqvLTyU2adV0NcWl7hsc3NomJtjELpCKUjXCnz4+WkhTbQmiAKCbznCHGkaUZqXTHTMDCBF3zTngcpn6fb7WFMQKNe5tKyKxIipYSlkC9DozXz01PsvOFmxmem2Th8grfc8xqysExqE1CKwIQohYyZcL7cqqE/06FuM+bHyzx401ZKz/45pD51sA6nc8hWGARydlaq/r7CjwJxKvYbAY+R4/o2DhgS8LSm34s5e/Ys0zffyCC1bNu+g5OnLrLebHNp8Qp7briJIDCFPqo2w266PC63aUrc72O0ItIh1jriuM9YtUxYrhAEhjgeYG1GmqYQkZMqwMHe6R6//aUex86vkKYKTEQ8SEn6MVrBrv272bpjFmMU47UA022ybSZmpW/p5wtJId15olHJaCnKOQc2Q+mcYi7eynqMXikwSgxL45m2zqIdaB8/WyfGrxRY5cjSlHaSCJVGCyPX+d4KoaAYkjQVz4DkLDItVwqOxoBTQt4zXinduRxJy/V7IUkSmu0OY/Xa0GMU4EDOEZPH9npdbKVP2Gxzp21x5KHP8lw0Qaw01UadwBjxUFEoOaev3s/3Wtw8M8PEjW/k2UPP88Y0FU/g5BxzJjA+nM7VIoU5k4ekIw3n7tWt47o3DkdOoZBFVa1VqVRr7Nqzn11793Ps9GVuOHCQNJPwKU0S0jQhsylplhaEPOWEDh1EIY2JCb+DhkTlElE/olqrkaIx2hDHMYphq2vmKR57pjRbZg2fPD7OM+dWscri3IBAaZQKcSiyNZjZUSdQAS9ebLF0ecCPvw7u3O549mLOCBWy3me++BDNdgsdlIrxXxVivq/zGFXiImdi5OuIjxjB6PNStEJtvwV304Nw6SjuyJf93D2Hq02j7nqPFM1e/jIsHhVRhG03w5GvkC2e4M/Cu7jCRDFGuhBkzt/bh1pS3xi+d96EhbV0+wMatSpRGJKkcbFwr8VMXZZx/IVDvKW0ynvjk3yi1eHr4W7U2DjtsQXu3zpGNQxEnilLOXToEGsbTfb2L/G+fg936DC/39+FmvHeICfMeMpQvmZckfb4pmKV95qPFCVf5bjujQPv7vEByfatWymXS0xNTbJ7105mJidYW75Ex88bVzhR9MASej0rUboTWNL4Al/evgqKUhTSqNfpJEJy09r4oqHc0UYUs6US88Zba1zsT3Jx8TSZTZGoNSNTmQymVIZzV9YoPfsSE/PbuNDsMWgN6NgG998AOkyZWrfQlxsUhhEmiCgAWgcBKTekF2mESqRuuhvyh1JN0K5BV+omQSRSOd2N4e5Xm4K3fK9wk+74bmi9JCgZwH3fC6YLyy/Cd/yAzAa/943wwufgHT9M9qF/wiM2ZmmEXp4LGRgTSM+8n6me90bgQFlHThXMrGWz1WF6fIw8O8rvYW5U+THo91nZ3ORQaFgzO1nfWWYyC4jDiEroyHodnKpKM2CWMTk+Rq8/YHzrAZ6PuriWQZWEYKrtMK8ZeitXtCnjV49z0hEo6ie2qH292nHdG0du/RpFJVDsumkvlXIJfe/d4Cwri5c4c+Yod933Wow2WGtJkhhlJPeI44QwlK4/Yepq8I37QRgQliLizoAL586RhRE33DhLEicM+rFv2oF33bXEO/Y2WFrKeGZjNwN3hkAZdKBRGDIlCE6lMcb4zCw7ZhtU6xVsGLDYb7HaH2OsepkffudWoucSjj6jaNSqvPe73sqnPvsFNtr9IaHQIbWRd/wU6AAOfwkuH4G3/T2hSayehaMPy8+LJ+Az/wG6m3KxZnfD8ml48XOAE82o3DhWzkgxs/ca0aKa3AqXDsNLX4B73iuUi1VPXvSJt+Qwzo8Tk5fRWqFcQOZDLuUyYbiiyJRmZa3J/u17KZci+oNUKDwjwIHyltTudOh0+xyOKlxoLFAbrzA91iAslUmThFacsTloUgpDjNKMz29nfHYrtW0LnNGKK6urlJSjUi6jul6/SwlEzLXeVclgUKe8pK7Dkw5focg6clz3xgHDD5gMYh56+Cu89r77eenYabrNDbKkTxRGTE1NgoLVtXXiJCHSJZqtNoM4QamQKNQEJsA6GVCjcCKkEEa04pROr0+jXGWQJLTabdqdDlmS4Bz86VczzjxymO9581bM2ibvuqlPezMhCERq1BhFaDSwjg5alHQJejAbGu69QbEj7KON5r/8t6e5OUvZogzay1kKJZ4CjkQhdZHnPiPiajO74f73i+Bae0UWeHVSBtz/6S+JF8mPIBLqBAhBLyzlV1AoL89+ElbOwX3ec3zHT8Nf+79gy02Qpb6ijUe9hju9tJdKYp3ztUTRY7gIhdKf0Ww2CcKISilgwxsQLkM7hcsoGq56vS6dVpOWa9LpNNF+TFmpFHk6uZOv/t4HSuNsxoUTR4nCkDiz3HPjHgZGZor7Ygx+gIj/3IVuJEPafZ6DqqKw+mrHt4Vx4AQpKZUjDh44SBwnXL50mfvuuYsTx47SGJ+gWmtgreJrjz7Bwo6dlCsVjh0/jjVlAqOoRwHVcomcgq6VhiwjjWNK5TJBtUJUrpA5R1AqEZYrBbLRDXdTGYNbblTceZtB6wYunfVIUlbI5UgvtxZNJ2NQSiQydRgSDxzzC1U2z6+wYDZBOdI0JU2TkSKeP/ptGJsXOc6ZnRJKjfshK17Tl9WzVxsGiBTn6/fC1Hbhe515FrbdAv2WvNaLn4f1y0LpDstw7BEhRb7lx6F5BaX2XSVb6i++r7M4byR+Jx7tMymSb0e708GhqFVkzHGWZb4FNsVaWO9vMogGnL1wic1mi/HxMSphQK1Rw2UObQylckk2skyAlcyHQE5BGEZYGxMaw6CzQRqmxH50G0b6yPOQKoe/CxV73+wlS8oVdJtXO65r48iZpc5aiWuVolYpE2eOchQQhiHlWoOpqQkqlSo4y+TkhMjQaEWj0WB5s4O1IdVymUGtQiWQeolLesRZRjIY0G536CcpO3Y2hJJdqJD4IpLNOLB9EkKFKbVRyQqqNitNSc6islQqrdIji4eUcCoFpUlcyIAxpiZ6tM4CRsTWHvra47TaHYKoJDarNZO2RfTkF3Fv/TF420/BEx8RkuJbfxKqDwqJce2C9Ctce6xfkpDqHT8rYdSxR+C+9zNYucjgqx9F3f83xbu8+DBsrKHuuQsOfhc8+UlsPyGtGBEo8AtGYnYYhiliGM4jbnkynuUcL2cZDHq0uwOmxuoYdcVLkVriLCaNU5bX18gWLP1MxLabzU3WVlak+Ko0YRSJKky+ABgm12kqRdAsk+FCYdqDCRnwmeX8ZSWblCTiMknFOoFycz2+YT7krhLhu/a4ro1j+Cn8zcp3V6VlUqjSZE6xc/cekjQjMIrpmSlWWgOMMYw1Jllca6IUdNot5mamCDRUqlUG7QGlUonMOQbxgM1mm212Gwq/KNKUvG3VupTNXpn/+lCDGxZSHjywScUeATNBlutJqQhcKHSNQItEsQq4tF7n2XNbMalhrX2ByN+WLLOsrjdJEksQeqjRKnbaZTbjhCe++AhOa1yqCML9NB5/gkq1ThiFBON3CJp2yz5slpJllv6gz8ZmE3dsHXv0EzKkRd/JvV/7U46YbZzf81Y2v/Ii7U4P5zJU8DaCR0+jzXmw06Rj30/LBiMw55CWMqS/IxApykMRfvEWrbAyx6PV7TE/N4s5clqoO0htw5RCahWZ+x0EAeBotVsoJ9pUuHwBexoIXA0Bj3hXrTTT43UcYJRMeHLeqzmthq+VP9fXgmQKulCKtMklWF/5uK6NQ13zjfL/ieZUhLOWMKowPjbJZqsrg+51gDGSJJZKZel38JIwJjC4NAFkt7HW0uv2GPT69Hs9MmvptVq0Wi3iOC7qD0oZ4sEqjfGUs+s3cJd6LS8+/Vv8/hfOshmHOFVl2+6DhCF0myvs3bsL03uB733LNtKpt1MbX2ULT3P8pRUWPEK2dX6Wtz74ej7y8U/65pth//eGrvO16GZRNFEZu/fsYbOfsnfvXgYO6QX3IIXSEBqR+Xz88SfYuW2W5csXZR9NBfmKVcCWfTeTXbzIYus8qBCnFAGBKJroiMw5Mpt6NcKrQ41C9lT7XdkXKwr5Ia8NZZEFvL7ZYvf8OKUwoh/IzEPthTKmpiaZ0o5/fmOP9vaALK1QFNGvuumvsGyvIgkqZiaa1HTGm9/0JuypdU6ev+JzGl8EvAZudm4YUmX+5b6t0apRN2hxnkhoMKUKgTFsWZhnemaOlWYPpxXrm5s4U0Fr7d2wJjCRmJVzMkvOet3bNCGJB0SBoVIuE4UhrV6HKIoIwhCXxv4sHEH3DO+66QK6VqO2qdlaiTl8eYwXjq+jdJfb4h6Ll86xcuUyY42j/LP3a6ajs7jkAgvjTVTaJR3MoGiIdzJaprXiFdCN84nkKPNWMRj0OHbuEufaKS8ubhAnKYnLhQcUxkOspSik3YrpuRUaOIRZ5f85x4lTp7Bef4uR3dlPVC5CpVxWxzppAtNaS3OQyueTyD3AjnjyTCjzaIVDs7q2wS17tzLeaNDpD8T40WjnWFILfM3uZ8tCz4MR1nvroYpk7qkym5FlQ5bAKGKmtSYKIx5KKzjGufXgLGcuLhV5RWHeTmg0mcqbwaz/bEOP9GrHdW0czkGSWlqdLtXGGNbhwxIRQ4iMplErMT09wXo7BmdpbzapTZXRSsaM4XcHQU3kIpsgIIpKMsjdBCRpitEQak2SiCJ3oY6O1D0ubcAvfjDmva8d8MCBHlsaml/9m3U+8tQ0T590XLh8lkYl44EHp/nuOwd89x1XCAY9Whsr/NGXyzhr6CczRcwehRFZlpKlFhW6q3Y5WQgZyiouXrpEM2px5Mw5+qmMK0gSi01iUDJtN4pKlIKQ2R072OhX2Vt2zNRrFHCmg5Mnz0jlOyqh3FChPf+s7qptCE81kVm2An3mVeb8eaqARqW6lCfqlma7gzYBY7UyS2sBsU29QWq6qswnuZXYxiRJjPP0ntBowsBglHRwpknCIEnox6mfkpUbrfOGEVKtVonCiLGvv8T0eM2Hd3I+4gBzA3D5iWKtZwg4yXm+bRNypTzhMJDZHEmSkoSGqBRx18G91Ks1TLCfzXYXEwVkVhGVq1RrNUxYZm1D+ETaGNmhcz6TtQzihO4gJk0yjIZaOSQqlTHaccuNewhOn8cmCbZjubK2TjfscWqzwVdebrJvJuD0conV3iqzWx/g7x4IUTqiqmKqYZe4dYSvPF/h5h2KySnD8aVpbtlpCboVdsxvgcur9LttLi9eEe1YX0wj38GRhWRJWe/0qE0ucGVlTZRNjMZpaUJCKVySoLp9GlGJ1onjzG5ZYGyixrRXjfdlYZkFWCA4w5BIrrO66ucc8sxHJeTep6Dy5NQMnA9NvJCzFbi13+th0dRrFYJQemUkOcYXVw3aBJhQgbV+yI/IvAZaYbzckQpCMIl4e7/gs0zY1IGRoq4ymmanQ7vdFP6b0j588jKhHksY1QHTWjyI8ZDxqx3XtXGAYOxaSUJXCgOiwDAY9Hn06ae47c47OH5+mVtv2s/dd92ICQJe87r7MdpgjGZycoLUhJSiUjFpFGsJjNQnVBAQZCml0JBYuZKdTpe19U0O7N/L08++QH8wYGl5lVNxh/fe7bh1S8ifP2/4j5+vstZx7L0N3rwno6rXUdqQuBKff7LGxqDOnTsS/vF7Vnn3fXBpSXNpvQ5jCWA5f/EyV66sSlLoMpQKJaRX0Gq3OLFynm2z49QnGpw+dxaXZoxXQqyFzUEfpxVODcXLwiigby2dwYCOrUFQZnFtjb7LcJEYm9F6ZA5IXmAd/gOKxU9Blc+lOSUEY8RYrlJBGabPxHHCZqvD1ORYQZK01ivBuHy2iMYYBFzRSgwjMAS+kKuUxukM45QsZD9zRY8MLC0gWq2xicwkz0ejXcsLGcK6frqu1gU95tWO69448gtJ/nmdolqJmJqc5uSps0xPTrJ0+Tzt5jrKaFyW4ZKYXpLgnCHFcP/dt2LjLnGzz6DbJcsSnDGEYUiWxQSlGrVyGatgvF5hx44b+dozz/H0oRf5u/uFkv3MGcuzJzrUQscgC7wapuLYoSc5/pyvmyA3XsK2kIeeH/D4ixlZtswgNTz4YIhvs2CsXmdqcpyllXW50TmDFeh0unzt0NPcdXA/vVKFbqoYG5+g6npYq+laS+aleLQ2lGoVKo0xKjYl22zSH6tz4uxZEuvoBl1U6NhZTdm7MMmZcxdl2XipHqXz6rfzAnYi4mAcRMoUQnZZUMZmKSQDqXhLooILImyphOs1cXaAcpaSGcdeOc1kf52a7dLFD/xxyqs6KpQyPhm2RQ5klCmM3TlDCKQmQzsNvgpf0D6Q8WbFoo9KKJsR50abzwPM15FH1CQTz/OofCzzKx/XvXGI1L7sdDb/3oGUvxT//fd/j30HboGwyq49e+itL7O+ts6uXTu47Zbb2OjFWAuHn32GjYunSbKMeCBjBpJ+n36nwyB16EDm820025z62pOcvbTMwCus3zUJ3W2aNI68B4J8stvQLQ8vslIJqD7UHUqFhajxLWaJ8qYwZ7dvneX+19zNRz/5aXLhM+3VUWZnpnnTbftY2lhjQ9Up1SeZqozLjdaa3SpAG+nwq5YiurFI/gRakzgL5YDLyxdZqJep1SN6ON7WfJgbN5cEjLjmGufZzvD3eWjn/3L7O+Dud4DLZFTaxZflEVPb4T0/J4F8vw2f/Dew9zWo175PFuznP04rM3xG7ZdKtX857RGuzI+ZFqhFmo/yiblSY8mEupINVVa0N0qhwEs3oVaa2vg4737r6/ncF77I0kYHMbq8ZnM1BJYDFVqLQb7acd0bh81ZlnoooIZHrZpLS4RZzA+++7uwYYWb99/AxsYGpy4usW/HFjSKl06fk/7pTPKMwGjq1Qo6CGXe4OYam60OE9NTZJmj24tpdgYEYcTk5BSH4j7v2tXju7YbnK0UOxcj/Qmjqy2PwXNdq9EKrdar6L7iq9m2oSiM0jhPdHQeRg2CkPmFOYLJGTImSMISYalCmuX1HnBa+ltKxlD2lCxnHbF11CoRUanEgZka5eYxrAJtM/SW/ehdd0tr79IJmcK09SCsnoOzz8LOO2FqGxz96lAWJyzD3e+CT/xLEZO47/vh4/9S/ja1FbIBfO2D8J1/H+qTQnX5+p9IH3x3jVDPoTEy3MdxFRybh7l5cp8rmYzmQuJV5XmFqqQdVQ2Rr2mSMN6osTAzxdK6qJ9YZ7l2dJNSGstwAu23t/oIkK++fA2mfgDk7NwC73zv91MqVWn2Y5ZW1qhEppC9HOoQKwZxQrvTQ2moVCqUlCYeCOGvFIY0xsaJqlXmtmxhgMGqJmG5zGeZ4/OthDSJSeLYu+EhKC+910N6tFIQBoEPDSS5VWiCMCAIQ4xSWB1yI7lcaYAMkvcn6+PloNJAG6gPYGN1kbBWxVoYZAqlBeGplGtoBWOVMnONKv3BgFMrTdZ7irl6BReGwyGRs3vhu34EXvgsvP5vDL8eeRje8Y/gY/8HfN+/hId+S9qB86NcFxpN84rwtRqzQoi0qfxuywGZAWhCobXM3wA3v1We99gf4s62RzyT37PdyN30AJlDKu2m0OGSG6i1hEKyhodGgytgA0DR6/X4k09/jn6v7wv6QxehtSZzgkI6L8dzjW98xeO6Nw6Fv7ne1JMspR/LBe47x8033yI7DoqJiTGeP/Q8LqqgjUcuvMR9JQqoV8s4pYiikiSJWYoxmshPfBoMBrQ7XeI4kcKh82GqUSgVYoIyoRvCw6MDZPLdLE1SCuFn58AJSmNNQGoiMuRmpZlleWVVGMdu+PB8zWy0uqxvttkyM0OlbHn5/FmSmV1UK5EUQMMK973uftK4z3i1wjtu28Pl82f5+gsvMjk1ycqVKyxeujiMKOb3iTDEUx8VJu4d3y0CaE99TCSCcHD+eaG7jyaqyUB2GRPJgo+l/RWl4ZbvEF2up/8E3vNPZfDm5iJ88hfFI936doILf0qoNHEyvE7GNy6B5G0STjmUdVjjZLPxk3YEmXUiaG18nlS0hgs9RMYRpFy4vATWFU1uTkR7BS5XWpTvMSjlPYcvBr/acd0bB4xUYp2/cC7DWcvC1u3MzM1SUo619hVw0GjUaQ4yj4b4JNk5siTGpgOsgthJG+2gL9pLpahEpVKll8rrovKwSFatRsmAIRcgA+BtMVoZ8EoXcrNlcrLyNG/h7ljnfKvncNM8c3GRi4tXcMoQWIt2w94C5xzNzQ3a6xt8z/372Tu7l48+eZpLScDZF54Bo0lLVc7Fi9RtwtSeXVyMNkldwL7pBgf3TPHQ0kVeWFqCOUA59MWX4DU/KVT36Z0ya/ytPylTYae2i2Xm02JHj0EHls+Id6hPydzyG98A228V8uMt3yl9JbN7xNAuH5H55GPz8NxnaFQrBD2ZBIWfdfiNhxMOlhIV9lHoWCsRuxjt9dZakaaZ7PtuOJdk1EPkDcn+chevp4oCqED630wQ9FsyDqXUBPCfgVv9OfwvwFHgfwC7gTPADzrn1pUEd78KvBPoAn/HOff1b/b6eVxorZVqqW9dtc6hjGJqvE61FJHFfenxKDZs2RdsLg6gFKmDxMmFTlLxNM4p4jQhcYogilB2QC62nCM50kWYFxClqVTnI7pGCHpOCxwahi6/NsPrpGVgjvKzuZVWbNu6lS3zMzz3wmFfmbZFe2+SpvR7HY6fOM6/+K3zjI2PkYY1prftxkzvIE4tpcBxfm1ArVpm4/KAZnmVuakGx4+c5A8/80UuXbjI9FgdN+uYci3m1y6RfPY/Ec/dRPrMZ0VO6M9+DTW/D47+O/TaMurRD0M0VgQbxXV86Pdwu+4SQzn3PK4yDhvrlJZP0F5vcnjmtbjPfAq3pOBzn0XtuhM9OM5c0qdy471EL21ijCFNPbVDibEI03d4r69ZW7LgXa4o7914npgb7ZXolRT2tIRm9XoDspTeICEf1nMtqJuLXzMSqr3S8a16jl8F/tw59wNKqQioAj8PfNE59++UUj8H/BwyRPO7gf3+3/3Ab/ivr3oUNVstaiHogEGcYFXodxSIQk0/kV03d7WZyxeoYONGG5wfVJOkUlBCKeIkY7PZpVQuEYUBWbc/Eq7m8bErmM5aKYxWw3HH+XmOeLYg8F2G2pBai9MMsXifcBsUC7NT7Nwyw3OHMs8HSoitZbG5zJaoy8lzl+i1W1jXodvcRJmA1uIF7MRO3vv9P8itYwMmJsZxWcrlxSt88H/8NwEUul1cZrFpSt0s4JyjTIJVAS8d/ADPnbrE2f49qIphPJhkws1gtrwOtd33hu/xu7C/9lqByizt5gbrG+eIq9uxVpO1HW80MH3hHJ9Zu5EsmyQL7pbxAKd6REGJgze+mQf230zt9ENsdnpFLm49kpQXJIcV7VxFniG9Iz8HLM6J+pQk8hIV+BpnMYXp3nvuph5mfOZLj/tsxOHnbgnowTDhd1Bogr3S8Zc2DqXUOPBG4O8gHywGYqXU9wBv9g/7PWSQ5j8Fvgf4fSer6nGl1IRSaotz7vKrvceo1wCFchbrND5awllHaCJi1fP0EIqqsPaFJX+ulKKIcrkMSmHCiDTNiALN5NwCjVqNarWK22gJ10flkgp5EpA3Iom3UVwzsHJ4TTxSpWSH8/0CQ0md/IOJt+n3+j5cEC5Tu9uj1e5gxzP63Y5ww7SiUa2yvrbGoN3Crizzmd8+w8Nhzs8yJEnCZreL0iHlcplGvU486GMTP0JBaTLnOHxuiaW+ou3KtNo9VkNotzboZGskSSraXtYKsREItCEMAkKjKGkYtwFjRqFNKGxmv3wKFMrnwPlCb7XaKK0Za9S4st7CWFt8XuW+0VvAcBiQ8sxaoxXOaaQT3kqthLxy71tf/edTwOrKCjfdcwtRaPwk2yF4Iiinr7PY0cDrlY9vxXPsAZaB/6aUugN4BviHwPzIgl8E5v3324DzI8+/4H93lXEopX4c+HGA+fk5CWuUsE97g5SoHKKtjGVxDowfvJ5lzmP4Izu6zpVcRXyhXIoA0XICRXOjQ7vdYnZqnCyTuoV1V3P8pVCUu/bhUdApCi81nNExSlUYeQaQN/dL62mSpp4M6Oj2esRxMhQcy1LieIBSGRurqxgjtBlJVlM61hAoUfLTYZmpqSpgsWlGZ2OdXqdDPTR+sQnt/KWXj9OLxgmigMvrGyStAWv9mHMrG7QGA1FbcVDK87B6lVqlggkMaeaY1o79YxHz87NDSR7/2Yoqu8ohUk232yPNLBPjDXCXJTTNrI+MVNGwJ7QeCsXFIcpXbE1yH3KAy/nne5gc53Bao3GcPHWKbnOdNMuksOrrIX6izlX3z1n3V5ZzBMDdwM84555QSv0qEkKNnoBT32wK+isczrnfBn4b4MCBmxzOV26tZXmjybaFaZyDmZlpkjRhdW2TUA9vUr4L56JtIOxVZ4VegIZAaVKVEWjDoD+g2WxSro1x4eJFFpdWSaySmdd5UQp8GKf84Hh/0Z3zY4GLcy9urvIJUDHAkWGua3LqgvKP05patUqp7JiIxhjTTe4ZT1lPHJDgEJq9RCBi8CbTPvmn8GajM0JUVTFfrlLF0KPqr4sAA4PEEmeOQ6dPs9zrY9NUZncoUYBMnCUJFMuXNwmNoHydJGVFO4JWlfrUFOUwZKgLNUy2h94WBnHMIEmYGKuTM8MLZsdVdTlZvG5k0ed3s5itojKUG06Lytd0bpTaG1B/MODU+csoY7x3ynwIl0cCCuUnO2UuH0L0yse3YhwXgAvOuSf8zx9FjONKHi4ppbYAuaz4RWDHyPO3+9990yP3BNYpBp6VmjnLlcUlpucVJopIBx2sH0xjcjqEx3/z4GeQiBwoRmONJU762HRAlsYopdFBRFSqUCrXyPoJiacVOGc9jCxZX96cjxotRo16K+XnfWjw54sPf3Koyil4+tnnJUxEEYahIFzW0Yt2MM8S//drMjI7yehKGub434jPO4bJLeS5WoLWllNqku1uHavAGUWcpCxtrLG6uU5mITCKsjO000TyMQ12M2VmrI7xVPLGRIP1zSbrgz6tThtbqZDafCoWw6KS8tVua+nHA7q9PmEYFEBJvoGIk1DX7OZDZMm63NPaIm92NqegDEXtrMvDXov13sXZTHJDnXsnGVSDz0FzBjHkEquvfPyljcM5t6iUOq+Uusk5dxR4G3DY//vbwL/zXz/hn/JJ4O8rpT6MJOKb3yzfGHknH9+rglWKE2lKEwSMj1VZW2oVUJ+VRMV/OI3x0ppC7pMLY71gQKfbpztICKKI/qBPEARefiaVAMiPPyaTRh7xFhaV85JULlw8kpTnxuzPoaj2FjMqJBmNfAFPxQOZBWIUxilOue38spslGfRp9zukaSpyqFoR+rHORmlfZ/Fs48ySWCvFUW8hxhgq5QqRKbFAmzvio3zhsSeItu9n2/QUV5Y3CMo1dJpQ1WCsJQ4lfFKIGuQt+3ZwbnWD2DlqtTqZCWivr9Dtxbx07Cx7a2fYuXfC88JGEmrn0TerWV1vMlGPZFajVmTWK4Hk4aj2ur/Oq4NYySGKZN0vfl2ABBIejTKJ8wYn52VAlTEopFMxN6MibyTnB0uPSsArCID741tFq34G+KBHqk4BP4L42o8opX4UOAv8oH/spxEY9wQC5f7I/7u3EONotdpX/TZzljAIJbFyIzUE/PW0ivjSJWa7TZKXX6bW6nI5SVDOEUYRNsuIoohemso4tTQjjmPSREKYXHzNjZyH9CYP4cShTOfwcTlCNlrRK1A3iaPQSnH/PXcQKMfDjz6Z+wW/CWj6BCREWFfCpSmpXxwYT57TIgcUBIGXExVNWzuColmticMIqzXO9QgCw01793BytcXZJGOgAiYnZ+h2NtGZMJ8ngwhCIwJ4xnD88roUMG3KyqApnZOp4sKVFfrdDjPbxuW94KrEVymfuznYbHeYHKsQ+kKrKN67wtFIndR5TWRPFsyF+HxdwmUOo6VhyTueq9DC3Lnm+d7u3fu4Zf8OvvCVr9KPbYHbjiqPWCsKNJ321etq9PiWjMM5dwh4zSv86W2v8FgH/PT/T68PJKmj0x1QbpSEFYoT8p/RfvqSX4TOJ2pOiSykc3Q3mtjYklxaJTQlKQ7ZlCSTcKhWLZGkCdoErG82aba7ZH73tc5B5gp9I4dXy1MyPDNQQxlMQdsFySpuNiNxrkOkbLzsvVaawCiMk0WitN/98LpQgAlCwjIEmQhdK//+guD4eYSBQTntu+zytxlK8CtUcc5aaw7u34MqXSaZ2cfY2jphqUKrP0cGVEoh57oJPUR0W6EIFNSc1JcSJ7nb2I69zIYpWyZqzE6v4Oz6UPzJq6o7zwrAOZqbTRo37KJRq7LR7IPLGIKw4kmVc15HWK6atZYUP0/ceRTQ5bt/xrAF1qOHBb1AjixN2bl9C5VyRG/QLUCQ4ii8vCKqTb7q+ruuK+QKudmDJKbqB9NIgc5QDoOitgGjqIb/LjD0pieZW5inHMds6bQ4/tAVwJI6B9ZJn7UxaG1oNlsiH3pNOAR+R5Jv8pR/uPgL/y831eYBMoUooP/zkCGqfJiY+t1e+QS+KHwh9z80omjirC0E5rI89/GhnPPJ6ehzc5i5gJF9zpnEwo0yE/Ow2eT0qRN0s4xOaqmGBq1DbJJiAiMzNgYJ5WqJwCm0s3SsZvctdzBeNlSWjqJYLd5neM2GRHGbZTRbbZxzVCtlzzfLRp4zRKTwz7Q4oqhEFIaCxGnx1v1+v8jZvFQLefIuTn7ITVteWeKFw0fIsqFS5uiqGu1deeWKvRzXtXEAJGlKd5AwicT2mbU4mzAz3iDI6SFK5ncEQUC1XsWut3HWsrS+yb5dW6lNT9C6nOJsJmohykki7mByfJJ6vcb4WIN2bwBIbcBaW9yY/OIW3yvJW0BuSk5ryR9Y7FKq8GugZOfPIecwDBkkA6Gr5G4/f5rSGCwqMARIUTFJE6n3uDwxz4MxRc7iBqFb5HG8cItGAkOlmNy2j/e887v4wtPbeOHs/2Dt0gmcUrQUuNTidEAQRmgFibOsaIPDUJuc4a7Xfwdve/1rOTAT8Yk/OEKO2DmXq5UPDSO/Br1BjHVQr5TB+ZYD+431hTx3y6wjiROUtWR+4RbUIa1l2pYHXEa3IOfkZbWDXq/Hw199AqUDGPFI2BFFEv+6IyjHNxzXvXH04oxBmo9Hlptdr1Vob/SLMAPk4sZxTBwnxS5qtCIKQ4IoJLOiNpJmliSNCbUlTjOhHhhh0cocu7xZhgJVKXg+ulj9RSJYLEu/QofeTPkQI+9BGDbqABw/eYrUy9EMF3D+WvI10JpQCT3CWqFaa+kWQmtJzF3ukbSECYEWTpl1jsSrKao8LXWKtNvk8AvPsHNmgn//T3+GX/5//jOXLl0icwpCRVSd4MZ9N3Hm3GnKjSm2bNlOH8u77ruTB+/cx4vPPcP5wRTdTgc75vzio0DvwId2PkdL05RBnFCtVtAaIRj6azh0G94L+xqItdIzjmfQFv+0wiaioCh98EPIV6DgHJCwZJnDuLSYkKV8kj9ExP7itXddG4d8CFXAePluGRhVxNbD3gpp4ywUMciVtA3W+VkdKIJQZktkgwFhuY4ODCYIyJwlThKviOGKGyykN1skgXn1nJH/5+eQx75Ka9nP8hzIjcbHcq6nzl70C0g+qc3zCp0HbBJnG58zGK2wTqOM8uiQfB3SIfxz8CxfZFxahpMaj7+ip557jEOPfYFu7Ng2N8u9N9zIE2sXWF5cJCqXmB+rUl47gbl8DLNsqMY7WNiyhbNPXOTxj11kcWmZUiliYXYGGlYCoQJ21ViXSqjpc7csy2j3elRKpYKNm7cU5FXAvKiXh6dFEXVkhx9SSQTKVwzHS0ha55HA/EqMSFI5L5BbgF8eNBDg8NvUczjnSDNZNNIpm8egFuM74QS5HcJ0kqTLkcfl+JskVBS5mROz89TGJskGHTLrGMQJIENopIVTXuPazrlhoW/421EqiVLDZFSN/G40PFPOsX/fHvr9HhcvXZautyLBdCPQV/7F5xWyJPxYj6sbeYpbnOP+AjORWZluZZ1jZWODCxfOc+HyMlGpxJlTZ5k8epydew7S62WoIGSQWS4vr0M0ho3KLPXBXrnCVw49KxOWyobT603GX/eAZzCL8eX6ttZL7YCIIWRZRq8/YKxcIgiMQOV+UtTV27eHY53MQzR+wzAjSunKX8urP3WeB7qR3yhUEFGvVOh0u2R58zsUm5PzxvnN2siva+PI0R6t8hBF4tLBIKbf6zOhRiTm/YUuxNGUIghCwPmLk4deCWmW0lm8gl28wk07F3BZShKLVIx1GZlffLqIeUfWq9/JR5PgYb0jHz+mCiPMF/ywRiNEyFtuuoGV5StcvnzZu/q8XgLOzyvMWcb5YZ0t9F2VUmRZJn3zLm/7UajA4LKUzDlim5LFCZfXVulXY5489CKrG9KvkmWiV7i2mtBqPUlp4SCvfd2b2dYQlChJ+mysrfC1hx/i9MY6Az/TvduU9xkMYshhCWexmXh3Zf25eCpPPLCsrm2w59b9hIGwCYzKaT3Sj1HURjyyl1mLseqqz+6cLciQUpj13ZO5kRVeRN5/bGKKD3zPd/K5z36B05dWfB3EYXM0E+FlDe/sNx7XtXGAG044daDIqJYiUIZypeQ5Qx4GVIokFaqy81Bf6MlrWIdyKQZFFAXoVLHcbDMxPk5mod/t0G616HY7pIkwarVzaDVS1NKi7xTks/pGsHZZ1Hn+4Y3FSsihvOp3vsvKghDqe5KkfgHkIaMwTyleL78KefI9jEZUPlzP5bmPfOaCUmItpDIXsbWygtvhGAxirNK4MBLR5SzDoum0m3SvnGL51BilhqFaq9Pc3KTT6bC2vERqIapUQSmiUoWgXPLTeC1O22tQIVck6gpJwFutNkEQUCkFrDedz73A+TKd8xufzDK0YDXWyZiIXOE9Hx1dIyYjBZeA8qILHufSHrNSWFRrhaC/ya6pEsuXB3KOChyiPIPLSJyVzsFXOa5z48jDGEl0ZybqfneWCnDRU+E8ndwYokhqH8qB67fprZwl09DZXCWKDKUgYhAnjKMwQUBYKmNRDJKEJM3ILGIUUOyuAvkpn9dYGZhSbGvDam+em4gImfcceVyd10U8DGm80JzGE+f8ZzXa+TyFwgCLxVMsIPnMBbEuD/V83qKU9Mz3en368WDYiOUsUSlgoTbL6vIqWmlKlQrjkxO0m5s899TXeNGE0n+iBHIen9uCUdBcWyMKDNiY+cl5QjXscbE2Qykj18zlYeiQAtru9gCYaDRYXG4WRuRGVM/lGmmkJ1aMAZWPIhBm7rjt8uPho5RIXhlluibLrn3+cQ5kKe+qJBKX3/t9uH33w8XD8OgfYJMBWSXjD19l7V33xpEjPM45qlHgXbbzYYcupD2F02+JIpnpYG3GsRef48XWsu8QE/FppzXWysXKsoxKtUoYlRgbG6fdTyGxBUtUkBM7hGrJ03BX5Dmj3XtZlknTjZeBEbGAHOpU4Hs7tEZmF3qxM6Bg4xZOJAcqncNmQ9Zrfv8tDmUVWo0aphoxUBlGHxhDuV4j1I7XTGUsr7dJ4wQ3Kbu6ZVMMYdKTJLU8v3BotMjSFDfmQ1OlMKub7J3Yx1QRHuVhoSKfg1FIe+Lo9vqkmaVWLROEBp1oMpuKr7wm78gBDKvwvEZVwOoGx6TuU5ndLpOuLh8d9q0HEWxclj73+jRUGmIENqOmgbl9cPA++PR/gLf8OOw5CKee/KYWcN0bh8TYEIUGGysMGossSuV3X1soW2i0CsTRKscgy+gPMpyoPEEQ4Cz0BwkbzTbjYzVPHc8ITCAyLS73Fj5fyL8vqqo5Bdp/r6RFNrOW1FoCHyZkdrhYCu17H05kmeLZ519kbX2zMAhlczTFglU4ZXPKnXih/HqMBFm5V5McRGo92kOezkEYhoCiPL2ddrjIL93VJ8vqZFk29GxuWJsAj7DmQEBeWNSCNOWzAuVv6xileFTt82PiRFbIKK/B5bJi2lKSJCSZxfj8SGtQ1lPQVZ5bekDCG02eY1q/8eXnw8E3w33vk2lWl49AryW/AxkBd/EleOCH4eufhMXjYjwAc3vhwkvS2nvyCdh6QIzjmxzXvXHknrdWqdKMY5yV+XvGBLKYMhEcLkIN7VswySnmoBCvYYIQjGZpY4N6vYZLU6JSiY1mp4BwcbIrayULTSDdIZSYH04N+VcgJ5lzmxzWz6VwaONvOnk12JFljsPHTotSYRiS11Io3s+iMmntlbrJ6AL25uk3g6IWg188vtKujRFjV4a+NvyafQMqi0nTlDiJ6Xb7JFlGliQys92zA3IgQsSpS1RKMtukVIooB2Xpy8/fG0VPRVBsFsP8x/leVOfk/rS7faanp9HmVBH+5EBH/unyEDpHrqzfWBQjqOHNb4Mv/44s9NokvPfn4bO/IhJC9/8QBCURiXj0v1+9kLJEBv8ABKF4mL/guM6NQ8mOhSWJY+I4LlAN7Y1A7oUqFrBWuVuXcD9P8tI0BSRhHfQHZC6hVgoJg4Bev09vMBBUS4F2w+If4EMkW8Tio+hIUa32D818yDXURsqTU1VoVSml2bKwQKvVkqacfJH4RFprVRT38vAtr72Ikfk6jPOeNQcIcm/nz6nweMaQqBIZIQtbZtizYyuPPvYYQeY7LTNL5Kks1vfLa6VEYijQqChCRSFpEJJ5Cru1ImOX89DyttZhA1ju30Spvd3tMT8xRjiCroHyIt858wAK1rRzOLwqYp5XYWWe4c1vg+ldEjqtnoNb3y5SQWFJPEW/9Y1LafE4vO6vw01vFE/zpd+Ce79fPA1nX3H1XefGAbUoZHZiDG1UIZiQWEsYliS3II8DPBQq8BY+m5VQQBuMlt3Q2oxKFJJgiEphISImYZGEVHncrrXoy2YuL/7lO92Qa5cvgyJEcfhqxHBXLFAs/wqVSsjb3/ZGHvva45y9tCgIUv46/jMpvxjyPq58lh6OofCZG3LLRotk+W6b13mUVBExCsqlkIWFGarVGv1E+tdTm6NHwx1aOYiCAGOgFEVEgYhNaK2LBD8v9oEuxqUVHnbk/JxzbG422bUwSSkMMIFBJ6I/ln9Ol18mf1gEENEKr2vr2KXWCR9/lPTu98LENtzTHxepoHu+V0ZIP/MpaK+KV3DDHFFrhV2/jHvoP8P+B+DJj8HFIzC+DZ28uge5ro3D4aiUAsphgFGKUmikop3K7hUoEQV2Ti6mNtor64lb7nS7dFotgjDCBIYgjEjiAfGgT2VskjA0OK3p9HrYLJWBNkiRUXmFDIcsOO1309xITB5KZLbYxbVf5BT26Xc75UANJyYZn1ymXjPJ+SKV1fl+6zwFfIiI4VyRwBY7tFjlsA7ECEvVPy/va7eZRStFfyBTcsMwInYpymagTbGQLY48GZCZGQJ+GBMQBJ7QqPHdmY5rw83CcxSeTAq165ttKuUypSiSc/UGWYRLathmnJ+CHUH+NI45NjkxqPCJh8+QZKewdhdpEMFTMUFoQe/HuBswLsWV74UsIYoi3nzXfp545lkuP7cKzz4iPtzdjv3qMm8s9V51/V3XxlGQvvMi18hXfEKeZSK+IMncSLXcw6MlPwSzH6cETjHoD4gthCiqWpMl0sORjoh7iaS+K27ytaDhkIo+rMwDxYgvrTXKWvLGJoC8Fx0EhkZBHMf+9fzhcwwJD4faS3akjDvat+6cDBLNRxcUXKMRBKgI67QCCxubmzz6tSdI00x2ZIV01/nw1JEbq78W+YzDqyBXv2loLfUDN3z/q4zFe2RrNc1WC+tkpmMYBtKiGqfDa5zrTw0jVt/PL/WmfFZhh4gzbpK+B0DQk9x+8DWMlxXddhsyuZelchlnHakzvJhVSW94A8GOjCzJWD17hOXFyzjnOBisver6u76NQ+H5Q34CkM8t8kQWfJyeX0RtUDrPBaTuEWcZ+Mdn1tKLLf1BimpuMr9tXjrW0uyqBQUUXqK4U2oYOuWE9eIcPYQaBKYgAxYSf/6wPjdQTjoYUUoM0iNNeXiYJ955jcRes9Dzr1cxS11+ft5gtP6GzyO4qNRx1ludYX+98mPMcrFuydiKz4rKvdXwtWGYdxRcsxGjlfuS5x+Sy/T7A+I0ZbxRw/g8InewuXHlfCz/C//X0fxFFZ9TA2l/QGRW+cPf+Y8YDN3NTWrj4zgFm8srbF2Yp5NJ9mewWEKMUezeMkm1XKXdHzKhX+l4dTL79XD43Yw8ZHFeQM3Ltzili12voAK4XAvVp3w6n2IkSXVUColKEfVqlWqljM0SkjQmHiTS6GSHqBVWWlDzn3PkJZ+Q+kqTSDUwqts9GoPn1BPtLEmSFq+dJ9sFJO09k83Di/z3/hxyBmuej+RcITllV/SRXH3fR5IkL1yt8jAQ3wczstApXsN7ZTckehbsW+GM4JyfvDvymTWjfROWwWBApxczOzXhdahcUU8ZCR6LzExJcuWvkT8PJf3vxy9e4tjZc/QGAwITUC7XaDXbqCDEAmGpzNz2bQTVKvV6jSgM0cZQLZdQRnFleZnJUoc0G5C8wj3Mj+vacwxvqL8ZCBHROiWwrPM1AOcXYXGVXbFQCr6Oc8PZ40mM0TXKlYpoQzkfwOQ7GHmY4Ir+f+ssgc572Iaew3p0abiT+3Pwm16+mOT8pGi5urbJpz79WdrtDsqExSIOsJRcjEKMPl+iSjkyMqy2uCyjyCVQqCwpFrtDZIq0n08uoaEtQkCpPueZlPJ5lSNFEeO7KnNww4dh+T2w1pIx9EpCwXAjH/hqz5YbMUUdKGNtfZPxsYbMANFXe+bR8FQAgfz3ORXe4YwjiiJuPXCAF46e5srGJsdOnaTT7mJdxtTUFBpHZ2Mdax1N5ZkUQYgxmkvLF1DaUK9VeP5skyScYfLG3cAjr7j6rnPjAJG10QSlKmPTEWNTU4RhmVI5QumQQdwvpD3z5pV8h0uShDTx48GUCAqn6YBBPGB5eZW9O7bR73WJkwE2Swv41PldLffs+f3P10IRypD//urEdLT+cVUM7iHO1EHqEG1YkJDGOh50x3mTO4l6hWagwmx9on/VI5yC+iy88UekcvzE/4CLLw//vOM2uO8HoLuB+sp/gYktAmvaDB75PY6tdPmIvpesQLmuCZH8ZpOHqvInSaStN6BR+HaYWIsnd0YClPVmh22zWylFJbr9RGD2osA5Aip43yGEUU2mPUvAAM6SpYp3vevdPPb04yyubUCphstSlpo9gjCEJMEmCQ6olMt0ey3p7YkM3UFMpgw7b72NB+6+k/HlL7zq0ru+jUMpMAFz23awZdt2ypUKxveOGyWDRxKb0Gy2SXy9gBxvR3B6FUWiq4oiVgntbg9tAmqNOspoNpstlpZWaPcTrJZej1HNiiIcGtnJrjWG0UPGe+X6TVcnx/lHmpue5A2vu4+Hv/oog0ECmcUpaDBgLkxgdh+0luVfVBWR5t6m6NtWxqE2Ab0mNJeGL/zAj8HqYVg5C2/5YfjQ/yqFr6AEb/1hEY5uzEKtBPd+F7z0CSmiveH7WPrE77xCjuLPvQi888r7CDAij0KMY8iiHbbL5q8joeH6xiaVyj6q5RKtdo9UuUKOM28SUzDkj5GHjA5jBKBwSnHTrXfxljfdx+TWXcwdeC1XNjrEWUagIItj0kRGRUhzW0qcZD6MTcFZJqfnePfbH+Sdd+6i8siJV11+17VxZJnl+cMvU6tWOHH6NOVISHHOOrIkFV2kOAMVsm/3DvZsX5AKOrIDicK5kPsCYwgqhs12h8AEVCsVCavQ1MbG6dqWH8U8LLppbQojcVC4jjxUk8MVC0tr7flKeZ4ykjTnwYxTVMoldixMExlDN+uh89AqKMG7/5lUcCvj8Ln/BG/+MUgHsOMOmaHxzp+F1io88ZGhcWgDs7vh8Q8Lzv/AD0uBrL0mhrTlJnjtB4Rqceyr8Nn/BHEP3voTcOWE7Ng5QdJ7sXyTyT+zKC0yTKhc3s+fK7Iw8lnzDQQK0Qlgc3OT3iChUoqkLuKlpJwFmzOY8xDKe6Z88muRRFlHmiRMjY/zvjfdw/e99f5iqm1QgBwU5576+5BaiK2lnyQYpZirB8SdJq1O51XX33VtHEopHvnyV8iUplwbw2jNWL0mO4A2TM9t48C+PczOz9LtdWTiEVJYyht8BklGpzdAaUXg6QMT42OkcR+tNHGcCvvWJ+I2yyFJXeQKukjqh70cMIyTcyQH/K7nRo1nNJ72tQRfzLzKAzmHG5uHxjR88GehOi5VYGfFKN77v3mhuAQ+8W/Eq4wezpHTSXxVUn6vA3nsR35eZnLc8U54+L/BPe8TT/LwfwPGh2qZw3XuNwQoUpaRxLy4Js5D237bH3qgEX0qJ2TRbr+PdYqxRh0urwyZzf6Uc0Zv8S/fjHze5gL5fTzosnTmFPMzU1RqFZwJUEEgjGqtCXyxUvv7qLzGl3IW5yJsFgOaleYGvWskn0aP69o4nLOsLS1yyy0HeNc7vpt2p0WjVpedrDJGdXyCII7pZtBxeY+3KhZrt9ej1WqjtQzHDAJDklnCwG+AWtPtD0izTFpJve5qzg8a7fAbkuBUkWiPnOlVqiUZOX3Ey5C5HAmiqC77pxXxvVNI6BSWYd9rYdcdcOppqM/A3vsktFJaxgDE3asvlM2EoXr3e2D1gniFoASv+2vw3GeEpLf7LvEgp54W2sSd75L5frUpiKXGM2xBEu9otPZolEfStMVailYB+btUsr8hyBxJyxySkA8GCZutNlNTkxh9FqMNWtkRjWNFGITE8WD40bzaTG4sSmvWV5b4l//g55h1KTsbAaXpBb77X/wrdu+ckettodvrUq/5FgelWD/2Euuf+3Pag5RzG20uJQF3f+87KSd/daJuf6WHUpq3v/N7qFdKMpXHCfqSZpZICbyb5WiMdUUjfaBFql4rTbkUEgQRQRgRhCGtdgczSJisl8AJz6oYjDIyCN65obyNUNZ9Yj7ScnltIpoT/rIsQ6MKkY08rMq3SK3y183wQjwELmNX9zTZZ34F7no3XD4GZ56FL/4m3PqdcOxrsHIOnvkEJMnIOfjjax+SpHv+Bvjcr8t5OmDQg0//R/EYp57h0ktPkzzwt2BxHXXLB3BXjnP5qa8Urb3Da68Kj5cXVqXZS/ufldRhLJ497L1l4QkVhb6U3zgym7LRbFGvVdBGk2X9Yf7iwQ7hzzmczYumDuWNMs/3KnPbed/P/e+YwYD2Zou43aOfWNrdfjE7stfrEUURRguT+PCRC1y6ktELIpp6ntKebTijWVv/Ni0CgqOTJLzp9a9lc/VKgZgkcUw9DDFaE+e7GhICRWFItVJBa0WtWiaiIgIKVpGlKfEgIenFzE40SJKEOEkKFEl2J/zQGnXVeVgryWAwAswXkOVInJ3zlCyuWGt5/J0/MU5SLi0uEceJLAANJZcxp9p89OJWLi0+5Vt0H2SyN8f40U3avRQ39m6Cjkbv2if8JP++mXNkqYVzlk53lYnp93D5wlnSp5aA1+OWHROf/xrfZ5/j93gTy198mSx9QcanoUi5GWeUlxfSRYXcOQlR82Ie7priYtFmqou8bLhVUNBWQJFlFm0y2p0uM5NzXphOkVdlVKHOMjSCfPOxnqJjbUaSJfS7LW7YPcvNu7cSBUbgfZsJg9vL74zVGxIF+CLw3W9/M7e8+UGCUBOaAGzCoWefpt8feqlrj+vaOJTSbNm+k/GpcdZWrtDt9qhWKgziQbEorbU4mQqD0QHVWkhUKaFNxPjYJH0X++knhna3S6kUMjk2TliKQPnW2v7Az8LQwuPx4cIQcfJhBuoqQ5BzHNY7lFKQ5ZRyVcTgwwUlIcqlK8t85vNflnpLGGEIijDkvJrkJHNopalX64ztuxvVWmN+sszKZpfI+HbdwMvvWKmwZyYlwBCamMXNFvXJ/Vw4c6oIiyIcRIqp/gBlZeS9TXr+2ngaCUZ60MMI1+uRpalXL5fekKBWxWiHimNcnOACTWZCkm6H1DrWqjXSYemi+Cr1Jkn0N5pNGrW91GsVOr0+OslIshFv7BhqeVk/m8XKvehlPdaTJmfOnOIzXwo4uW0roQNTCrEGzi820Vm7YFsbrQmiEhOT08xPNTCZpRSUGJ9usNnaoLWxSa/3bWocWiv279pJKQgIA1OQ1hghF1bKZZKeNP9vNttY69izdZ56rcoNN97Ii09ehgyscqTxgFo5Io0HVKIJnIOBp6pbmwm5EEeWJDgToI0uRBZySHcEu2KI64sh5zGTy/JQYQgJj3oYHYTMzs6wuHh5mNyOvpaVBZWisOvrvP2Pfhcz6A/Dv2vOovidFCmkU1JdPYBelVPCAzE/duwIbhAUecVVR7kMP/ZjsGULnDkDv/u7PoQDbr8d3v4dqIUF+OIX4aGHcH/v78lzDh+m95E/4lduuYOVckUScH9/8mhLGAWKdqeL0ZpauexZvnnfjD+HoesQ4CLN6Md94jhmPWoRBSmrzQ67VMj8tq1smRRxvzAMeerKYej2qbQ7hEFAllnGxsbZf9MC49WANIlx1tLq9jhy9CRLVxapf7t6DkCYuCbwFVfJK0wQYDPhy/T6XTIrC7PdHdDptNm3a5u0q3q0SuZRG1LryJDOtCgMiNOUOPMDZKzDKpG70TlOr4bYu/KeJBcEGBqKHLIY8qQ212UaeW6OpKHYuW0rb33DfXzs458kzmz+qsXrWRw2Tmh3xVOEM9OYnTvBGHjiCej34dZbYX4ennwSSiXYuRPqdTh5Em65BVZW4NAhmJyEe+6BS8dBrRLt3w8T22Q82RNPQJoOL/bBg7Iwf/EX4ad+CvbuhZd9MfG552BtDf7JP4FHH4UdO+S9H3sM/vf/HftnfybAwGje4j9V4YWVl/VUiomxOurSon+kJ2i6YYOZXFN5sjEB6+0N+o0UFTgaEdiNC/zWL3+GLI6pNRpYm7DeHpBmhkq1LGqYShEYQ/PSEWbndjBZLxNFmj17b2DH9m0cO3qYMP42paxThC6Qk9600URRJAmkMvQHCVZHRf2hEFPz8bM2BpwmsY5OP2a91WVibBxtQtqdHkki04yEKStCaMLHGqGf+yP3ADl6Mzo0E/+3LEsLRGqI0vps04coUaCJAuMH7Aw/5xCCtWy2Nhl0Yk6dOUv2lrdgduyAixfhttvg61+HD3wALl+Ge++FEyfgTW+Cj34Ufvqn5XF33y0G8AM/IAv7Ne+Bh1+Av/H34dBxMaxuF559dvgBd+6E48eh3RYj27FjaBzOiXFevgzveQ/81m/J7974Rnk/r4lrrWiK5dyzHNp2Pm/r92O6vT6NWnW4Cflkf5iY52xrqZUbo+n1OqgxcFnKo1/4NE9HIRsbbUwQYDQMBqlsgkqIk0XPv9Y89AXN9NQ0tWqJtfUNZqZmuPc1t3H61Gl+YOpa/zs8rm/j8MGGHqk45x1/WWZ9xVaSxxxiHdZmZSEGWgbJuFQQjzCKCI2iXi3T7stC1sbg0qwg7OGurtjmKMwrXcYCih1Z4EPCXf5c+Wp9KUILpjt8LvginCtg3ZXlK3RK03yte5Fkrkr0pS+JJ/iFXwBPkSBNYXlZ6h+f+hQ89JAYxIMPQrUKlYp4mY9+FO6/BSIFGxvwwQ/CW98KU1NXf5hWCyYm5PtGAy5dGlr4zIyEWr/+6/DzPy/ncMcd8PrXw2/+JvixcQJODVUj84vifK1D5FgtlUrJT5PyXtjmNY3R6+d8d6QUZK11zJTgtnJX8phJqaYo51A17+kVKB8eCw/a98wkl9GbMBcqXHODM18+RSUqsXXL9KuuvuvaOBz4uNSgld+NnJ8HiCrIeaK4lz+j2KRHhnI5UptSqVXZOTHFrp3baZRD1luLhUS/8lOgnC8aCYLi42WPhOGcVybMFzIMYVwxRq0FPXG+nCyIphpqLDgk8fcKjFLAHRYF8hxntdlhVUHcPYN7403wnd8pYc/58+I53v52WbxRJEbS64mR3HqreJJ775WdvlyG978f9m+Bhx+Xx4r47lUhEACHD8M//Ify+4MH4c//HH7iJ+DLX4bv/344dUqM58wZ8WA/8zPw6U+LkTz11DDPGJHqzP+fNy0lcUyr1fJqMTKQJ9OZ0MqdResMi8Uqh1PWF/ACbto2R8fF3Dq9woe/s1EoxAw3TfwGJiJzVx9Kro0bfmbtFTONeoWWWn9c18ZhraXV6dDqdIlKFTbbHSrVmkwf8jdXMYrHW9I0kV3FZkW8rxGsvdduEdXh2NEj3HHLAfqD/lVjB2AIX+Y7ul/xUHC2rk2EvyEtLp5bhGG5lSmwaMqlEs5aL3Wa1z98Qu5dTGYdqY35oak6lTShefky8dFjuCefJBgMqDabfGZmgcGLL7IZJ5Ak6L4l+/Afw+13EH74jwleOMzMpSXqD7yWyle/xu29Ps99+jMManXU8RO4NIXZOe/BkLnDH/8E7N8Pf/THOKdxR45BnKI/9nHM3Xejr1xBHTqE27oV9+WvQKWK3badwdnz9AKh2+Qeo0D2Ch6ahEvtTpe5yTpRENAbiVu/IzzLW8Jzr7ASHIzL9TQgBmNzxrR//tgcvOlHIarAYx9CXXpZ7owJUA/8Ddh2MzSvwEP/GbRBv/XvomsTQsPh1Cuuv+vaOJRS9HqCbgz6fcHknaPZ7THZsCij6MUpNhjyd7QxfgCSwICZEyqJMYYgCAQeHPTJkoRWs0WvP6DXj9E6uIqNmi/woV6V/5d7kGtqHMVzigEugrgUYwyUAqvRytHa3OD8pYte0EEXiXvxOj4+N0HIzkCzvHiFf/TU87z49efo24w9Ucjvv/Aiv2pOcbFS5ezFRUI/s2T99CL6zCK1RoNypcHtNmLf8dPM2QE3aM0newNWt26XfgsFjE0W5+h8uyzHT4MpYXfuwbZ6qMlpAqUonTpDYEBv3w6APXqMNJNrbGfniwE8V12Pa3Iyh6PZ7rBzyzTG5JGBRtmMMR0zX3ZSyNy8IrSXUg1m9wp7YOMyVKeEMNnduJp4+ba/DcsnYP0ifPdPeuJlCpPzcNdb4c/+L3jwb8P+O2D7rZBswEuPwdTsq66/69w4IAojqpUyuEzwa6OplkrkzS/9/oCgFsoO7CzEPVy/iy2XsDal1e1itAEvEBAGoZe8MX5cWJ4IaB/iUHiM0QWr8toFV++KVy1+//sRR391kVCBcpaTp89z5twFFDJTxKjAh1s550+LInwQ0O93eOjzX+QTzT4zlSqtzFBHEJ3Vfszp9TZhEFAPDKVKjf5YxKDZAudhaC+ZOfBBpuRQzo8skCPnwF5Fcxn5VzRAFf/08LEjIWGO2DGyoTiGRpKDJZutDuVSmXIpQrf7iN6WxgUlkdpRGqoTQrx8609Avw277oKP/QK865/C5mV4fJR4GcD0Tvjq70NnA17/N6DcgM66/BxE8P3/Cipj8PlfF7p+uQE774QnP/Kq6+9bMg6l1D8CfsxfgxeQOX9bgA8D08hs8r/pnIuVUiXg94F7gFXgh5xzZ/6i9wiiyCdmrpgTF0VCDdXOMd6o0s4kr9BJj5OPf5GVFyuMz82xeHkZk1M6rNRB5qoNgnKZsFzGBIZypUJsuwgAq65KqPM4lkJo7RvbKrMsu4a+Lr3j+RyK0Z1TGvtlhzZBQBwPMPnC9KOGnzl6hitjmtgqqpUyqt+RkQLGoExAJVLUgwDoE1RqTFQbqCzFZRn9sMStO7ZBd5OzmwNqUYm1fgIrLdJ+k2yLT3CVY2pygjTL2Gx1Cq8LFDH5aE9GzkKWyVVCOEz9Sh8W/Hw8n1+/wlvabzCSdqcD2jBWr7O02vRopEVNLIhRfPBn5evcHkgG8PF/Ce/7BVBGGMqf+EVhHxeHk3uUEy+BQj596wFYvwyf+f/Aa74PDrxJwuTP/SforMG7fw74vVdee3/R4ny1Qym1DfgHwM3OuZ5S6iPAB5ChmL/snPuwUuo3gR8FfsN/XXfO3aCU+gDwS8AP/QXvUuhE5TuwGEeJgYf8jDG4VBLmJM1YbnZYa7UxS+sopSlXyoCiF8dYa1nf3KQaKuJ+jzTLSNPUCyFLhVi6+nKA6hvF3PJK+LUNQYV3wFeEVf4Jhkf+GbZv3cr2LbM89/yL3oBsIZKwtHiJQxf6BGGJA1NjlHuWe7ttfr0WYXRGqRQyoRVRogjKJTKniFWZKHOYcolUKarjU0yHMdvHG5xZ6ZJsJrgzh7HzOcHPcMMNe9DA408fkrDIn62+5vOKoqMlcxD4sElCKf/5nBeYy5PjnBkARSPTEPGTzs1Or0evPyAKA59u+evc25ScYf8D4ilOPi65xA2vFUNRSrxIfI1iiM2Ei3bP90joNWhDVIM73gUrZwSYaMyKrlUPuHBYiJjX9sRcc3yrPeQBUFFKBUAVuAy8FZlJDmKS7/Pffw9DE/0o8Db1ah1DxTF0/Bq5ScYLqzlPiwjDcIj0FCIMgpqEYURoAkKfa4Rh6DVbKwz6PeIkKTSqTN5qWlR3r0m7C6hWXf2z/956QmI2ou3rrkn08592b1/g1gP7itHJOYSrleL2m/ayUAlQaNLY8UlV5bOlceLqFJ2gznJa4kRi+CU9xgUbEYYNGmGVSq3BRH2CyfEZkrAOQYWzmzHdQUzYXeKem/cQ+KYv5yxpklAtR57h7scYj3zu4cYwhFWvEnvwC996fpXkZL5334dczmPr+bPyAT1xnDCIE+rVShGyhWTs6Z8l+8yvkO57LenSadLTz5J+8TfJbnwj9sgj2NUL2Gc+ITwqpYf/0NjHPiTSSjO7yT7362SZtCKkZ58jfeEL2NvfQXN9jWOPf4ljD32ctfI8y5M3cfSTv/Oqq+9bmUN+USn1H4BziD1+DgmjNpxzedn1ArDNf78NOO+fmyqlNpHQa2X0dZVSPw78OMD8/Nzw4uaVU2dBh75YpL1Oq/NDTvByLBnKyjQnlPbaVH0WV9cJShHb5iex2hTJs7JQqBUUqNRoom0lWc3zCK4OmXKhY2szSex13rRztRFpfMiOI0vikQR2+H7bF+a5b2w3FwYBrdocF0p1fm32ID2gruByp49RvnXUgjWGzEmo1Faa5b4GVSOszxAnKfsmYl5TmWE2W/fcL4FNB/0+ulFBmpYkbMtZCAVPzJ8b+WZEDjJIqKms/7tgVPmNKtylUlqIf8MClPDBkoRWp0ujVi3AwJK2zKouf3jSceHEw2RYXHYr2bMxu7tnqTTGsDPvw/Uc7NgnYbRCuFdKMVarUGmX6K/G9MffztLFC2w+dAqlbsU+ushbwqdIreO32zfinOLt5zKmx0L+6PzWV13j30pYNYl4gz3ABvBHwDv+sq+XH8653wZ+G+DATTcVMgNZlglM62fFWa8JNQxvtMhIWon3rXNgLNoT9GyWEQYBjVqNyYlJGQrpm58KtAafYrhhYm3diJhaHjX4nTE/dM4w9cY72uw06hytr51kznlRNFssyDx4V0CgYNDtcmLxJFMz8/QyRcfBOop+nJBBPurD12WERWwDgzIaaxVpGJD2Y9plSxxkOF2cEFjH0WMnOH0mKAAJB+S8fFF0yR/vW3/9OWdapjjl7ADn/KiG3EaGKfzQ7+fKhs5vXllGp9tjdqJBGBhkDo4876wd47idJLMZl86cZnV9hVtq+8mCFt1BLGMi/LmZvKKqFFpvEoYRlVKJeqWEszOcO3+JLVu2gIM7zBINBqQYrIJnXzrCzq2zpOrVTeBbSci/AzjtnFv2i+BjwOuBCaVU4L3HduCif/xFYAdwwYdh48DqN77s8BiyYkcWE47AGFzqioQwDwFylm5+KHyhKQgwChrVCi6JCbTy2rnD5zp5w5Hn5jwq5/O8vHqbn9w35htDA5EgPA+3rtKYKuJ6VyBH0h2df2aIU8vswgI7wx4nz55joDWuVEOVK5SiirR+BiFOOT+mLRCES5cpV+tkpJTLZfZuC7lva4Pm4cdw6mrpnE5/QC/JyOesFz3yDA07h6aFleCKE7Re+ODaz49yQgrl6r9fe0+ttTRbHfZsm6VSLtHu9YvNCWfJMmklWNlc554DOzh85EWWWj26PYHzVRhA5kffKd/Cq400o2lDFJWYqJWZMBGDJCP0c949Fg/Wsbi0wqWLl3B/RaOWzwGvVUpVkbDqbcDTwEPAD/x/2zvzWNuu+65/fmvvfYY73zf5Pc+O7Tp1nMlJm1q0KqGU0qiFChVEhCBCReUPkIqEhBrxRyVAVZCAUgSqilogVKiFDiJVUjXN2JCkSerEdpzEs/1sv+c33PvudM495+xhrR9/rGHvc997dgbV71q6S3rvnmGfvddee/2m72/CI1YfAD4Sjv/D8P7Pwvef1oOK/TVG1GGtbShnJWVZUvQXvKQ24sva4/0bdV1TlhWCw+S+Lm7dOJQZVVmxtrpCOZtR5Dl7kymzsqRumrCBQzrlAb9FC1U6Uh4pOmefxM2RZVmCP1urtKPDh/NI7BjlLGBCTkcrOaZlyfKg5N514YFbHmB7f8Y3z21wwVXU/UXywRDpDRisnMBmOUtZxVq/x63HjlEYYa3ZYbWuODFQqr2X2ShnqaBWLNLsFF/CRwp/Ly7YB9Ju7DanolMUe+5zL7E1tm0I540Fsee85NGwt0qe54wnPhmJTg9BVeUbL77In11y3HXTSRZX19lxizz38ln2MVj1ofPHjq8mFc86hxYFrqrZ3twEk7O6BNP9McfuvI3pZI/zu/tsnxqzslqA0wDyCCoZVtvI5YPje7E5viwivwd8DWiAR/Dq0MeA3xGRfxM++83wk98EfktEngW28MjWq44kEfDSs5d7dGNhcZGt6QQRQ3/QB8m87aEONSY0qs8S0Qg+sb7oK2VV0h8MGW9s09iWS8Zq4SkqV9riYhIdIBE5a9dgbq5RDYvGeepcZqJ6JjgRnj/7IlsbG8zKKSbv+3wOE6WkoypnPPHlz9PP+/ytn3k/X3jhi2w9/QRnhjlre0vkC0to3ufON91LNS3Z3LpAIULpLM/slVTO8I9++qf41te+ynPnzrG20Oeemwdpzj5TkSAJFWKldn8j8885FjwIJkWs0xV7jXhij9EoQXUKTCStT2QSCWVVRvtjFChC/V0T6gTfeuo0D6wscOH8eSq11BcvU86maH/IwuICuTFsb2xQDPo+wFGEXr+HZIYsz1kYDnxvFtdweesKy9owduBCSkEEFkwUJH9RRd1U9ZeAXzrw8fPAD17j2Bnwt7+LqyQukRxv4u0LxeuvSecPkGwy3o33AsfaVSbLWF1dwdqGvfE+1jY0zuJbBhjiFlHTOrmScg9XSYr4OiE8CdYMx4UyPy3K48gwvPTiK5wTn9lWiGF3PGJkS5rTlivbO+zsWrZHE7aznP/8kY8yczAtVhjvb9Av9+n3tlhaXWbryV1yFDObUlYV1hRsmZvg+97Jh1/eYcQ65eQc7x64JIEjgibGq5tWo4Uwp1Ve/RSiVAiqrDHGJ3ZpGwUQWgOiakOflC7Kh89zEXBqmYYur6sry1y8sutrA4uwttBnzeRsDQcsZgWbOzt+MxtD0SvoFz0aqzRlRT4cMjCGem/MtCrp93sUeZbg5suXNzlx22neevddHLOPAXV6dglufxXA9FB7yLXVUZI9ISL0B/1gyLaqTYyi9Q/RhZKhxtcsKitmZUU9nrC6UPhmLY1LYdURdJGApmh07ImQmauTguZCTMJrY2ILNmnPqYKJqFXQyFQsg+UF8ixjZ/sKZV3zyJPPspRDfbzhpUsbXNiw1FWFMyM29wQWVpCbbqMZ3EM9ugD7Vxhv7SK66+/X9NDhEvbknZy5720UTcWLj32FyfYGptzHrpzBWYUiEIIqg16PB95yP089/Qyzsk5+HddZ9O59Rs08Ji15zTJr88tTkndkXjr3+4RYAThlMi0ZjSesr67Mr61TJpMZb3vb2zn73FlqM2Zx/SSLayuYvCDv5ayuryHqI7W7HXedWu+sRSmLHqONK+xOSi5e2UXW/APw0LNH1MRkDPvD6+6/Q00cUTRL6P+goTl70R/6zS9Q5HnrIASKzPhAQyO+M1DwjfSHy+SDIcN+Qa/IEVEa21A3DUiGiEVC9ZFICoKmrlld1Olgqmwc1vqw91hW33mlrOVQ6iHXh37gHRQCf/TJT1M3yrRu6IfNZKuSamZxTcnQWJrxFCvQCIyvlLilNW6/70c52SsRfO1YtY7RtOL5F57l0vNnGZ46Q3PpBYbVPn3T0JObSHUE1XvwsyznvjfdwcalC7x8YSNEB2gquROVjVbmacgUD6qZs6HmVPhGWoPeqUXnDHYCbK5YETJVmqamaSwLvV6QZkHsBBVNiiFn7r6b4fo6OzNLiWGvqnECpVNq9ZbRQpH7emNAP8voZz7Vueg1rK2uw/YmS8vLxFwR1RCdK7C8uMRP/8Rf5bc+/BvX3H2HnDhCBYqOpzoGEDahP4SP8w/FxYiGb4D6MuOjOCXj9ltvx6nScxWuachN5H4eCtVQAC4OnyRFi3Awr0YdlBrpO9dxAgb1T8TbGqGaLf1ejjZ1iCK2uMbigoe8rmuqyvfN6AH1aARlRbF+E814B1tOeed7f5gHhtuYvECKAZMKnn3hJV54+CUwBU29ixlvMez5BqF1NaOqe+iAFCpflSWz2RSDLzwhWchj1xB2HpG/qCISmUEs4EMqqJ1KGAUiSKpnxMWJZkc05IXGNpRVw8ryoifcYBOIwtJwwCsvvcCJM2cY7l3m0pNP81zpaNSi5FhjUM0o+j2q4YC6Kn1FmiL3DUKX17nr5jP0L22y4Rwvv3KB5kwDPQAPSBgRqqpi2O9dd/cdcuLAE0awKUznrws2QSIOIzhrfctlMS3ns5ZZWfHEE0+TZ3DHmZPUzSqzchYkEXRQylYVCCHRWfQBHLQvpPW/QMgkhFad6BwbYUR1DskyijxnZ28P2ziKPPMtjNVnJCreD+IkY9qALK1jtEEunWWpyJGtfT734X/Pl4zDmRwlp3a+INpanqF2wt54Ru/MHQyGQybjPc+xG39+Pz9L3ZRsbF2hbmzYv94wJ0qOSOThKw2ARWM9By7yPK1DVKtaQToPXsyhVsFmaaxje2eXO04fS73m/VpZ9va2uXjxMv2nv8aZnQv0ZzVPj4V9MtaPn+DkrW9hYXkFcSUiMJ1V7E9GSDVl8/wLbD//JM3jjvctG77/5tt5fLdGz4R76ERNV7UvFXS9ceiJQ1JPODpcO/aMkNBRNhQUIGwuF9sl+wWYlpXPj2gqFgY9ppMply9eZG9a0jihyH2aLSZrjfvA4QQltIv3HJX56uCxfmwMQ0kSJMwlSrLoRJTwWVlVlGWJQzi2ssJsz7t81DlELc10P6g6vpTp4toxiizD2ZpKHHVQcgTA+ND6zAhihqw5Ye/8WTZVyQzYtR7ODQm7AlWoasdn//QLQIZkRUCq1bddoElBlklCJtvJhGr3FiNZ6yOCJGHiWrWt2jT1SPe5+v793mjM4K6bfU9220CuOG144cWXaeqGly+fY6NpWDhxnGE9RfIBO9vblKcWeP9P/DBu6yWWVtaZVRV55vjcn3yMc9MZpjfgVB9Wl2rOPfsks6UTTG4/zvpKv90rTgHLn3/1q9fde4ecOOLiekPSBs7r8E5BCbvNhpZedWgG45GirOM9FXA1apV+b4jp9ckHixQ2R5wLSf0H/Bvg23tp9FrHdmjx++jzMKGPXwf10dbbDoJkGbkxSGgbnGUZgjBcGGJMzl3DRc6/NAOmxCrjdSfuq0HYnVy/bGVcqzSSGgjOGCbTMs0pdg7AOWpVskzJRBNMKxGdS707WhQ2IlOZiVEDljwvvIM2nT9gviGYMhbig9AuwkW/Rs2VrS1sVVEYZb8qsbnjhZfO88rlDY6trXM5XyLPHINJQ54VVHVJBuS7T/H5j75C34TmO+rIjePKxiWsOhb7A1ZPnuaxzbM4WWTaZG0fQ+d8hIH4LlzPv3juuit6yImD9qaCZ9UFnTluBhNr2hpfg8rrk3jOZWlLvzhLYyvIfB7zfffexS233sGTz5zl+efP+mrcySHoueHycIG3fP+bWVldZjwa8/TTzzErSx/J6yz9ouCuO29nbX0VEeHK5g7PnD1LVdWI8R1j3/G2BxgWOf3BkJ3dXT73hS/6Wq5ZhjE5WZbRN8Ldd9xGr9jh799e8d5jjnIyIDnIOiratYZ0/gdSRHB0lJ48MebWpQvkoj4rz3R98ulQgKSP+7WVTogLARRp4VsvEaxHDV3ssW6Dj0gQ10YMuI4tZhsPrGzv7lJXM4ZFxmMvnqO8p2Jja9sXYFi29E+s0yiMnJJLzuJkn8Y6GG9yfnzlgKNRQC39wYKPIL75Jl6sxlSDktI6YnyYL1fkwQevUl9/XQ89cbhOlGtkx9EQhKj7B04fOFNDCDgUX11wVlbsjcYsLgwYDhbYryzldMr5l84ym03oD/qU42rOj5FlOfffdx+XL17g8uULfN/dd3Hm9DqvXLhMJjnTsuHmm2/irfffxyOPPkJR9PiBd72dze0tX0VPlR988G0YtXztsUe5/833cubESVSVxx7/BnvjiS96nPtARRms8sn6Tu46scupdYdtlkNjntbGiYicSKxOSAAVor4emIKL0Kk/LstzjHF8YnYr2853N+r+Lta5suA3MrH4AwnGjjaHGiCFXERgwqX1b+HgViVLIEWCfRXbWPZGY85f2mRvv2Rja9tLOqtI3iPDsHtlm9F0GhicISty8iz3VWhQyHz51yzLfbRE8HU55zj74jPMqorpdEqWFUkVjmCDR8/cq4alH3ri8GqLJ4aF5WWWlpaDweoLGkioT4XEqFfje86FeJssc1hVil7B8ZUljBFG4zHnLmwyqSx33HE7N58u2Hl6dz4GSpTBIGN9/TgXN7f40sOPU5YzisKjWLnxf61znHtlkyzPeec7vWNNEfJMOHf+HA++/a28+13vZnVpGLoyCd985sUQvIjPcRZBxfDx6nbszIeTlzNfyMyX0/TQcG4yMhHy3HjVLKh4mclTuzPrlLpuUuXGPM9YWFggz3tRWwoWlJAShGg3Taw37F0BMcxek0S2zpE5Qs+/dmsZI2Sh3UBMmffDW0a+t2NwQgbbrW5q8l6fN999G1/8UujxCPR6QxYWB2T42l3WKVYdjbWUVMTohfisoqQXPFiT9ZfJ5QTb209QVzWnz5z2zkH10QFRAnr98g3qBIwjGuGKz99wLhi3AR7tIivJE6yKtf6hG2Po9wdUdY0q7O9PWVxc4L0/+iDb430++7kvAPO+DFs3fP5LX+P4sXXuvPU09/3we/jcF/6MixubXt8Onnnf6jlWIm85qEW4cGmT4XDAY49/izfdeSvDXg+HsrS0jNqG6cRXS09+lbgps4ys6FGIwTZNkGb4XBbjiT8L1QKj3BQldbFV41tO++hZH7If+4QnD4bA4sIS/V6P0Wg0Z1RHw12C4eqiepc2/Txq1/YI9OWPIpLoz3cA+g5wt3NC01ims5rVpSVWFgZJdRNjefn8ebJAsElK0mFe+EuIxPYQhJbQGYOeslLsM84ybG6p6grVQUscEWqOc7rOONTEkdAekRCBaZK9kfKO1RvhzkYeFziVEZqqoa4rcM43Tcz9+fZGE+647RSFUR7/+jcRU6BUCYGK49TxYzz4zgcwCL0C0BptfHh2tE2i4WwCJ8ozk+ZeViWjvV3uv+9eFhcW2Ni4TG4MP/7eH+HSpYt85eFH5m84cG6c8d5g42PGVDT0OffgQiZCHgjD7wwvKR2CGO9f8Sa/D8yUAH3HDrkRULjjtlu49+67+JNPfcYHaHYg6K4/J10mMKnwZFoDPctoGhs2qqZN1wYmtmqxZyQOHBhr2BtPuPP0CqdPriNywROOrZlOpr4Gl7la8ZE0g84eSUsojEcjrly+FFRCYX9/gury/N4Ka3Aw+qE7DjVxxMUk6LuNU5qmSTVjJehVsVEJoSWzBTLJ6PV6WLVsb+9SY8ilh5iMytY88cyLfO3xZ1Ax9HJDXXqemuK3MsPGlS0efewbDPo9vjIes7s7RkVTbakLFy8x2ttD8SHwn/1/X2RrZy9xsu2dPX73I3/MyvIiANPpDBHD8bVl9vd2ki5ujM999jFk3q9jQqUHzTIkGI9ZwMMkFpyTON/oZPTfZ6GPYmxKGR1srSoRNpaz9LIIvsYhCZnStP06vgrVtth2PC5Itmic+/NpuicNF9TwwnS4/d5ozPDO05w6tka/V3DbYsPWqjDLMlJcT2dDJClLWB80nSse4/NuhACXsbCgrOSW2FbCAxUmwHBvYLUqYu3WNkwn+zjricNvCp94MxwOybMM29iA0/tNZ4HZdMbe/hSHcsvJ20CEqq7ZHU0py9pDpeo9tFE9yLIMaz3XeeXSpldhOuqbZH7TTWcls7JKRRY2ruxQNiHeRL2hO51VPnYp2BgLA599V9e+RmvaiOoCcXokKUsqUzzIqzZtEbrWZ+J1bk8kBsGZqG5IMN4N8YigqeB7azRkeSiNEzl+KBcUs799hK0BvLPQOosNmZfR8UmcRyiiHfhUsgOdxKoqgXzF+OgFI+yXJaboM1xc4UqzyIceHNG4Pqq9VgK1u6Gj2l1vv3TIPEhaEUM/n/CRnRPExqq+iqLM096BceiJwzmLtf5frg22mqWAQRHDoD9kaXmRLC9oVChrh3V+49XWh3/38oyVlSWWFhdTm7MYy+M3o4cgvZE7X1Qh6cvdRxQeQCSKuQC7BC1y1fFKVCuinyaWyXQ+m09aNYHwNwslM9FQyU8iQfjnakLBuSygS5Y2dKObBCaJSUa1By5e2uDhRx6jLCscprNRgr0R7DqNSRrhrrKO1JhXvyQY7fP1vOK9JHUshoqYjKpuyIo+xdIKv37hrWR2wmQyo64bqqqhKitfeM+6IH3aQhtZqJ3cZRLWWpySktmMMUie0x8M2HG9ZJNGaf0qguPwE0dZVQl1qWf7bFy6yPKp23FqaRrYtxNuO3MTYmve/P1v4bGHv8zuzqZ/uPhFW18esrZU0MuUyWSSKiOqxjCJ9npd/TUlAAXxa0wH9+9siu5mPhg+kgirA4y4wIEhqgVRr243kEj7wNu5eQ7fJY6oGURlSYSQANbOKTk1aaehKFs7e+yOJgEIiKEedO4tqm4BzdJQrvQA4XlgwnV8J9dj7/7KqV8HUFcVgnL82HFevrzDfqVMnVDahlobaslpxOLE+SQl0WRLZVmOMW28XQqdb7wRXtW1n5cr6Nt+Ajy8MJS0jtcb32v1kb/Q0VjLcLCASEZR9Hj2pYtc2BrhfTqG/WnJo998CmlKFoc9eoOcPPdx/2IybOi5UVrl/NaEosjZHY2YTmdMp5VvvxtDTWg5vG+xhi9IHKBJkBBBYZKqB3HzEH7v/+tKiISiGQn1Wv1nUUod1KlR7yPvPkBviDNHMBo4cCRs0faacWO26asE/V9Q35cn9T3Ms7ZjbtThncbe4A4NdlykHH89k7hvSyT+EO+D6Nga4ey+OuOy3AAAGDFJREFUT6Km3IzYZbasGxrnWF1eDKqkD+fpFT3yLCfPC/K8IMt9EKWaDGcM0c9uAmhhQn1jY4QsQN3G5GR5QWZ8NRcTCnL4fiivqlEBh1xyGBH2drY4f3EQwjt8D0DrPOYOSlnXyVkmhFwKZ6mqhrqqoKkZT2sPf+Y9CrxDKM9zVCVkDAaVIBppdDe/zL1PUCcxpkrDg5iHGz0Xj3VzvXfW4KtxXLh4gdE4BrzFCN4IV7fniGhUik/SeXVFAwIVEaS4YZU2vsvE30cJGAknnSOkwIZASx/dLGlNkp7fuW8X1r+qqsS12/KotL/BX9cFZqPamQ/+87KsmJYNx44dC/4HOtLZRxJkgYlopzJ9JgGeDkhm9PtEaNnbRz7AMRaNTupmfH6vYcAcaslhTIYpBpw8dQJrHQvDJXKE5NkMm7OJRjCxKqJfiLzIcZIxntVkeU5/uIgxQr/X855pafvQpdHZbNeyPQ6+9u9962Rn2/I1aZvPiW5HbRs+/unP8+jXn2w3PrStvtK/ToQvrS0Sr+2cS79v5zNn6bTcUWSuhlY8n+I3eEwRTtIHIBLJASkU61R1P7PWBq4cYVuCBKTtjRjuK/mknJdGzvnC0qsrS/R7BVkWfD3CHNomIeRGos/GBIdf9I5nrRTLsgyTmfSM2+coRNJAY+GINyha1ev1eOAtb8bkOfc88HaGq6fZ2b1CCN8hxspkeSwT41K1DJMZMjJO3XSSO+++B3GWfn/AflmT5xm9IvexVq2diVOffK8i3Y+v2uxxxJiu2Kg+2iuqIZI3cs8IwQbMKMty7y3XWOgsRvriN2UgzjgBJRijLkCmYePhXDp7NLqTWhfsj25xZ5c68qaMcfqDPlVtOxIu/rYjkfBrHaOKwRvruWl9Iq4L42rMjTHxllCX/PJ0I3ZVYVbVnpCaJqFrxoBRwQSbzYevuDaWLlIQEU1re6N7CZqRGfUGe5TqUaoRYg6UNOdrjUMtOaxr2N/bZG9ng6rc4+SJIWduOcH2eA/wXurZdNpyzsB9XSjt75oGV5a88tJZ6mqGwzGrKprGUdc29YzoSoFog/gSma3uH8uEdrmzRGiSmPAUuW7rXErh7a5N0Tx18lTqkd0VW3NON+JGbAmzqxZBrHdFkiSRQTtaadKayErbn0IDpGs4cew4/V6R2o0pQVUL3n65xhapg6E7r2r6v7YTGW1t0xLUVQhaON5ZRvv7iDH0e70ETiRnbzD4fTRwFkghqLSB+STWIyYZ3ZFJSAyP6SxqYlRz63n1ONSS4/LlTX75Q//Oc1oMPSruuutu3v3Qj/riCaoM+oPQKandjLWtmZUlmQiXtkecfeUCZW05ceIkm5c3GY32mMwqJMvDuYkwTcoDiQ/EQ6Vt0NzVSFWUYJDnBaohstcYTGhPHOcFsLywwE//5I/x1JNP8cWvfC3pyEl9oM2F96Nj82g0c6N3Ok67RQTaXhi0vyNpav6MgUD6/QEPvedBHnn0cZ47+xIaKra4kPTUhaaDFR8KJJBCQBIaJvMqWOy0paE/fPgRsXJiytcHRuN98ixn0C88E4rqFC16aELDn4NInlOf6JWrSc9DxGsOxipg59aiRfg0mlDXHYeaOAaDIffc+xbuedM9iFZ86uMfI8uEXhFDIpgjjBjOnhvDytISOMfGzi6Lg2EKvtvdG7G/P0VN5hugmMB9Q1JVuxk8t0+WZGckg9J51cGYVp2AsAmV0LGpw12N14d7mcHWVVAvSLi/53BtQlVEjqCdQ/d5dkM0IHr4Nalz0YBNcxNC5Kw/h3UeHh30inbj0BIaCZyNRBn0dFoJ0K4DaR4JoVO/fj7tIDrfSN+pdVhrmExmFHnh0SrBF+0rBFf5TrZp/8aJx8tF8dphMBpKKHkvfFvhPT27eDcaBcz1RcehVquWFge8/a1v4b0/8i5uObXG7adPsrS07BPw8Vw2czNoJojWiNa+EWV4xHVdUWQZt9x8mtWVRW+ULyywuLJCf7BA1uuhYgiNtpI6AKR4pG4zmoPe127QXdqEMfgwbez2+BhGD0pVe896RNk6pn8gkbgdW5NnzuEWNxyKqndqthv4anWnBQrwIeOqNLZmOpuRh0hjzxwchMDOWCLCdPZPMqY75z8YSpLWKUHJ0vY8DOpUVP2cU/ZGe5RVzdrKim+HZgQ0NMyUaOWIV/FUOncYTu/a+zQhODNGGqTi2B01Mz0rIqR97XGoJYc3/EIsk1NWhj1OHlsOG8WQ2YrRS0/zyMWnuenMrexPJ2SUDPp9KuurjqytrTJrfFyW4nXipq5pLCGvwW8I2zg0y9MmjYUDuly6SwzAHOeMpXnCwcnATrCqKjif426dUjc+qjf2GPQh5JGdtRBqG/4dfQwkYrWqqW6vU4dKVIs0bMZOkpQG+ylJR2+bPfHU04xG43SPkTtr93rESXjD25kImQtZiM2KPhu/QUNToM7aaUc1RTufO8d4f8JkNmNleTERlwspi74jbZhDZ90TKka3kB5thiideUX/TxfGjUzpjapWEblvyObTpiEPzj0xMCunPP/SedRVPPHMi16NML5vubWOumkoy4r+4gr9Xh91dm5RfSZn4Ei0CwgtMcxDtvOvrxkikQhkXv2Jo65r6sb6lF6CluAUMTFkw2+KaDBGpGZehJA2cJIGUWEIBHaVOi3BTwCtzm+VJ59+zv9SMjJ1qBowHWNepO2RGEPT8SpZTttqOq6rZyAdNTCsaZxPVN+c85VYnCq1tZR1w9LSYvqNiUWtg9TxAMJ8pLBTh3EmqMZXe7yjMe8am9Kho88pXucNKzmibioIeZ6RZTlZVrDQL1hcvplpOfUlPZ3i22t4taVxjrL2jr/FxQWsWl9EbdeLb5MZMmnPDVxVLCD5EGg1b/9xt6DCQb1bfA/CMPukokl3o7vQ2HQeTSJwe4l6dbwe7QP1/Uk6YIDVxLG7hdR8MGuHQwbbJ8U3qSSiixvaqx1hI3YYQ9LZJcUSXkUQ8R6TRh/bFYQ7iPfX2gUu2Ir+26a2TMuK4+srnpsbaeccd0Kwl9I1gvrqxOHUS6oIBafwGvEGionPIIADSqsBZG9UPwcKznqVZbiwgBoo8oxhz3DPW+9m58JlVpdXGI+2kgfU4b3mZVlicBTDBQb9HkVuGI3H7E8mPo0Vbxw79dG7yU8RyljO1WOi3RDtA9YUrBiPc11dPLJKaX8bQ1LqqqSqZukeVSLnjw+1tXPiMYmLhvk4Z30JIvUHtKhaRJriVu7Mv8P9Y5QuhMStUASbdP4QvhuILcK8QnSczldZj/ZTFx3z8HI0xA/WpO0QObC/P+HU6nEGvYKqsXOtqLsbIoXIRAsrClVa73t8HskWcj4bVDCBZ0QAhLl7PjgON3HQEcuqISyk5uuPPIyprrC9M0apAqTZqjm28cZc1Tj2R/sMexVnTp4gy13IiIsbMapNHU6TpIXnLllm0gpey96IdkjXKE3Gc9LV43thb3/K73/ko4zG+6gaRLLwfXvPsXxM95oaHHjpGl2INxyn0V5IbYjbR+8LWXftJk3Ozuhz8ATZRv4mKQSptZlTRyYxt98TSWsnxOJ6yvX4cVs21P/z6m/NeLxPv3cLC4M+o0mZVKJYYKNLJUmyOY/2JYdjZy2gjZqes/+SWeWJ3L0KdbwxiCP+c4p1wpPPvMCXvvQV7rzjDpqyREMfOr9BoOj1yYqCzStbVGSotZi8oKzGHurNi+BACnop3sdAMkiD009JXulrjS7GD6GaoEbMyAVbJhKIhmMatnb2UXXkmaT8eE35Fx2u1iGG7hRUY7FNH3+UUCKYw70I9kdrr0CXu7ug3jjnQuh3CCNJKhnBsO/WOYznJkmLbsXHaDN156DpZfxOg2RzQcJYxvv7iBiG/dxvWqcp/DwSugRjKjnwOvahVxO9BMtDidjuGsZJxyDKaGtcI9EwjUMN5ZKQHMWJoP11ltfXOX3bHWhvhTvvvseXeZGYQmqSOlJVFSCIMVgV8rzwxdWc0jS+4HOyaQIRNJ0I3XR5Wq7YhSpjTkkTyvn4kjTt5vParkuF5jTCoyIUhQ+fTtKFebtGdT6uqi32ocl2aG2GzsMXWmPYKYLzEcYhhtWhKTo2KkkLCwvccssZosHta/1q2nBdqdm1QbpznAMv4nycJo/2vG7kfR0x2Tk6FHdHY9QIK4uLQRuNTMkRcQftohx01Fd8BHc0tNt8n+BdjzWQA6HGgoCE53K9caiJw+usPj5ncXGZBx58B1fGDU2xxNseeoi19eNs7Ywo64baWqrGV92o6orpdAbq1ZO8yMnyjNo2PqQ58zE4HgY1aGhVEEVwlxPHf9cKUGv14kAwgZNCV00J7/EZccOFBX7oPe/m1MnjYUPGDT4nGw4YvZoerjugu3cJFp0nGD3wm9i4BgjtEpRbb76Z9/zAg/T7XprOeVwSgejcddI5w75qIwk6ahNeSnpC68ylE1avgSlZhdF4TNNY1tfX/DrSok3d+YTVueoeNal9mhKdulI9ggQanKrt3+vvv0OtVplQfMyg7I92eP5bj/LAux7COsdwsc/a2iLDpSX2RqOU9GKMoWoaj0rlOf1en34vpyh65EURQpvjppakNqi0XZ1aPXVez+2+joTRfXhRJTv4O69VKaLC+soK73jgXjYunGNz84oPrQj8WJDOT+c3QDgFEKucdGROl3NL+1m8Fw2EkAV7IJ7T4dGb5eGQPCtw1NE7kOLAUFLfEn91QpmdTuh5B7mLNo2KJJUospmDKg6de9if+PbLg6FvCZDKwLoDjEPjUsv8+khUK6Nk0yTRY6CidYoYl5yarxZ0CIecOMAXJXjl/AUuXLzI9s42RSH0C2Fx0KecTqmqGb1+jyzL00NaWhgwHAyYNQ1S9FgaDkCV6bSkrhuapvGJQpELh5Zn2oFmU7K1tovdfbgivqhCr9frcGfBNRYTKpAcrKYnosHAD46ISAzSPiiJEitG7DlvSEc/xhyrk5YjQpZMm+gbmgvJjioZrSqhwGw2BSPkIeTb2RAXlsqBRm95OyJC5lTbHu4HfBBRksUq+RpUX5ziOvxDAGcb6rphOitZWhgw6Pe8+mcdrrbeAx7V3y4jgHQt5xQnFidt1fs4rwS2RGmn2qneeP29d6iJwzaWvf0JWdFH8h5qekwqy954TJYZmqrCYEL5T0uWefFeNw1NXTEpS3oLBtvLaJqaqqxCcYYQYGL8zozqDeLzklH/AE1MN+2oEl3fRkqgwftYrG07KAFhQwoRIklqVDeCNnC9iBClgL9U1X8ezowvIxG1focgeUK1x4jORMTGdeaUqssLPkrZNiAhmtlkYVN7cEMO3H+8lp/n1bnkRCdbh6nMhdMnVW3+WVd1zXh/ymI/wLCSdaQRJFhJWp9SJIrMCGoU5/zf7nxMqO9lQ8pzXK/4DF6NOl7T5hCR/yYil0XkG53PjonIJ0TkmfB3PXwuIvKfRORZEfm6iDzY+c0HwvHPiMgHXuu64POse72Cft9zftvUrK+usLiwyPLaKfrDnn8IKa86mLXiQ9H3J1MuX76cDDUMqRiahiSna+rs4fpq3Vy/DWiPj4Z4FN3z+q2mBxevE889m838hmVe3YhqTmztHDdx8koEiBUID3bevvAbt7VHDn6HkOKa2us6Ll/a4JOf+gx7e+MAHBwgxk5IfzfOKX7nnJ0zgNOuj9QfjiNKRFqfSaQRn1Pv2N3bo9fvHyBE0jm1Pfv8M+lYhwele3iRHItzdt6riQ2+PYP8f3B1f/FfBD6lqvcCnwrvAX4SuDf8+3ng18Ikj+F7B74H3y/wlyJBvepQwDmy4OXMjS/sdmlzCzdc5+EnnkMyLy2bUK2inFXsh06xJivo9QYM+ws+h6OqQUIVvySqlYjrtoam/ywGHXa5XLQ3ukbonNF9jYy7aAirkogqifXOcYmIohFMu5n9xtVWJQrztS62bvPXaBKcrHMxR74It0ub0oVQmqqqOHf+MlUTqxq27eDm5tdVY9BERN0SQN0N7ZxtVblwX36enfmHOfous74lweLiAstLC8n3kpgLtMxB2tfxXDEPp2tvdJlel+HMGVDfi+RQ1c/hu792x98EPhxefxj4mc7n/1P9+BK+J/kZ4CeAT6jqlqpuA5/gaoK7enLGhCodXvXIcsN0OuP85UvMmm2ujPbIi35Iqs+CGgR5UXDyxAluv+1WlpeWWF5apKpqJtNpiIZt5lAVbwJ43B0c1jVpM0f6iBsGrvZvREO4ffCaUk/nUZ7wWxGKIg81qFp1J5brTwUOAiG4ECnbPpRIs+0OEfW+DzHSHj8nFYMN1P2tRiPe+P4YSWqEDeW0VUN0nll0kacupB03aVw/pRNh3Nm03XRZF+57ezTGNY5engX/kiSfxtz6Kx1Pv59PYggdwu7sYU+srpUuB4n/WuO7tTluUtUL4fVF4Kbw+hbg5c5x58Jn1/v8qiEiP4+XOhw7fjwYncGAFV8Quq/Ko5/9BLvnn+P0yhI2oE517WtSKY7t7S1mjlDL1jIaj3yBtenM9/kwOU0TwiH8hb2/JCXit3OK69wliq4q4XX6lsNdy2iEuFG83yFBmtJyUWjjl+J50t/uubr+FGmPjSiRBAO4e56uft1Nt4VrqIPi82Q0luxJN+b/cxoA9o5kMkbmzmMCWkVnDt2VaNdHkySfTCZY9aVbY9nQpDJ1NLb2VqIaGgJTXUTW5iMWunZiVwqlSOjrjO/ZIFdVFTmIZ3xP5/uv+H7m3H33PQo+mA8yClMwGCxw002n+NNPfpKeKGUvJ7qmuslGdWOZVJa6nNIvCrZ3NpmVU+qqBDEUWRHgRp/FlyDMWAlPSV2bvI0yv1kjcSQoN0COc8Z4J3EJPLfb3R3xB3/4Ma/jayh27fBQciwL2iWKdmX8HJxL6EsM4ovnd2HDR3QrOr9a3ZvA9b1kMhrP6/95yRuu0zrquzNIqkhS+RS6IeJdWy7mqRzk0EkCEXJHQhTieLyPAivLyx21yKbfz62H0DrwwmtNbvx55CxeM55HpJ33q9AGcpC7XfMgkTuBj6rqA+H9U8BfVtULQW36rKreJyK/Hl7/dve4+E9V/3H4fO64V7nuCHjqNSd4eMYJYPNGT+LbHEdzbccdqnry4IffreT4Q+ADwIfC3490Pv+nIvI7eON7NxDQx4Ff7hjhfw344LdxnadU9d3f5Rxf9yEiD79R5ns019cer0kcIvLbeM5/QkTO4VGnDwH/R0R+DngR+Dvh8D8C3gc8C0yAfwigqlsi8q+BPw/H/StVPWjkH42jcajGt6VW3ajxRuJu8Maa79FcX3sc6sBDgmH+BhpvpPkezfU1xqGWHEfjaNzIcdglx9E4GjdsHBHH0Tga1xmHljhE5K+LyFMhiPEXX/sXf+HzuU1EPiMi3xKRb4rIL4TPv+MgzNdxzpmIPCIiHw3v7xKRL4c5/W8R6YXP++H9s+H7O1/nea6JyO+JyJMi8oSIPHQY1vVQEof4qgP/BR/IeD/wfhG5/8bOigb456p6P/BDwD8Jc/qOgjBf5/ELwBOd9/8W+BVVvQfYBn4ufP5zwHb4/FfCca/n+FXgj1X1zcDb8XO+8es6Hxh3OP4BDwEf77z/IPDBGz2vA3P8CPDjeA/+mfDZGbzjEuDXgfd3jk/HvU7zuzVsqr8CfBQf37EJ5AfXGPg48FB4nYfj5HWa5yrwwsHrHYZ1PZSSg+8gUPFGjKB2vBP4Mt95EObrNf4j8C9oyy4fB3ZUtbnGfNJcw/e74fjXY9wFbAD/PaiAvyEiixyCdT2sxHFoh4gsAb8P/DNV3et+p56V3XBsXER+Crisql+90XP5NkYOPAj8mqq+E9inVaGAG7euh5U4zgO3dd7fGj67oUNECjxh/C9V/YPw8aUQfEn4ezl8fiPv4S8Bf0NEzgK/g1etfhWfXxNDhrrzSXMN368CV16nuZ4Dzqnql8P738MTyw1f18NKHH8O3BvQlR7wd/FBjTdsiI/7/k3gCVX9D52vYhAmXB2E+Q8CuvJDhCDM12OuqvpBVb1VVe/Er92nVfXvAZ8BfvY6c4338LPh+NeFU6vqReBlEbkvfPRjwLc4DOv6ehmI34Wh9j7gaeA54F8egvn8MF60fx14NPx7H143/xTwDPBJ4Fg4XvCI23PA48C7b9C8/zI+3QDgTcBX8IGhvwv0w+eD8P7Z8P2bXuc5vgN4OKzt/wXWD8O6HoWPHI2jcZ1xWNWqo3E0bvg4Io6jcTSuM46I42gcjeuMI+I4GkfjOuOIOI7G0bjOOCKOo3E0rjOOiONoHI3rjP8PGW64/q0WoM8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "plt.imshow(np.squeeze(results.render()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d737522",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[39, 35, 34],\n",
       "         [39, 35, 34],\n",
       "         [39, 35, 34],\n",
       "         ...,\n",
       "         [32, 28, 29],\n",
       "         [31, 27, 28],\n",
       "         [30, 26, 27]],\n",
       " \n",
       "        [[34, 30, 29],\n",
       "         [34, 30, 29],\n",
       "         [35, 31, 30],\n",
       "         ...,\n",
       "         [25, 21, 22],\n",
       "         [23, 19, 20],\n",
       "         [23, 19, 20]],\n",
       " \n",
       "        [[27, 23, 22],\n",
       "         [28, 24, 23],\n",
       "         [29, 25, 24],\n",
       "         ...,\n",
       "         [16, 12, 13],\n",
       "         [15, 11, 12],\n",
       "         [14, 10, 11]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  6,  4],\n",
       "         [ 7,  6,  4],\n",
       "         [ 7,  6,  4],\n",
       "         ...,\n",
       "         [80, 78, 79],\n",
       "         [81, 79, 80],\n",
       "         [80, 78, 79]],\n",
       " \n",
       "        [[ 8,  7,  5],\n",
       "         [ 8,  7,  5],\n",
       "         [ 8,  7,  5],\n",
       "         ...,\n",
       "         [80, 78, 79],\n",
       "         [82, 80, 81],\n",
       "         [79, 77, 78]],\n",
       " \n",
       "        [[ 8,  7,  5],\n",
       "         [ 8,  7,  5],\n",
       "         [ 8,  7,  5],\n",
       "         ...,\n",
       "         [80, 78, 79],\n",
       "         [82, 80, 81],\n",
       "         [79, 77, 78]]], dtype=uint8)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a28033",
   "metadata": {},
   "source": [
    "## 4. Real Time Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf55564a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 2.0ms pre-process, 52.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 51.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 2.0ms pre-process, 51.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 52.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 52.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 cat\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 44.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 44.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 43.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 44.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 53.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 44.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 44.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 44.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 48.5ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 51.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.5ms pre-process, 44.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 44.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 44.5ms inference, 4.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 44.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 suitcase\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 suitcase\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 53.0ms inference, 5.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 44.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 44.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 52.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 51.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 44.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 52.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 2 couchs\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.2ms inference, 1.3ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 50.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 49.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 43.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 52.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 49.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.2ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 44.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.5ms pre-process, 44.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 50.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.4ms pre-process, 47.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 44.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 50.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 44.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 4.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 44.5ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 hot dog, 1 couch\n",
      "Speed: 1.5ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 48.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 49.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch, 1 laptop\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch, 1 laptop, 1 remote\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch, 1 remote\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch, 1 remote\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 dog, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 dog, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 44.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 51.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 50.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 44.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 52.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 44.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 44.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 50.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 44.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 53.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 44.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 44.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 44.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 48.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 44.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 48.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 44.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch, 1 toothbrush\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 44.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch, 1 remote\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.5ms pre-process, 48.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 cell phone\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 cell phone\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 cell phone\n",
      "Speed: 1.0ms pre-process, 49.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 cell phone\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 cell phone\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 toothbrush\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 toothbrush\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 44.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 52.5ms inference, 5.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 51.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 44.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 53.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 44.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 toothbrush\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 50.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 49.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 toothbrush\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 toothbrush\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 49.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 teddy bear\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 baseball bat\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 baseball bat\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 cell phone\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 51.0ms inference, 1.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 50.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 4.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 1.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 44.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 cell phone\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 49.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 1.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 toothbrush\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 44.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 57.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 44.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 frisbee\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 toothbrush\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 51.5ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 4.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 49.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 50.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 49.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 4.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 51.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 49.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 44.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 cell phone\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 cell phone\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 remote\n",
      "Speed: 1.0ms pre-process, 50.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 remote\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 cell phone\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 cell phone\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 51.0ms inference, 2.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 50.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 45.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 cell phone\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench, 1 couch\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 cell phone\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 48.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 48.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 49.0ms inference, 2.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 bench\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person, 1 couch\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 44.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 46.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.5ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 49.0ms inference, 1.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 47.0ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.5ms pre-process, 47.0ms inference, 3.5ms NMS per image at shape (1, 3, 512, 640)\n",
      "0\n",
      "image 1/1: 480x640 1 person\n",
      "Speed: 1.0ms pre-process, 45.5ms inference, 3.0ms NMS per image at shape (1, 3, 512, 640)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"Cars - 1900.mp4\")\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    #resize the frame\n",
    "    frame = frame[:, 200:1280-100, :]\n",
    "    \n",
    "    # Make detections\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = model(frame)\n",
    "    \n",
    "    #count number of vehicles\n",
    "    num_vehicles = results.pandas().xyxy[0][\"class\"]\n",
    "    results.names\n",
    "    num = 0\n",
    "    for vehicle in num_vehicles:\n",
    "        if vehicle == 2 or vehicle == 3 or vehicle == 5 or vehicle == 7:\n",
    "            num+= 1\n",
    "\n",
    "    print(num)\n",
    "    \n",
    "    cv2.imshow('YOLO', cv2.cvtColor(np.squeeze(results.render()), cv2.COLOR_BGR2RGB))\n",
    "    results.print()\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189631c9",
   "metadata": {},
   "source": [
    "## 5. detect numbers of vehicles in every traffic light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "beb3db07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of vehicles in traffic light 1:  10\n",
      "number of vehicles in traffic light 2:  30\n",
      "number of vehicles in traffic light 3:  24\n",
      "number of vehicles in traffic light 4:  5\n"
     ]
    }
   ],
   "source": [
    "#set dic to traffic light. First value number of repeating and second number of vehicles\n",
    "traffic_light = np.array([ [0,0], [0,0], [0,0], [0,0] ])\n",
    "\n",
    "#set four images for testing traffic light\n",
    "imgs = [\"https://focastock.com/wp-content/uploads/2019/04/P1030336.jpg\",\n",
    "        \"https://images.unsplash.com/photo-1589828155685-83225f7d91f3?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=710&q=80\",\n",
    "        \"https://media.baamboozle.com/uploads/images/199143/1642726643_69020.jpeg\",\n",
    "        \"https://res.cloudinary.com/twenty20/private_images/t_watermark-criss-cross-10/v1538121876000/photosp/e0f3f938-58c9-40b5-99a6-e5f5733eb76c/stock-photo-car-road-transportation-street-vehicle-automobile-cars-auto-front-e0f3f938-58c9-40b5-99a6-e5f5733eb76c.jpg\"]\n",
    "\n",
    "# get number of vehicles in every traffic light and get higher value for that traffic light\n",
    "i = 0;\n",
    "for img in imgs:\n",
    "    results = model(img)\n",
    "    num_vehicles = results.pandas().xyxy[0][\"class\"]\n",
    "    num = 0\n",
    "    for vehicle in num_vehicles:\n",
    "        if vehicle == 2 or vehicle == 3 or vehicle == 5 or vehicle == 7:\n",
    "            num+= 1\n",
    "    traffic_light[i,1] = num\n",
    "    print(\"number of vehicles in traffic light \"+str(i+1)+\": \", num)\n",
    "    i+= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d073c7e0",
   "metadata": {},
   "source": [
    "## get the max value and add for repeating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "775dce48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "1\n",
      "[[ 0 10]\n",
      " [ 1 30]\n",
      " [ 0 24]\n",
      " [ 0  5]]\n"
     ]
    }
   ],
   "source": [
    "#this for testing the max number\n",
    "max_num = np.max(traffic_light[:,1])\n",
    "#get index of max number\n",
    "index_max_num = np.argmax(traffic_light[:,1])\n",
    "\n",
    "print(max_num)\n",
    "print(index_max_num)\n",
    "\n",
    "#set wall traffic light to zero except the max value that is adding one\n",
    "for i in range(4):\n",
    "    if index_max_num == i:\n",
    "        traffic_light[i,0]+= 1\n",
    "    else:\n",
    "        traffic_light[i,0] = 0\n",
    "print(traffic_light)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
